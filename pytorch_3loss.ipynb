{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook #, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BatchNorm2d\n",
    "from torchvision.models import ResNet\n",
    "from torchvision.models.resnet import BasicBlock\n",
    "\n",
    "import time\n",
    "from kaggle_util import *\n",
    "from models import *\n",
    "\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BN_EPS = 1e-4\n",
    "\n",
    "class ConvBn2d(nn.Module):\n",
    "\n",
    "    def merge_bn(self):\n",
    "        #raise NotImplementedError\n",
    "        assert(self.conv.bias==None)\n",
    "        conv_weight     = self.conv.weight.data\n",
    "        bn_weight       = self.bn.weight.data\n",
    "        bn_bias         = self.bn.bias.data\n",
    "        bn_running_mean = self.bn.running_mean\n",
    "        bn_running_var  = self.bn.running_var\n",
    "        bn_eps          = self.bn.eps\n",
    "\n",
    "        #https://github.com/sanghoon/pva-faster-rcnn/issues/5\n",
    "        #https://github.com/sanghoon/pva-faster-rcnn/commit/39570aab8c6513f0e76e5ab5dba8dfbf63e9c68c\n",
    "\n",
    "        N,C,KH,KW = conv_weight.size()\n",
    "        std = 1/(torch.sqrt(bn_running_var+bn_eps))\n",
    "        std_bn_weight =(std*bn_weight).repeat(C*KH*KW,1).t().contiguous().view(N,C,KH,KW )\n",
    "        conv_weight_hat = std_bn_weight*conv_weight\n",
    "        conv_bias_hat   = (bn_bias - bn_weight*std*bn_running_mean)\n",
    "\n",
    "        self.bn   = None\n",
    "        self.conv = nn.Conv2d(in_channels=self.conv.in_channels, out_channels=self.conv.out_channels, kernel_size=self.conv.kernel_size,\n",
    "                              padding=self.conv.padding, stride=self.conv.stride, dilation=self.conv.dilation, groups=self.conv.groups,\n",
    "                              bias=True)\n",
    "        self.conv.weight.data = conv_weight_hat #fill in\n",
    "        self.conv.bias.data   = conv_bias_hat\n",
    "\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1, dilation=1, stride=1, groups=1, is_bn=True):\n",
    "        super(ConvBn2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride, dilation=dilation, groups=groups, bias=False)\n",
    "        self.bn   = nn.BatchNorm2d(out_channels, eps=BN_EPS)\n",
    "\n",
    "        if is_bn is False:\n",
    "            self.bn =None\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self ):\n",
    "        super(Net,self).__init__()\n",
    "        self.resnet = ResNet(BasicBlock, [3, 4, 6, 3], num_classes=1 )\n",
    "\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3, bias=False),\n",
    "            BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            self.resnet.layer1,\n",
    "        )\n",
    "        self.encoder3 = self.resnet.layer2\n",
    "        self.encoder4 = self.resnet.layer3\n",
    "        self.encoder5 = self.resnet.layer4\n",
    "\n",
    "        self.center = nn.Sequential(\n",
    "            ConvBn2d( 512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ConvBn2d( 512, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.decoder5 = Decoder(256, 512, 512, 64)\n",
    "        self.decoder4 = Decoder( 64, 256, 256, 64)\n",
    "        self.decoder3 = Decoder( 64, 128, 128, 64)\n",
    "        self.decoder2 = Decoder( 64,  64,  64, 64)\n",
    "        self.decoder1 = Decoder( 64,  64,  32, 64)\n",
    "\n",
    "        self.logit_pixel  = nn.Sequential(\n",
    "            nn.Conv2d(320, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d( 64,  1, kernel_size=1, padding=0),\n",
    "        )\n",
    "\n",
    "        self.logit_image = nn.Sequential(\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size,C,H,W = x.shape\n",
    "\n",
    "        mean=[0.485, 0.456, 0.406]\n",
    "        std =[0.229, 0.224, 0.225]\n",
    "        x = torch.cat([\n",
    "            (x-mean[2])/std[2],\n",
    "            (x-mean[1])/std[1],\n",
    "            (x-mean[0])/std[0],\n",
    "        ],1)\n",
    "\n",
    "\n",
    "        e1 = self.encoder1(x )  #; print('e1',e1.size())\n",
    "        e2 = self.encoder2(e1)  #; print('e2',e2.size())\n",
    "        e3 = self.encoder3(e2)  #; print('e3',e3.size())\n",
    "        e4 = self.encoder4(e3)  #; print('e4',e4.size())\n",
    "        e5 = self.encoder5(e4)  #; print('e5',e5.size())\n",
    "\n",
    "        f = self.center(e5)                #; print('f',f.size())\n",
    "\n",
    "        d5 = self.decoder5( f,e5)          #; print('d5',f.size())\n",
    "        d4 = self.decoder4(d5,e4)          #; print('d4',f.size())\n",
    "        d3 = self.decoder3(d4,e3)          #; print('d3',f.size())\n",
    "        d2 = self.decoder2(d3,e2)          #; print('d2',f.size())\n",
    "        d1 = self.decoder1(d2,e1)          #; print('d1',f.size())\n",
    "\n",
    "        f = torch.cat((\n",
    "            d1,\n",
    "            F.upsample(d2,scale_factor= 2, mode='bilinear',align_corners=False),\n",
    "            F.upsample(d3,scale_factor= 4, mode='bilinear',align_corners=False),\n",
    "            F.upsample(d4,scale_factor= 8, mode='bilinear',align_corners=False),\n",
    "            F.upsample(d5,scale_factor=16, mode='bilinear',align_corners=False),\n",
    "        ),1)\n",
    "        f = F.dropout(f, p=0.50, training=self.training)\n",
    "        logit_pixel = self.logit_pixel(f)\n",
    "\n",
    "\n",
    "        f = F.adaptive_avg_pool2d(e5, output_size=1).view(batch_size,-1)\n",
    "        f = F.dropout(f, p=0.50, training=self.training)\n",
    "        logit_image = self.logit_image(f).view(-1)\n",
    "\n",
    "        return logit_pixel, logit_image\n",
    "\n",
    "\n",
    "    ##-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "    def criterion(self, logit_pixel, logit_image, truth_pixel, truth_image, is_average=True):\n",
    "        weight_image, weight_pixel = 1, 1\n",
    "\n",
    "        loss_image = F.binary_cross_entropy_with_logits(logit_image, truth_image, reduce=is_average)\n",
    "\n",
    "        #--\n",
    "        loss_pixel = lovasz_loss(logit_pixel, truth_pixel, mode='logistic', is_average=False)\n",
    "        #loss_pixel = lovasz_loss(logit_pixel, truth_pixel, mode='hinge', is_average=False)\n",
    "        #loss_pixel = PseudoBCELoss2d()(logit_pixel, truth_pixel, is_average=False)\n",
    "        #loss_pixel = FocalLoss2d()(logit_pixel, truth_pixel, type='sigmoid', is_average=False)\n",
    "\n",
    "        #--\n",
    "        loss_pixel = loss_pixel*truth_image #loss for empty image is weighted 0\n",
    "        if is_average:\n",
    "            loss_pixel = loss_pixel.sum()/truth_image.sum()\n",
    "\n",
    "\n",
    "        #weight_image, weight_pixel = 0.1, 10  #focal\n",
    "        weight_image, weight_pixel = 0.1, 2   #lovasz?\n",
    "        #weight_image, weight_pixel = 0.1, 2 #bce\n",
    "\n",
    "        return weight_pixel*loss_pixel, weight_image*loss_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "\n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Decoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5fcf48cdbad3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-c8fe929a4cd2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m         )\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Decoder' is not defined"
     ]
    }
   ],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of training/testing ids and depths\n",
    "train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)\n",
    "\n",
    "train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)\n",
    "train_df['empty'] = train_df['masks'].apply(lambda x: (x.max()!=0) * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['empty'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET = len(train_df)\n",
    "train_df = train_df.head(SUBSET)\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test, empty_train, empty_test = train_test_split(\n",
    "train_df.index.values,\n",
    "np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "train_df.coverage.values,\n",
    "train_df.z.values,\n",
    "train_df['empty'].values,\n",
    "test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data augmentation\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "empty_train = np.append(empty_train, empty_train, axis=0)\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)\n",
    "print(empty_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_feature = 32\n",
    "batch_size = 32\n",
    "dropout = 0.5\n",
    "base_name = 'Unet_resnet_3loss_{}_{}_{}'.format(start_feature, batch_size, dropout)\n",
    "basic_name = '../model/{}'.format(base_name)\n",
    "save_model_name = basic_name + '.model'\n",
    "submission_file = basic_name + '.csv'\n",
    "\n",
    "print(save_model_name)\n",
    "print(submission_file)\n",
    "\n",
    "# model\n",
    "input_layer = Input((img_size_target, img_size_target, 1))\n",
    "output_layer, out_empty, out_final = build_model_deeper(input_layer, start_feature,dropout)\n",
    "\n",
    "model1 = Model(input_layer, [output_layer, out_empty, out_final])\n",
    "\n",
    "losses = {\n",
    "    'empty_out' : 'binary_crossentropy',\n",
    "    'segment_out':lovasz_loss,\n",
    "    #'final_out' : lovasz_loss,\n",
    "}\n",
    "lossWeights = {\n",
    "    'empty_out' : 0.2,\n",
    "    'segment_out':2,\n",
    "    #'final_out' : 3,\n",
    "}\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "model1.compile(loss=losses, loss_weights=lossWeights, optimizer=c, metrics=[my_iou_metric_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_combine_rain = {\n",
    "    'empty_out' : empty_train,\n",
    "    'segment_out':y_train,\n",
    "    #'final_out' : y_train,\n",
    "}\n",
    "\n",
    "y_combine_test = {\n",
    "    'empty_out' : empty_test,\n",
    "    'segment_out':y_valid,\n",
    "    #'final_out' : y_valid,\n",
    "}\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "board = keras.callbacks.TensorBoard(log_dir='log/{}'.format(base_name),\n",
    "                       histogram_freq=0, write_graph=True, write_images=False)\n",
    "early_stopping = EarlyStopping(monitor='val_final_out_my_iou_metric_2', mode = 'max',patience=20, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_segment_out_my_iou_metric_2', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_final_out_my_iou_metric_2', mode = 'max',factor=0.5, patience=3, min_lr=0.00001, verbose=1)\n",
    "\n",
    "\n",
    "history = model1.fit(x_train, y_combine_rain,\n",
    "                    validation_data=[x_valid, y_combine_test], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[board, early_stopping, model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n",
    "                                                   'lovasz_loss': lovasz_loss})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = predict_result(model,x_valid,img_size_target)\n",
    "## Scoring for last model, choose threshold by validation data \n",
    "thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
    "# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
    "thresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n",
    "\n",
    "# ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "# print(ious)\n",
    "ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "print(ious)\n",
    "\n",
    "# instead of using default 0 as threshold, use validation data to find the best threshold.\n",
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)\n",
    "\n",
    "preds_test = predict_result(model,x_test,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "pred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "t2 = time.time()\n",
    "\n",
    "print(f\"Usedtime = {t2-t1} s\")\n",
    "\n",
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub = sub.reset_index()\n",
    "save_result(sub, '../result/{}.csv'.format(base_name), \n",
    "                        competition = 'tgs-salt-identification-challenge', \n",
    "                        send = True, index = False)\n",
    "\n",
    "t_finish = time.time()\n",
    "print(f\"Kernel run time = {(t_finish-t_start)/3600} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
