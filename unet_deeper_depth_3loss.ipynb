{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook #, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n",
    "\n",
    "import time\n",
    "from kaggle_util import *\n",
    "from models import *\n",
    "\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "\n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n",
    "\n",
    "def build_model_deeper(input_layer, start_neurons, DropoutRatio = 0.5):\n",
    "    # 101 -> 50\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1, True)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "    # 50 -> 25\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2, True)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "    # 25 -> 12\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4, True)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "    # 12 -> 6\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8, True)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = residual_block(convm,start_neurons * 16, True)\n",
    "    \n",
    "    # 6 -> 12\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n",
    "    \n",
    "    # 12 -> 25\n",
    "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])    \n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n",
    "\n",
    "    # 25 -> 50\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "        \n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n",
    "    \n",
    "    # 50 -> 101\n",
    "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n",
    "    \n",
    "    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
    "    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation='relu')(uconv1)\n",
    "    \n",
    "#     output_layer =  Activation('sigmoid', name = 'segment_out')(output_layer)\n",
    "\n",
    "    ga = GlobalAveragePooling2D()(convm)\n",
    "    ga = Dropout(DropoutRatio)(ga)\n",
    "    empty = Dense(256, kernel_initializer='he_uniform')(ga)\n",
    "    empty = BatchActivate(empty)\n",
    "    empty = Dropout(DropoutRatio)(empty)\n",
    "    empty = Dense(64, kernel_initializer='he_uniform')(empty)\n",
    "    empty = BatchActivate(empty)\n",
    "    empty = Dropout(DropoutRatio)(empty)\n",
    "    out_empty = Dense(1, activation='sigmoid', name='empty_out')(empty)\n",
    "    \n",
    "    final_out_noact = multiply([output_layer, out_empty])\n",
    "    final_out_noact = BatchNormalization()(final_out_noact)\n",
    "    final_out =  Activation('sigmoid', name = 'segment_out')(final_out_noact)\n",
    "#     final_out = output_layer\n",
    "    \n",
    "    return final_out, out_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce016a0d9ca4361a890473200ef1b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca69a5ad93df4b47b49299293af31441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kownse/.local/lib/python3.6/site-packages/keras_preprocessing/image.py:487: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading of training/testing ids and depths\n",
    "train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)\n",
    "\n",
    "train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=False)) / 255 for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)\n",
    "train_df['empty'] = train_df['masks'].apply(lambda x: (x.max()!=0) * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_max = train_df['z'].max()\n",
    "z_min = train_df['z'].min()\n",
    "z_dis = z_max - z_min\n",
    "train_df['z'] = (train_df['z'] - z_min) / z_dis\n",
    "step = 1 / z_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2438\n",
       "0    1562\n",
       "Name: empty, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['empty'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBSET = len(train_df)\n",
    "train_df = train_df.head(SUBSET)\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test, empty_train, empty_test = train_test_split(\n",
    "train_df.index.values,\n",
    "np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 3), \n",
    "np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "train_df.coverage.values,\n",
    "train_df.z.values,\n",
    "train_df['empty'].values,\n",
    "test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 101, 101, 3)\n",
      "(800, 101, 101, 1)\n",
      "(6400,)\n"
     ]
    }
   ],
   "source": [
    "#Data augmentation\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "depth_train = np.append(depth_train, depth_train, axis=0)\n",
    "empty_train = np.append(empty_train, empty_train, axis=0)\n",
    "\n",
    "# x_train = add_depth_bulk_act(x_train, depth_train, step)\n",
    "# x_valid = add_depth_bulk_act(x_valid, depth_test, step)\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)\n",
    "print(empty_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "../model/Unet_resnet_3loss_depth_32_32_0.5.csv\n"
     ]
    }
   ],
   "source": [
    "start_feature = 32\n",
    "batch_size = 32\n",
    "dropout = 0.5\n",
    "base_name = 'Unet_resnet_3loss_depth_{}_{}_{}'.format(start_feature, batch_size, dropout)\n",
    "basic_name = '../model/{}'.format(base_name)\n",
    "save_model_name = basic_name + '.model'\n",
    "submission_file = basic_name + '.csv'\n",
    "\n",
    "print(save_model_name)\n",
    "print(submission_file)\n",
    "\n",
    "# model\n",
    "input_layer = Input((img_size_target, img_size_target, 3))\n",
    "output_layer, out_empty = build_model_deeper(input_layer, start_feature,dropout)\n",
    "\n",
    "model1 = Model(input_layer, [output_layer, out_empty])\n",
    "\n",
    "losses = {\n",
    "    'empty_out' : 'binary_crossentropy',\n",
    "    'segment_out': 'binary_crossentropy',\n",
    "    #'final_out' : lovasz_loss,\n",
    "}\n",
    "lossWeights = {\n",
    "    'empty_out' : 0.2,\n",
    "    'segment_out':2,\n",
    "    #'final_out' : 3,\n",
    "}\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "model1.compile(loss=losses, loss_weights=lossWeights, optimizer=c, metrics=[my_iou_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/200\n",
      "6400/6400 [==============================] - 72s 11ms/step - loss: 1.0490 - segment_out_loss: 0.4593 - empty_out_loss: 0.6517 - segment_out_my_iou_metric: 0.4142 - empty_out_my_iou_metric: 0.6366 - val_loss: 3.2027 - val_segment_out_loss: 0.6181 - val_empty_out_loss: 9.8320 - val_segment_out_my_iou_metric: 0.3900 - val_empty_out_my_iou_metric: 0.3900\n",
      "\n",
      "Epoch 00001: val_segment_out_my_iou_metric improved from -inf to 0.39000, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 2/200\n",
      "6400/6400 [==============================] - 59s 9ms/step - loss: 0.9357 - segment_out_loss: 0.4097 - empty_out_loss: 0.5811 - segment_out_my_iou_metric: 0.4872 - empty_out_my_iou_metric: 0.6831 - val_loss: 1.4451 - val_segment_out_loss: 0.6420 - val_empty_out_loss: 0.8057 - val_segment_out_my_iou_metric: 0.3900 - val_empty_out_my_iou_metric: 0.3900\n",
      "\n",
      "Epoch 00002: val_segment_out_my_iou_metric did not improve from 0.39000\n",
      "Epoch 3/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.7812 - segment_out_loss: 0.3372 - empty_out_loss: 0.5341 - segment_out_my_iou_metric: 0.5509 - empty_out_my_iou_metric: 0.7516 - val_loss: 2.0695 - val_segment_out_loss: 0.7712 - val_empty_out_loss: 2.6351 - val_segment_out_my_iou_metric: 0.3887 - val_empty_out_my_iou_metric: 0.4088\n",
      "\n",
      "Epoch 00003: val_segment_out_my_iou_metric did not improve from 0.39000\n",
      "Epoch 4/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.6868 - segment_out_loss: 0.2933 - empty_out_loss: 0.5007 - segment_out_my_iou_metric: 0.5753 - empty_out_my_iou_metric: 0.7678 - val_loss: 0.8407 - val_segment_out_loss: 0.3399 - val_empty_out_loss: 0.8044 - val_segment_out_my_iou_metric: 0.5604 - val_empty_out_my_iou_metric: 0.7025\n",
      "\n",
      "Epoch 00004: val_segment_out_my_iou_metric improved from 0.39000 to 0.56038, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 5/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.6696 - segment_out_loss: 0.2836 - empty_out_loss: 0.5119 - segment_out_my_iou_metric: 0.5841 - empty_out_my_iou_metric: 0.7356 - val_loss: 0.7433 - val_segment_out_loss: 0.3219 - val_empty_out_loss: 0.4973 - val_segment_out_my_iou_metric: 0.4489 - val_empty_out_my_iou_metric: 0.7650\n",
      "\n",
      "Epoch 00005: val_segment_out_my_iou_metric did not improve from 0.56038\n",
      "Epoch 6/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.6343 - segment_out_loss: 0.2696 - empty_out_loss: 0.4754 - segment_out_my_iou_metric: 0.5810 - empty_out_my_iou_metric: 0.7584 - val_loss: 0.8027 - val_segment_out_loss: 0.3395 - val_empty_out_loss: 0.6186 - val_segment_out_my_iou_metric: 0.5859 - val_empty_out_my_iou_metric: 0.6587\n",
      "\n",
      "Epoch 00006: val_segment_out_my_iou_metric improved from 0.56038 to 0.58588, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 7/200\n",
      "6400/6400 [==============================] - 59s 9ms/step - loss: 0.5910 - segment_out_loss: 0.2491 - empty_out_loss: 0.4636 - segment_out_my_iou_metric: 0.6044 - empty_out_my_iou_metric: 0.7586 - val_loss: 0.6482 - val_segment_out_loss: 0.2716 - val_empty_out_loss: 0.5249 - val_segment_out_my_iou_metric: 0.5774 - val_empty_out_my_iou_metric: 0.6763\n",
      "\n",
      "Epoch 00007: val_segment_out_my_iou_metric did not improve from 0.58588\n",
      "Epoch 8/200\n",
      "6400/6400 [==============================] - 59s 9ms/step - loss: 0.5926 - segment_out_loss: 0.2510 - empty_out_loss: 0.4528 - segment_out_my_iou_metric: 0.6053 - empty_out_my_iou_metric: 0.7712 - val_loss: 0.9130 - val_segment_out_loss: 0.4043 - val_empty_out_loss: 0.5224 - val_segment_out_my_iou_metric: 0.4980 - val_empty_out_my_iou_metric: 0.6863\n",
      "\n",
      "Epoch 00008: val_segment_out_my_iou_metric did not improve from 0.58588\n",
      "Epoch 9/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.5579 - segment_out_loss: 0.2346 - empty_out_loss: 0.4436 - segment_out_my_iou_metric: 0.6053 - empty_out_my_iou_metric: 0.7600 - val_loss: 0.7104 - val_segment_out_loss: 0.3098 - val_empty_out_loss: 0.4540 - val_segment_out_my_iou_metric: 0.5546 - val_empty_out_my_iou_metric: 0.7913\n",
      "\n",
      "Epoch 00009: val_segment_out_my_iou_metric did not improve from 0.58588\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 10/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.4881 - segment_out_loss: 0.2042 - empty_out_loss: 0.3979 - segment_out_my_iou_metric: 0.6558 - empty_out_my_iou_metric: 0.7758 - val_loss: 1.1798 - val_segment_out_loss: 0.4971 - val_empty_out_loss: 0.9278 - val_segment_out_my_iou_metric: 0.5356 - val_empty_out_my_iou_metric: 0.6562\n",
      "\n",
      "Epoch 00010: val_segment_out_my_iou_metric did not improve from 0.58588\n",
      "Epoch 11/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.4817 - segment_out_loss: 0.2020 - empty_out_loss: 0.3881 - segment_out_my_iou_metric: 0.6570 - empty_out_my_iou_metric: 0.7919 - val_loss: 0.5946 - val_segment_out_loss: 0.2501 - val_empty_out_loss: 0.4714 - val_segment_out_my_iou_metric: 0.6010 - val_empty_out_my_iou_metric: 0.7525\n",
      "\n",
      "Epoch 00011: val_segment_out_my_iou_metric improved from 0.58588 to 0.60100, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 12/200\n",
      "6400/6400 [==============================] - 59s 9ms/step - loss: 0.4657 - segment_out_loss: 0.1953 - empty_out_loss: 0.3757 - segment_out_my_iou_metric: 0.6748 - empty_out_my_iou_metric: 0.8020 - val_loss: 0.5906 - val_segment_out_loss: 0.2457 - val_empty_out_loss: 0.4964 - val_segment_out_my_iou_metric: 0.6312 - val_empty_out_my_iou_metric: 0.7512\n",
      "\n",
      "Epoch 00012: val_segment_out_my_iou_metric improved from 0.60100 to 0.63125, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 13/200\n",
      "6400/6400 [==============================] - 59s 9ms/step - loss: 0.4485 - segment_out_loss: 0.1873 - empty_out_loss: 0.3698 - segment_out_my_iou_metric: 0.6890 - empty_out_my_iou_metric: 0.8283 - val_loss: 0.4551 - val_segment_out_loss: 0.1807 - val_empty_out_loss: 0.4683 - val_segment_out_my_iou_metric: 0.7076 - val_empty_out_my_iou_metric: 0.7950\n",
      "\n",
      "Epoch 00013: val_segment_out_my_iou_metric improved from 0.63125 to 0.70763, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 14/200\n",
      "6400/6400 [==============================] - 59s 9ms/step - loss: 0.4296 - segment_out_loss: 0.1789 - empty_out_loss: 0.3588 - segment_out_my_iou_metric: 0.7000 - empty_out_my_iou_metric: 0.8327 - val_loss: 0.5272 - val_segment_out_loss: 0.2243 - val_empty_out_loss: 0.3929 - val_segment_out_my_iou_metric: 0.6865 - val_empty_out_my_iou_metric: 0.8237\n",
      "\n",
      "Epoch 00014: val_segment_out_my_iou_metric did not improve from 0.70763\n",
      "Epoch 15/200\n",
      "6400/6400 [==============================] - 59s 9ms/step - loss: 0.4342 - segment_out_loss: 0.1817 - empty_out_loss: 0.3543 - segment_out_my_iou_metric: 0.6968 - empty_out_my_iou_metric: 0.8377 - val_loss: 0.5266 - val_segment_out_loss: 0.2085 - val_empty_out_loss: 0.5479 - val_segment_out_my_iou_metric: 0.6218 - val_empty_out_my_iou_metric: 0.7525\n",
      "\n",
      "Epoch 00015: val_segment_out_my_iou_metric did not improve from 0.70763\n",
      "Epoch 16/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.4000 - segment_out_loss: 0.1667 - empty_out_loss: 0.3326 - segment_out_my_iou_metric: 0.7114 - empty_out_my_iou_metric: 0.8539 - val_loss: 0.4113 - val_segment_out_loss: 0.1699 - val_empty_out_loss: 0.3574 - val_segment_out_my_iou_metric: 0.7110 - val_empty_out_my_iou_metric: 0.8137\n",
      "\n",
      "Epoch 00016: val_segment_out_my_iou_metric improved from 0.70763 to 0.71100, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 17/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.3893 - segment_out_loss: 0.1617 - empty_out_loss: 0.3292 - segment_out_my_iou_metric: 0.7223 - empty_out_my_iou_metric: 0.8489 - val_loss: 0.5197 - val_segment_out_loss: 0.2217 - val_empty_out_loss: 0.3813 - val_segment_out_my_iou_metric: 0.6960 - val_empty_out_my_iou_metric: 0.8263\n",
      "\n",
      "Epoch 00017: val_segment_out_my_iou_metric did not improve from 0.71100\n",
      "Epoch 18/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.3832 - segment_out_loss: 0.1592 - empty_out_loss: 0.3241 - segment_out_my_iou_metric: 0.7246 - empty_out_my_iou_metric: 0.8550 - val_loss: 0.3889 - val_segment_out_loss: 0.1613 - val_empty_out_loss: 0.3317 - val_segment_out_my_iou_metric: 0.7334 - val_empty_out_my_iou_metric: 0.8475\n",
      "\n",
      "Epoch 00018: val_segment_out_my_iou_metric improved from 0.71100 to 0.73338, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 19/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.3757 - segment_out_loss: 0.1570 - empty_out_loss: 0.3086 - segment_out_my_iou_metric: 0.7257 - empty_out_my_iou_metric: 0.8678 - val_loss: 1.6624 - val_segment_out_loss: 0.7152 - val_empty_out_loss: 1.1602 - val_segment_out_my_iou_metric: 0.4734 - val_empty_out_my_iou_metric: 0.6175\n",
      "\n",
      "Epoch 00019: val_segment_out_my_iou_metric did not improve from 0.73338\n",
      "Epoch 20/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.3867 - segment_out_loss: 0.1614 - empty_out_loss: 0.3195 - segment_out_my_iou_metric: 0.7158 - empty_out_my_iou_metric: 0.8575 - val_loss: 0.3982 - val_segment_out_loss: 0.1691 - val_empty_out_loss: 0.2997 - val_segment_out_my_iou_metric: 0.7286 - val_empty_out_my_iou_metric: 0.8712\n",
      "\n",
      "Epoch 00020: val_segment_out_my_iou_metric did not improve from 0.73338\n",
      "Epoch 21/200\n",
      "6400/6400 [==============================] - 59s 9ms/step - loss: 0.3809 - segment_out_loss: 0.1590 - empty_out_loss: 0.3145 - segment_out_my_iou_metric: 0.7328 - empty_out_my_iou_metric: 0.8558 - val_loss: 0.4398 - val_segment_out_loss: 0.1842 - val_empty_out_loss: 0.3567 - val_segment_out_my_iou_metric: 0.7077 - val_empty_out_my_iou_metric: 0.8462\n",
      "\n",
      "Epoch 00021: val_segment_out_my_iou_metric did not improve from 0.73338\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 22/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.3391 - segment_out_loss: 0.1395 - empty_out_loss: 0.3012 - segment_out_my_iou_metric: 0.7494 - empty_out_my_iou_metric: 0.8647 - val_loss: 0.3869 - val_segment_out_loss: 0.1645 - val_empty_out_loss: 0.2892 - val_segment_out_my_iou_metric: 0.7394 - val_empty_out_my_iou_metric: 0.8800\n",
      "\n",
      "Epoch 00022: val_segment_out_my_iou_metric improved from 0.73338 to 0.73938, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 23/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.3337 - segment_out_loss: 0.1381 - empty_out_loss: 0.2877 - segment_out_my_iou_metric: 0.7517 - empty_out_my_iou_metric: 0.8786 - val_loss: 0.3697 - val_segment_out_loss: 0.1558 - val_empty_out_loss: 0.2902 - val_segment_out_my_iou_metric: 0.7465 - val_empty_out_my_iou_metric: 0.8762\n",
      "\n",
      "Epoch 00023: val_segment_out_my_iou_metric improved from 0.73938 to 0.74650, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 24/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.3162 - segment_out_loss: 0.1310 - empty_out_loss: 0.2712 - segment_out_my_iou_metric: 0.7615 - empty_out_my_iou_metric: 0.8819 - val_loss: 0.3456 - val_segment_out_loss: 0.1450 - val_empty_out_loss: 0.2777 - val_segment_out_my_iou_metric: 0.7555 - val_empty_out_my_iou_metric: 0.8750\n",
      "\n",
      "Epoch 00024: val_segment_out_my_iou_metric improved from 0.74650 to 0.75550, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 25/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.3106 - segment_out_loss: 0.1277 - empty_out_loss: 0.2763 - segment_out_my_iou_metric: 0.7593 - empty_out_my_iou_metric: 0.8855 - val_loss: 0.3443 - val_segment_out_loss: 0.1426 - val_empty_out_loss: 0.2958 - val_segment_out_my_iou_metric: 0.7593 - val_empty_out_my_iou_metric: 0.8588\n",
      "\n",
      "Epoch 00025: val_segment_out_my_iou_metric improved from 0.75550 to 0.75925, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 26/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.3066 - segment_out_loss: 0.1267 - empty_out_loss: 0.2654 - segment_out_my_iou_metric: 0.7669 - empty_out_my_iou_metric: 0.8837 - val_loss: 0.3541 - val_segment_out_loss: 0.1499 - val_empty_out_loss: 0.2712 - val_segment_out_my_iou_metric: 0.7569 - val_empty_out_my_iou_metric: 0.8888\n",
      "\n",
      "Epoch 00026: val_segment_out_my_iou_metric did not improve from 0.75925\n",
      "Epoch 27/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.3092 - segment_out_loss: 0.1280 - empty_out_loss: 0.2661 - segment_out_my_iou_metric: 0.7645 - empty_out_my_iou_metric: 0.8887 - val_loss: 0.3570 - val_segment_out_loss: 0.1502 - val_empty_out_loss: 0.2833 - val_segment_out_my_iou_metric: 0.7583 - val_empty_out_my_iou_metric: 0.8838\n",
      "\n",
      "Epoch 00027: val_segment_out_my_iou_metric did not improve from 0.75925\n",
      "Epoch 28/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.3017 - segment_out_loss: 0.1247 - empty_out_loss: 0.2613 - segment_out_my_iou_metric: 0.7678 - empty_out_my_iou_metric: 0.8894 - val_loss: 0.3901 - val_segment_out_loss: 0.1639 - val_empty_out_loss: 0.3117 - val_segment_out_my_iou_metric: 0.7395 - val_empty_out_my_iou_metric: 0.8538\n",
      "\n",
      "Epoch 00028: val_segment_out_my_iou_metric did not improve from 0.75925\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 29/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2809 - segment_out_loss: 0.1157 - empty_out_loss: 0.2477 - segment_out_my_iou_metric: 0.7777 - empty_out_my_iou_metric: 0.8966 - val_loss: 0.3341 - val_segment_out_loss: 0.1401 - val_empty_out_loss: 0.2694 - val_segment_out_my_iou_metric: 0.7663 - val_empty_out_my_iou_metric: 0.8788\n",
      "\n",
      "Epoch 00029: val_segment_out_my_iou_metric improved from 0.75925 to 0.76625, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 30/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2778 - segment_out_loss: 0.1145 - empty_out_loss: 0.2445 - segment_out_my_iou_metric: 0.7815 - empty_out_my_iou_metric: 0.8997 - val_loss: 0.3342 - val_segment_out_loss: 0.1388 - val_empty_out_loss: 0.2827 - val_segment_out_my_iou_metric: 0.7641 - val_empty_out_my_iou_metric: 0.8750\n",
      "\n",
      "Epoch 00030: val_segment_out_my_iou_metric did not improve from 0.76625\n",
      "Epoch 31/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2759 - segment_out_loss: 0.1136 - empty_out_loss: 0.2431 - segment_out_my_iou_metric: 0.7818 - empty_out_my_iou_metric: 0.8975 - val_loss: 0.3636 - val_segment_out_loss: 0.1551 - val_empty_out_loss: 0.2664 - val_segment_out_my_iou_metric: 0.7640 - val_empty_out_my_iou_metric: 0.8675\n",
      "\n",
      "Epoch 00031: val_segment_out_my_iou_metric did not improve from 0.76625\n",
      "Epoch 32/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2656 - segment_out_loss: 0.1099 - empty_out_loss: 0.2291 - segment_out_my_iou_metric: 0.7814 - empty_out_my_iou_metric: 0.9072 - val_loss: 0.3547 - val_segment_out_loss: 0.1514 - val_empty_out_loss: 0.2596 - val_segment_out_my_iou_metric: 0.7697 - val_empty_out_my_iou_metric: 0.8862\n",
      "\n",
      "Epoch 00032: val_segment_out_my_iou_metric improved from 0.76625 to 0.76975, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 33/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2598 - segment_out_loss: 0.1069 - empty_out_loss: 0.2302 - segment_out_my_iou_metric: 0.7887 - empty_out_my_iou_metric: 0.9092 - val_loss: 0.3402 - val_segment_out_loss: 0.1436 - val_empty_out_loss: 0.2647 - val_segment_out_my_iou_metric: 0.7711 - val_empty_out_my_iou_metric: 0.8738\n",
      "\n",
      "Epoch 00033: val_segment_out_my_iou_metric improved from 0.76975 to 0.77112, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 34/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2628 - segment_out_loss: 0.1084 - empty_out_loss: 0.2296 - segment_out_my_iou_metric: 0.7865 - empty_out_my_iou_metric: 0.9056 - val_loss: 0.3372 - val_segment_out_loss: 0.1405 - val_empty_out_loss: 0.2807 - val_segment_out_my_iou_metric: 0.7665 - val_empty_out_my_iou_metric: 0.8738\n",
      "\n",
      "Epoch 00036: val_segment_out_my_iou_metric did not improve from 0.77112\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 37/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2495 - segment_out_loss: 0.1032 - empty_out_loss: 0.2158 - segment_out_my_iou_metric: 0.7947 - empty_out_my_iou_metric: 0.9159 - val_loss: 0.3089 - val_segment_out_loss: 0.1272 - val_empty_out_loss: 0.2723 - val_segment_out_my_iou_metric: 0.7803 - val_empty_out_my_iou_metric: 0.8762\n",
      "\n",
      "Epoch 00037: val_segment_out_my_iou_metric improved from 0.77112 to 0.78025, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 38/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2333 - segment_out_loss: 0.0957 - empty_out_loss: 0.2092 - segment_out_my_iou_metric: 0.7989 - empty_out_my_iou_metric: 0.9186 - val_loss: 0.3521 - val_segment_out_loss: 0.1429 - val_empty_out_loss: 0.3312 - val_segment_out_my_iou_metric: 0.7770 - val_empty_out_my_iou_metric: 0.8762\n",
      "\n",
      "Epoch 00040: val_segment_out_my_iou_metric did not improve from 0.78025\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 41/200\n",
      "6400/6400 [==============================] - 59s 9ms/step - loss: 0.2263 - segment_out_loss: 0.0927 - empty_out_loss: 0.2041 - segment_out_my_iou_metric: 0.8003 - empty_out_my_iou_metric: 0.9178 - val_loss: 0.3252 - val_segment_out_loss: 0.1363 - val_empty_out_loss: 0.2626 - val_segment_out_my_iou_metric: 0.7796 - val_empty_out_my_iou_metric: 0.8838\n",
      "\n",
      "Epoch 00041: val_segment_out_my_iou_metric did not improve from 0.78025\n",
      "Epoch 42/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2333 - segment_out_loss: 0.0960 - empty_out_loss: 0.2060 - segment_out_my_iou_metric: 0.8013 - empty_out_my_iou_metric: 0.9184 - val_loss: 0.3226 - val_segment_out_loss: 0.1347 - val_empty_out_loss: 0.2659 - val_segment_out_my_iou_metric: 0.7830 - val_empty_out_my_iou_metric: 0.8850\n",
      "\n",
      "Epoch 00042: val_segment_out_my_iou_metric improved from 0.78025 to 0.78300, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 43/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2233 - segment_out_loss: 0.0913 - empty_out_loss: 0.2032 - segment_out_my_iou_metric: 0.8016 - empty_out_my_iou_metric: 0.9194 - val_loss: 0.3182 - val_segment_out_loss: 0.1334 - val_empty_out_loss: 0.2569 - val_segment_out_my_iou_metric: 0.7777 - val_empty_out_my_iou_metric: 0.8912\n",
      "\n",
      "Epoch 00043: val_segment_out_my_iou_metric did not improve from 0.78300\n",
      "Epoch 44/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2227 - segment_out_loss: 0.0913 - empty_out_loss: 0.2005 - segment_out_my_iou_metric: 0.8035 - empty_out_my_iou_metric: 0.9192 - val_loss: 0.3348 - val_segment_out_loss: 0.1404 - val_empty_out_loss: 0.2700 - val_segment_out_my_iou_metric: 0.7851 - val_empty_out_my_iou_metric: 0.8888\n",
      "\n",
      "Epoch 00044: val_segment_out_my_iou_metric improved from 0.78300 to 0.78513, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 45/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2187 - segment_out_loss: 0.0897 - empty_out_loss: 0.1969 - segment_out_my_iou_metric: 0.8067 - empty_out_my_iou_metric: 0.9247 - val_loss: 0.3180 - val_segment_out_loss: 0.1341 - val_empty_out_loss: 0.2486 - val_segment_out_my_iou_metric: 0.7806 - val_empty_out_my_iou_metric: 0.8862\n",
      "\n",
      "Epoch 00045: val_segment_out_my_iou_metric did not improve from 0.78513\n",
      "Epoch 46/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2163 - segment_out_loss: 0.0887 - empty_out_loss: 0.1942 - segment_out_my_iou_metric: 0.8071 - empty_out_my_iou_metric: 0.9216 - val_loss: 0.3426 - val_segment_out_loss: 0.1451 - val_empty_out_loss: 0.2626 - val_segment_out_my_iou_metric: 0.7835 - val_empty_out_my_iou_metric: 0.8862\n",
      "\n",
      "Epoch 00046: val_segment_out_my_iou_metric did not improve from 0.78513\n",
      "Epoch 47/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2126 - segment_out_loss: 0.0869 - empty_out_loss: 0.1940 - segment_out_my_iou_metric: 0.8075 - empty_out_my_iou_metric: 0.9267 - val_loss: 0.3372 - val_segment_out_loss: 0.1420 - val_empty_out_loss: 0.2657 - val_segment_out_my_iou_metric: 0.7831 - val_empty_out_my_iou_metric: 0.8912\n",
      "\n",
      "Epoch 00047: val_segment_out_my_iou_metric did not improve from 0.78513\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Epoch 48/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2058 - segment_out_loss: 0.0842 - empty_out_loss: 0.1868 - segment_out_my_iou_metric: 0.8109 - empty_out_my_iou_metric: 0.9286 - val_loss: 0.3270 - val_segment_out_loss: 0.1375 - val_empty_out_loss: 0.2598 - val_segment_out_my_iou_metric: 0.7847 - val_empty_out_my_iou_metric: 0.8900\n",
      "\n",
      "Epoch 00048: val_segment_out_my_iou_metric did not improve from 0.78513\n",
      "Epoch 49/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2071 - segment_out_loss: 0.0846 - empty_out_loss: 0.1897 - segment_out_my_iou_metric: 0.8085 - empty_out_my_iou_metric: 0.9280 - val_loss: 0.3326 - val_segment_out_loss: 0.1394 - val_empty_out_loss: 0.2691 - val_segment_out_my_iou_metric: 0.7819 - val_empty_out_my_iou_metric: 0.8875\n",
      "\n",
      "Epoch 00049: val_segment_out_my_iou_metric did not improve from 0.78513\n",
      "Epoch 50/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2134 - segment_out_loss: 0.0874 - empty_out_loss: 0.1931 - segment_out_my_iou_metric: 0.8088 - empty_out_my_iou_metric: 0.9239 - val_loss: 0.3271 - val_segment_out_loss: 0.1368 - val_empty_out_loss: 0.2672 - val_segment_out_my_iou_metric: 0.7834 - val_empty_out_my_iou_metric: 0.8825\n",
      "\n",
      "Epoch 00050: val_segment_out_my_iou_metric did not improve from 0.78513\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Epoch 51/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2090 - segment_out_loss: 0.0852 - empty_out_loss: 0.1926 - segment_out_my_iou_metric: 0.8081 - empty_out_my_iou_metric: 0.9225 - val_loss: 0.3271 - val_segment_out_loss: 0.1372 - val_empty_out_loss: 0.2632 - val_segment_out_my_iou_metric: 0.7869 - val_empty_out_my_iou_metric: 0.8862\n",
      "\n",
      "Epoch 00051: val_segment_out_my_iou_metric improved from 0.78513 to 0.78687, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 52/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2062 - segment_out_loss: 0.0842 - empty_out_loss: 0.1894 - segment_out_my_iou_metric: 0.8115 - empty_out_my_iou_metric: 0.9270 - val_loss: 0.3271 - val_segment_out_loss: 0.1372 - val_empty_out_loss: 0.2631 - val_segment_out_my_iou_metric: 0.7881 - val_empty_out_my_iou_metric: 0.8862\n",
      "\n",
      "Epoch 00052: val_segment_out_my_iou_metric improved from 0.78687 to 0.78813, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 53/200\n",
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.2034 - segment_out_loss: 0.0826 - empty_out_loss: 0.1912 - segment_out_my_iou_metric: 0.8090 - empty_out_my_iou_metric: 0.9241 - val_loss: 0.3233 - val_segment_out_loss: 0.1356 - val_empty_out_loss: 0.2604 - val_segment_out_my_iou_metric: 0.7883 - val_empty_out_my_iou_metric: 0.8850\n",
      "\n",
      "Epoch 00053: val_segment_out_my_iou_metric improved from 0.78813 to 0.78825, saving model to ../model/Unet_resnet_3loss_depth_32_32_0.5.model\n",
      "Epoch 54/200\n",
      "4736/6400 [=====================>........] - ETA: 14s - loss: 0.1964 - segment_out_loss: 0.0804 - empty_out_loss: 0.1777 - segment_out_my_iou_metric: 0.8174 - empty_out_my_iou_metric: 0.9301"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 60s 9ms/step - loss: 0.1971 - segment_out_loss: 0.0801 - empty_out_loss: 0.1844 - segment_out_my_iou_metric: 0.8131 - empty_out_my_iou_metric: 0.9270 - val_loss: 0.3290 - val_segment_out_loss: 0.1381 - val_empty_out_loss: 0.2638 - val_segment_out_my_iou_metric: 0.7893 - val_empty_out_my_iou_metric: 0.8888\n",
      "\n",
      "Epoch 00072: val_segment_out_my_iou_metric did not improve from 0.79037\n",
      "Epoch 00072: early stopping\n"
     ]
    }
   ],
   "source": [
    "y_combine_rain = {\n",
    "    'empty_out' : empty_train,\n",
    "    'segment_out':y_train,\n",
    "    #'final_out' : y_train,\n",
    "}\n",
    "\n",
    "y_combine_test = {\n",
    "    'empty_out' : empty_test,\n",
    "    'segment_out':y_valid,\n",
    "    #'final_out' : y_valid,\n",
    "}\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "board = keras.callbacks.TensorBoard(log_dir='log/{}'.format(base_name),\n",
    "                       histogram_freq=0, write_graph=True, write_images=False)\n",
    "early_stopping = EarlyStopping(monitor='val_segment_out_my_iou_metric', mode = 'max',patience=12, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_segment_out_my_iou_metric', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_segment_out_my_iou_metric', mode = 'max',factor=0.5, patience=3, min_lr=0.00001, verbose=1)\n",
    "\n",
    "\n",
    "history = model1.fit(x_train, y_combine_rain,\n",
    "                    validation_data=[x_valid, y_combine_test], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[board, early_stopping, model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = 'Unet_resnet_3loss_depth_{}_{}_{}'.format(start_feature, batch_size, dropout)\n",
    "basic_name = '../model/{}'.format(base_name)\n",
    "save_model_name = basic_name + '.model'\n",
    "\n",
    "model1 = load_model(save_model_name,custom_objects={'my_iou_metric': my_iou_metric})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/200\n",
      " 896/6400 [===>..........................] - ETA: 2:28 - loss: 0.5171 - segment_out_loss: 0.2223 - empty_out_loss: 0.3622 - segment_out_my_iou_metric_2: 0.7301 - empty_out_my_iou_metric_2: 0.6183"
     ]
    }
   ],
   "source": [
    "\n",
    "base_name = 'Unet_resnet_3loss_depth_stage2_{}_{}_{}'.format(start_feature, batch_size, dropout)\n",
    "basic_name = '../model/{}'.format(base_name)\n",
    "save_model_name = basic_name + '.model'\n",
    "submission_file = basic_name + '.csv'\n",
    "\n",
    "input_x = model1.layers[0].input\n",
    "model1.layers[-1].name = 'segment_out_old'\n",
    "\n",
    "output_layer = model1.layers[-2]\n",
    "output_layer.name = 'segment_out'\n",
    "output_layer = output_layer.output\n",
    "\n",
    "empty_out = model1.get_layer(\"empty_out\").output\n",
    "model = Model(input_x, [output_layer, empty_out])\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "\n",
    "losses = {\n",
    "    'empty_out' : 'binary_crossentropy',\n",
    "    'segment_out': lovasz_loss,\n",
    "    #'final_out' : lovasz_loss,\n",
    "}\n",
    "lossWeights = {\n",
    "    'empty_out' : 0.2,\n",
    "    'segment_out':2,\n",
    "    #'final_out' : 3,\n",
    "}\n",
    "model.compile(loss=losses, loss_weights=lossWeights, optimizer=c, metrics=[my_iou_metric_2])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_segment_out_my_iou_metric_2', mode = 'max',patience=16, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_segment_out_my_iou_metric_2', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_segment_out_my_iou_metric_2', mode = 'max',factor=0.5, patience=4, min_lr=0.00001, verbose=1)\n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_combine_rain,\n",
    "                    validation_data=[x_valid, y_combine_test], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[board, early_stopping, model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n",
    "                                                   'lovasz_loss': lovasz_loss})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = predict_result(model,x_valid,img_size_target)\n",
    "## Scoring for last model, choose threshold by validation data \n",
    "thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
    "# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
    "thresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n",
    "\n",
    "# ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "# print(ious)\n",
    "ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "print(ious)\n",
    "\n",
    "# instead of using default 0 as threshold, use validation data to find the best threshold.\n",
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)\n",
    "\n",
    "preds_test = predict_result(model,x_test,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "pred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "t2 = time.time()\n",
    "\n",
    "print(f\"Usedtime = {t2-t1} s\")\n",
    "\n",
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub = sub.reset_index()\n",
    "save_result(sub, '../result/{}.csv'.format(base_name), \n",
    "                        competition = 'tgs-salt-identification-challenge', \n",
    "                        send = True, index = False)\n",
    "\n",
    "t_finish = time.time()\n",
    "print(f\"Kernel run time = {(t_finish-t_start)/3600} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
