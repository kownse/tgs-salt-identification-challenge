{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from tqdm import tqdm #, tnrange\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add, Dense, Input, Dropout\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n",
    "\n",
    "import time\n",
    "from kaggle_util import *\n",
    "from models import *\n",
    "\n",
    "from albumentations import (\n",
    "    PadIfNeeded,\n",
    "    HorizontalFlip,\n",
    "    VerticalFlip,    \n",
    "    CenterCrop,    \n",
    "    Crop,\n",
    "    Compose,\n",
    "    Transpose,\n",
    "    RandomRotate90,\n",
    "    ElasticTransform,\n",
    "    GridDistortion, \n",
    "    OpticalDistortion,\n",
    "    RandomSizedCrop,\n",
    "    OneOf,\n",
    "    CLAHE,\n",
    "    RandomContrast,\n",
    "    RandomGamma,\n",
    "    RandomBrightness\n",
    ")\n",
    "\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "\n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n",
    "\n",
    "def get_model(BASE_MODEL):\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    if BASE_MODEL=='VGG16':\n",
    "        from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n",
    "    elif BASE_MODEL=='VGG19':\n",
    "        from keras.applications.vgg19 import VGG19 as PTModel, preprocess_input\n",
    "    elif BASE_MODEL=='RESNET52':\n",
    "        from keras.applications.resnet50 import ResNet50 as PTModel, preprocess_input\n",
    "    elif BASE_MODEL=='InceptionV3':\n",
    "        from keras.applications.inception_v3 import InceptionV3 as PTModel, preprocess_input\n",
    "    elif BASE_MODEL=='Xception':\n",
    "        from keras.applications.xception import Xception as PTModel, preprocess_input\n",
    "    elif BASE_MODEL=='DenseNet169': \n",
    "        from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\n",
    "    elif BASE_MODEL=='DenseNet121':\n",
    "        from keras.applications.densenet import DenseNet121 as PTModel, preprocess_input\n",
    "    elif BASE_MODEL=='InceptionResNetV2':\n",
    "        from keras.applications.inception_resnet_v2 import InceptionResNetV2 as PTModel, preprocess_input\n",
    "    else:\n",
    "        raise ValueError('Unknown model: {}'.format(BASE_MODEL))\n",
    "        \n",
    "    return PTModel, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of training/testing ids and depths\n",
    "train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)\n",
    "\n",
    "train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=False)) for idx in tqdm(train_df.index)]\n",
    "train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm(train_df.index)]\n",
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)\n",
    "train_df['hassalt'] = train_df['masks'].apply(lambda x: (x.max()!=0) * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splits(train_df, train_idx, val_idx):\n",
    "    X_train = train_df.iloc[train_idx]\n",
    "    X_valid = train_df.iloc[val_idx]\n",
    "    x_train = np.array(X_train.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 3)\n",
    "    x_valid = np.array(X_valid.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 3)\n",
    "    msk_train = np.array(X_train.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)\n",
    "    msk_val = np.array(X_valid.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)\n",
    "    y_train = X_train.hassalt.values\n",
    "    y_valid = X_valid.hassalt.values\n",
    "    id_train = X_train.index.values\n",
    "    id_valid = X_valid.index.values\n",
    "    return x_train, x_valid, msk_train, msk_val, y_train, y_valid, id_train, id_valid\n",
    "\n",
    "def argument(x_train, msk_train, y_train):\n",
    "    aug_img = []\n",
    "    aug_msk = []\n",
    "    aug_y = []\n",
    "    augments = [\n",
    "        (1, HorizontalFlip(p=1)),\n",
    "        (0.25, VerticalFlip(p=1)),\n",
    "        (0.25, RandomRotate90(p=1)),\n",
    "        (0.25, Transpose(p=1)),\n",
    "        (0.25, ElasticTransform(p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03)),\n",
    "        (0.25, GridDistortion(p=1)),\n",
    "        (0.25, OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)),\n",
    "#         (0.5, RandomSizedCrop(p=1, min_max_height=(int(img_size_ori / 2), img_size_ori), height=img_size_ori, width=img_size_ori)),\n",
    "    ]\n",
    "\n",
    "    for ratio, aug in tqdm(augments):\n",
    "        selidx = np.random.choice(x_train.shape[0], int(x_train.shape[0] * ratio), replace=False)\n",
    "        for idx in tqdm(selidx):\n",
    "            augmented = aug(image=x_train[idx], mask=msk_train[idx])\n",
    "            aimg = augmented['image']\n",
    "            amsk = augmented['mask']\n",
    "            if len(aimg.shape) < 3:\n",
    "                aimg = aimg[...,np.newaxis]\n",
    "            if len(amsk.shape) < 3:\n",
    "                amsk = amsk[...,np.newaxis]\n",
    "            aug_img.append(aimg)\n",
    "            aug_msk.append(amsk)\n",
    "            aug_y.append(y_train[idx])\n",
    "\n",
    "    aug_img = np.asarray(aug_img)\n",
    "    aug_msk = np.asarray(aug_msk)\n",
    "    aug_y = np.asarray(aug_y)\n",
    "    x_train = np.append(x_train, aug_img, axis=0)\n",
    "    msk_train = np.append(msk_train, aug_msk, axis=0)\n",
    "    y_train = np.append(y_train, aug_y, axis=0)\n",
    "    print(x_train.shape)\n",
    "    print(msk_train.shape)\n",
    "    print(y_train.shape)\n",
    "    \n",
    "    return x_train, msk_train, y_train\n",
    "\n",
    "def train_classifier(fold, model_name, x_train, y_train, x_valid, y_valid, id_valid):\n",
    "    print(model_name)\n",
    "    x_train_act = x_train\n",
    "    x_val_act = x_valid\n",
    "#     x_train_act = x_train.astype(np.float32)\n",
    "#     for idx in range(len(x_train_act)):\n",
    "#         x_train_act[idx] = preprocess_input(x_train_act[idx])\n",
    "#     print(x_train_act.max())\n",
    "\n",
    "#     x_val_act = x_valid.astype(np.float32)\n",
    "#     for idx in range(len(x_val_act)):\n",
    "#         x_val_act[idx] = preprocess_input(x_val_act[idx])\n",
    "\n",
    "    inputshape = x_train_act.shape[1:]\n",
    "    PTModel, preprocess_input = get_model(model_name)\n",
    "    base_pretrained_model = PTModel(input_shape = inputshape, \n",
    "                                  include_top = False, weights = 'imagenet')\n",
    "    base_pretrained_model.trainable = False\n",
    "\n",
    "    from keras import models, layers\n",
    "    from keras.optimizers import Adam\n",
    "    img_in = layers.Input(inputshape, name='Image_RGB_In')\n",
    "    x = base_pretrained_model(img_in)\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "\n",
    "    x = Dense(256)(x)\n",
    "    x = BatchActivate(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(64)(x)\n",
    "    x = BatchActivate(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    out_layer = layers.Dense(1, activation = 'sigmoid')(x)\n",
    "    class_model = models.Model(inputs = [img_in], outputs = [out_layer], name = 'full_model')\n",
    "\n",
    "    class_model.compile(optimizer = Adam(lr=0.01), \n",
    "                       loss = 'binary_crossentropy',\n",
    "                       metrics = ['binary_accuracy'])\n",
    "\n",
    "    batch_size = 32\n",
    "    base_name = '{}_{}'.format(model_name, fold)\n",
    "    save_model_name = '../model/classifier/{}.model'.format(base_name)\n",
    "    submission_file = '../result/classifier/{}.csv'.format(base_name)\n",
    "    oof_file = '../result/classifier/{}_oof.csv'.format(base_name)\n",
    "\n",
    "    print(save_model_name)\n",
    "    print(submission_file)\n",
    "    print(oof_file)\n",
    "    \n",
    "    board = keras.callbacks.TensorBoard(log_dir='log/classifier/{}'.format(base_name),\n",
    "                           histogram_freq=0, write_graph=True, write_images=False)\n",
    "    early_stopping = EarlyStopping(monitor='val_binary_accuracy', mode = 'max',patience=5, verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_binary_accuracy', \n",
    "                                       mode = 'max', save_best_only=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_binary_accuracy', mode = 'max',factor=0.5, patience=2, min_lr=0.00001, verbose=1)\n",
    "\n",
    "    epochs = 200\n",
    "\n",
    "    history = class_model.fit(x_train, y_train,\n",
    "                        validation_data=[x_valid, y_valid], \n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[board, early_stopping, reduce_lr, model_checkpoint],\n",
    "                        verbose=1)\n",
    "    \n",
    "    model = load_model(save_model_name)\n",
    "    \n",
    "    oof = model.predict(x_valid)\n",
    "    df_oof = pd.DataFrame()\n",
    "    df_oof['id'] = id_valid\n",
    "    df_oof['target'] = oof\n",
    "    df_oof.to_csv(oof_file, index=False)\n",
    "    \n",
    "    files = os.listdir('../input/test/images/')\n",
    "    x_test = np.array([(np.array(load_img(\"../input/test/images/{}\".format(idx), grayscale = False))) for idx in files]).reshape(-1, img_size_target, img_size_target, 3)\n",
    "    preds_test = model.predict(x_test)\n",
    "    df_result = pd.DataFrame()\n",
    "    df_result['id'] = files\n",
    "    df_result['pre'] = preds_test.reshape(len(files))\n",
    "    df_result.to_csv(submission_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['hassalt'])):\n",
    "    x_train, x_valid, msk_train, msk_val, y_train, y_valid, id_train, id_valid = get_splits(train_df, train_idx, val_idx)\n",
    "    x_train, msk_train, y_train = argument(x_train, msk_train, y_train)\n",
    "    \n",
    "    model = train_classifier(fold, 'VGG16', x_train, y_train, x_valid, y_valid, id_valid)\n",
    "    \n",
    "    from keras import backend as K\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
