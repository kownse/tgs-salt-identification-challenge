{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import math\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as vsn\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "from models.nets import ResUNet\n",
    "from utils.data_loaders import *\n",
    "from utils.data_vis import plot_from_torch\n",
    "\n",
    "from utils.evaluations import DiceLoss, calc_metric\n",
    "from tqdm import tqdm_notebook\n",
    "from kaggle_util import *\n",
    "from utils.evaluations import FocalLoss2d, DiceLoss, get_iou_vector\n",
    "import utils.lovasz_losses as L\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "imsize = 128\n",
    "batch_size = 2\n",
    "gpu = 1\n",
    "weight_folder = '../model_weights/best/'\n",
    "debug = False\n",
    "flip_tta = True\n",
    "use_bool = True\n",
    "\n",
    "device = torch.device(\"cuda:{}\".format(gpu) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RLenc(img, order='F', format=True):\n",
    "    \"\"\"\n",
    "    img is binary mask image, shape (r,c)\n",
    "    order is down-then-right, i.e. Fortran\n",
    "    format determines if the order needs to be preformatted \n",
    "    (according to submission rules) or not\n",
    "\n",
    "    returns run length as an array or string (if format is True)\n",
    "    \"\"\"\n",
    "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
    "    runs = []  ## list of run lengths\n",
    "    r = 0  ## the current run length\n",
    "    pos = 1  ## count starts from 1 per WK\n",
    "    for c in bytes:\n",
    "        if (c == 0):\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos += r\n",
    "                r = 0\n",
    "            pos += 1\n",
    "        else:\n",
    "            r += 1\n",
    "\n",
    "    # if last run is unsaved (i.e. data ends with 1)\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "        r = 0\n",
    "\n",
    "    if format:\n",
    "        z = ''\n",
    "\n",
    "        for rr in runs:\n",
    "            z += '{} {} '.format(rr[0], rr[1])\n",
    "        return z[:-1]\n",
    "    else:\n",
    "        return runs\n",
    "\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b > prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "\n",
    "    print(run_lengths)\n",
    "    return run_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 models\n",
      "['../model_weights/best/best_fix2_resunet_tgs_slt_fold-0.pth', '../model_weights/best/best_fix2_resunet_tgs_slt_fold-1.pth', '../model_weights/best/best_fix2_resunet_tgs_slt_fold-2.pth', '../model_weights/best/best_fix2_resunet_tgs_slt_fold-3.pth', '../model_weights/best/best_fix2_resunet_tgs_slt_fold-4.pth']\n"
     ]
    }
   ],
   "source": [
    "weights = glob.glob(weight_folder + 'best_fix2_*.pth')\n",
    "print('Found {} models'.format(len(weights)))\n",
    "\n",
    "print(weights)\n",
    "OUT_FILE = '../subm/averaged_{}_resunet_models.csv'.format(len(weights))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['best_fix3_resunet_tgs_slt_fold-0.pth',\n",
    "        'best_fix3_resunet_tgs_slt_fold-1.pth',\n",
    "        'best_fix2_resunet_tgs_slt_fold-2.pth',\n",
    "        'best_fix3_2_resunet_tgs_slt_fold-3.pth',\n",
    "        'best_fix2_resunet_tgs_slt_fold-4.pth']\n",
    "\n",
    "weights = ['../model_weights/best/' + f for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model_weights/best/best_fix3_resunet_tgs_slt_fold-0.pth',\n",
       " '../model_weights/best/best_fix3_resunet_tgs_slt_fold-1.pth',\n",
       " '../model_weights/best/best_fix2_resunet_tgs_slt_fold-2.pth',\n",
       " '../model_weights/best/best_fix3_2_resunet_tgs_slt_fold-3.pth',\n",
       " '../model_weights/best/best_fix2_resunet_tgs_slt_fold-4.pth']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18000 test images\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResUNet(\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (conv_in): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "  (bn_in): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (encode_b): Sequential(\n",
       "    (0): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (2): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encode_c): Sequential(\n",
       "    (0): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (2): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (3): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encode_d): Sequential(\n",
       "    (0): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (2): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (3): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (4): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (5): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encode_e): Sequential(\n",
       "    (0): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (2): SEResNeXtBottleneck(\n",
       "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (se_module): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "        (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (center): Sequential(\n",
       "    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (decoder_a): Decoder(\n",
       "    (conv1): Conv2d(2560, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (se): SELayer(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=4, bias=True)\n",
       "        (1): ReLU(inplace)\n",
       "        (2): Linear(in_features=4, out_features=64, bias=True)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_b): Decoder(\n",
       "    (conv1): Conv2d(1088, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (se): SELayer(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=4, bias=True)\n",
       "        (1): ReLU(inplace)\n",
       "        (2): Linear(in_features=4, out_features=64, bias=True)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_c): Decoder(\n",
       "    (conv1): Conv2d(576, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (se): SELayer(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=4, bias=True)\n",
       "        (1): ReLU(inplace)\n",
       "        (2): Linear(in_features=4, out_features=64, bias=True)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_d): Decoder(\n",
       "    (conv1): Conv2d(320, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (se): SELayer(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=4, bias=True)\n",
       "        (1): ReLU(inplace)\n",
       "        (2): Linear(in_features=4, out_features=64, bias=True)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_e): Decoder(\n",
       "    (conv1): Conv2d(128, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (se): SELayer(\n",
       "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=4, bias=True)\n",
       "        (1): ReLU(inplace)\n",
       "        (2): Linear(in_features=4, out_features=64, bias=True)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mask_out): Sequential(\n",
       "    (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (mask_chck): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (1): Flatten()\n",
       "    (2): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout2d(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the loaders\n",
    "test_loader = get_test_loader(imsize=imsize, batch_size=batch_size)\n",
    "\n",
    "net = ResUNet(use_bool=use_bool)\n",
    "torch.cuda.set_device(gpu)\n",
    "cudnn.benchmark = True\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net, data_loader, test_ids, all_blanks, averaged_mask_preds, averaged_bool_preds,\n",
    "            use_bool = True, flip_tta = True, test=True):\n",
    "    \n",
    "    total = len(data_loader.dataset) / batch_size\n",
    "    prog = tqdm_notebook(total = total)\n",
    "    for batch_idx, data in enumerate(data_loader): \n",
    "        prog.update(1)\n",
    "        test_imgs = data['img'].cuda(async=True)\n",
    "        batch_ids = data['id']\n",
    "        if test:\n",
    "            blanks = data['blank']\n",
    "        # get predictions\n",
    "        preds = net(test_imgs)\n",
    "        if use_bool:\n",
    "            bool_preds = preds[1].sigmoid()\n",
    "            preds = preds[0].sigmoid()\n",
    "        else:\n",
    "            preds = preds.sigmoid()\n",
    "\n",
    "        if test and flip_tta:\n",
    "            test_imgs_lr = data['img_lr'].cuda(async=True)\n",
    "            preds_lr_ = net(test_imgs_lr)\n",
    "            if use_bool:\n",
    "                bool_lr = preds_lr_[1].sigmoid()\n",
    "                preds_lr_ = preds_lr_[0].sigmoid()\n",
    "                bool_preds = (bool_lr + bool_preds) / 2.\n",
    "            else:\n",
    "                preds_lr_ = preds_lr_.sigmoid()\n",
    "\n",
    "            preds_lr = np.zeros((preds_lr_.size())).astype(np.float32)\n",
    "            preds_lr = np.copy(preds_lr_.data.cpu().numpy()[:,:,:,::-1])\n",
    "\n",
    "            preds = (preds + torch.from_numpy(preds_lr).cuda()) / 2.\n",
    "\n",
    "        if w_idx == 0:\n",
    "            #print(preds.size())\n",
    "            test_ids.extend(batch_ids)\n",
    "            if test:\n",
    "                all_blanks.extend(blanks.data.cpu())\n",
    "            averaged_mask_preds.append(preds.data.view(-1, imsize, imsize).cpu())\n",
    "            if use_bool:\n",
    "                #print(bool_preds)\n",
    "                averaged_bool_preds.append(bool_preds.data.cpu())\n",
    "        else:\n",
    "            averaged_mask_preds[batch_idx] += preds.data.view(-1, imsize, imsize).cpu()\n",
    "            averaged_bool_preds[batch_idx] += bool_preds.data.cpu()\n",
    "            \n",
    "    return test_ids, all_blanks, averaged_mask_preds, averaged_bool_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bdc93601884c86b543aaefdcc79f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing model 1 of 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a417edd739a34ee88c7f389f61b3a467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kownse/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing model 2 of 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430b3450d3d641acb1cf25e7d2cc4a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing model 3 of 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988b06bb9c904fcb84cbb4f8cd3b0fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing model 4 of 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b693e3690544c6a463a337dc600807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing model 5 of 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d113882f5aee4cc9aad6bcb4650a2a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_msks = []\n",
    "val_bools = []\n",
    "val_blanks = []\n",
    "test_ids = []\n",
    "averaged_mask_preds = []\n",
    "averaged_bool_preds = []\n",
    "all_blanks = []\n",
    "for w_idx, wf in tqdm_notebook(enumerate(weights)):\n",
    "    print('Doing model {} of {}'.format(w_idx+1, len(weights)))\n",
    "    \n",
    "    train_loader, valid_loader = get_data_loaders(imsize=imsize,\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      num_folds=5,\n",
    "                                                      fold=w_idx)\n",
    "    \n",
    "    net.load_state_dict(torch.load(wf,map_location=lambda storage, loc: storage))\n",
    "    net.eval() \n",
    "    net.to(device)\n",
    "    \n",
    "#     _, val_blanks, val_msks, val_bools =\\\n",
    "#         predict(net, valid_loader, [], val_blanks, val_msks, val_bools, flip_tta=False, test=False)\n",
    "    \n",
    "    test_ids, all_blanks, averaged_mask_preds, averaged_bool_preds =\\\n",
    "        predict(net, test_loader, test_ids, all_blanks, averaged_mask_preds, averaged_bool_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18000, 128, 128])\n",
      "blanks torch.Size([18000, 1, 1])\n",
      "(18000, 128, 128)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16fad0893a724458bf8de3b9edecd8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000 18000\n",
      "save result\n",
      "upload result\n",
      "cmd: kaggle competitions submit -c tgs-salt-identification-challenge -f ../subm/seresnet_bool_fix3.csv.7z -m \"submit\"\n"
     ]
    }
   ],
   "source": [
    "use_bool = False\n",
    "#bool_thresh = 0.52\n",
    "#msk_thresh = 0.46\n",
    "bool_thresh = 0.5\n",
    "msk_thresh = 0.4\n",
    "\n",
    "avg_preds = torch.cat(averaged_mask_preds, dim=0)\n",
    "#print(avg_preds)\n",
    "avg_preds /= float(len(weights))\n",
    "#print(avg_preds)\n",
    "print(avg_preds.size())\n",
    "\n",
    "# set masks to 0 with low probability of having mask \n",
    "if use_bool:\n",
    "    bool_preds = torch.cat(averaged_bool_preds, dim=0)\n",
    "    #print(bool_preds)\n",
    "    bool_preds /= float(len(weights))\n",
    "    bool_preds = bool_preds > bool_thresh\n",
    "    print('number of non-empty predicted masks', bool_preds.sum())\n",
    "    #print(bool_preds.size())\n",
    "    avg_preds *= bool_preds.view(bool_preds.size(0),1,1).expand_as(avg_preds).float()\n",
    "\n",
    "blanks = torch.Tensor(all_blanks).view(-1,1,1)\n",
    "print('blanks', blanks.size())\n",
    "avg_preds *= blanks.expand_as(avg_preds).float()\n",
    "\n",
    "pred_np = avg_preds.cpu().numpy()\n",
    "\n",
    "print(pred_np.shape)\n",
    "\n",
    "# keep track of losses\n",
    "rles = []\n",
    "ids = []\n",
    "for j in tqdm_notebook(range(pred_np.shape[0])):\n",
    "    if imsize == 256:\n",
    "        predicted_mask = resize(pred_np[j][27:229, 27:229], (101,101),\n",
    "                                preserve_range=True)\n",
    "    else:\n",
    "        predicted_mask = pred_np[j][13:114, 13:114]\n",
    "        predicted_mask = np.where(predicted_mask > msk_thresh, 1, 0)\n",
    "        rles.append(RLenc(predicted_mask.astype(np.int32)))\n",
    "        ids.append(test_ids[j])\n",
    "\n",
    "print(len(ids), len(rles))\n",
    "#print({'id':ids[:4], 'rle_mask':rles[:4]})\n",
    "\n",
    "subm = pd.DataFrame.from_dict({'id':ids, 'rle_mask':rles}, orient='index').T\n",
    "\n",
    "save_result(subm, '../subm/seresnet_bool_fix3.csv', \n",
    "                        competition = 'tgs-salt-identification-challenge', \n",
    "                        send = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B, threshold = 0.5):\n",
    "    batch_size = A.shape[0]\n",
    "    B = np.where(B > threshold, 1, 0)\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        if np.count_nonzero(t) == 0 and np.count_nonzero(p) > 0:\n",
    "            metric.append(0)\n",
    "            continue\n",
    "        if np.count_nonzero(t) >= 1 and np.count_nonzero(p) == 0:\n",
    "            metric.append(0)\n",
    "            continue\n",
    "        if np.count_nonzero(t) == 0 and np.count_nonzero(p) == 0:\n",
    "            metric.append(1)\n",
    "            continue\n",
    "\n",
    "        intersection = np.logical_and(t, p)\n",
    "        union = np.logical_or(t, p)\n",
    "        iou = np.sum(intersection > 0) / np.sum(union > 0)\n",
    "        thresholds = np.arange(0.5, 1, 0.05)\n",
    "        s = []\n",
    "        for thresh in thresholds:\n",
    "            s.append(iou > thresh)\n",
    "        metric.append(np.mean(s))\n",
    "\n",
    "    return np.mean(metric)\n",
    "\n",
    "focal_loss = FocalLoss2d()\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def valid(net, valid_loader, threshold = 0.5, lambda_bool = 0.5, use_lovasz=True):\n",
    "    net.eval() \n",
    "    # keep track of losses\n",
    "    val_ious = []\n",
    "    val_iter_loss = 0.\n",
    "    # no gradients during validation\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            \n",
    "            valid_imgs = data['img'].to(device)\n",
    "            valid_msks = data['msk'].to(device)\n",
    "            valid_msk_bool = data['has_msk'].float().to(device)\n",
    "            # get predictions\n",
    "            msk_vpreds, bool_vpreds = net(valid_imgs)\n",
    "            msk_blend_vpreds = msk_vpreds * bool_vpreds.view(valid_imgs.size(0), 1, 1, 1)\n",
    "\n",
    "            # calculate loss\n",
    "            if use_lovasz:\n",
    "                vloss = L.lovasz_hinge(msk_vpreds, valid_msks)\n",
    "                #vloss += focal_loss(msk_vpreds, valid_msks)\n",
    "                #vloss -= dice(msk_vpreds.sigmoid(), valid_msks)\n",
    "            else:\n",
    "                vloss = focal_loss(msk_vpreds, valid_msks)\n",
    "                vloss += L.lovasz_hinge(msk_vpreds, valid_msks)\n",
    "                #vloss -= dice(msk_vpreds.sigmoid(), valid_msks)\n",
    "            \n",
    "            vloss += lambda_bool * bce(bool_vpreds, valid_msk_bool.view(-1,1))\n",
    "            vloss += lambda_bool * focal_loss(msk_blend_vpreds, valid_msks)\n",
    "\n",
    "            #vloss += args.lambda_dice * dice(msk_vpreds.sigmoid(), valid_msks)\n",
    "            # get validation stats\n",
    "            val_iter_loss += vloss.item()\n",
    "            \n",
    "            val_ious.append(get_iou_vector(valid_msks.cpu().numpy()[:,:,13:114, 13:114], \n",
    "                                           msk_vpreds.sigmoid().cpu().numpy()[:,:,13:114, 13:114],\n",
    "                                          threshold))\n",
    "            \n",
    "    epoch_vloss = val_iter_loss / (len(valid_loader.dataset) / batch_size)\n",
    "    print('Avg Eval Loss: {:.4}, Avg IOU: {:.4}'.format(epoch_vloss, np.mean(val_ious)))\n",
    "    return epoch_vloss, np.mean(val_ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "\n",
    "\n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    #  if all zeros, original code  generate wrong  bins [-0.5 0 0.5],\n",
    "    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n",
    "\n",
    "    intersection = temp1[0]\n",
    "\n",
    "    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n",
    "    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "      \n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    intersection[intersection == 0] = 1e-9\n",
    "    \n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(net, valid_loader):\n",
    "    net.eval() \n",
    "    # keep track of losses\n",
    "    msk_preds = []\n",
    "    bool_preds = []\n",
    "    tar_msks = []\n",
    "    # no gradients during validation\n",
    "    with torch.no_grad():\n",
    "        total = len(valid_loader.dataset) / batch_size\n",
    "        prog = tqdm_notebook(total = total)\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            prog.update(1)\n",
    "            \n",
    "            valid_imgs = data['img'].to(device)\n",
    "            valid_msks = data['msk'].to(device)\n",
    "            valid_msk_bool = data['has_msk'].float().to(device)\n",
    "            # get predictions\n",
    "            msk_vpreds, bool_vpreds = net(valid_imgs)\n",
    "            msk_vpreds = msk_vpreds.sigmoid()\n",
    "            bool_vpreds = bool_vpreds.sigmoid()\n",
    "        \n",
    "            msk_preds.append(msk_vpreds.data.view(-1, imsize, imsize).cpu().numpy())\n",
    "            bool_preds.append([val.data.cpu().numpy() for val in bool_vpreds])\n",
    "            tar_msks.append(data['msk'])\n",
    "            \n",
    "            \n",
    "    tar_msks = np.concatenate(tar_msks, axis= 0)\n",
    "    msk_preds = np.concatenate(msk_preds, axis= 0)\n",
    "    bool_preds = np.concatenate(bool_preds, axis= 0)\n",
    "            \n",
    "    return tar_msks, msk_preds, bool_preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_lovasz = True\n",
    "best_ious = []\n",
    "\n",
    "tot_msk_preds = []\n",
    "tot_bool_preds = []\n",
    "tot_tar_msks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0074deee97f7475790552da131dab8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing model 1 of 5 ../model_weights/best/best_fix2_resunet_tgs_slt_fold-0.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14001e0afc9248ad9be0623577cf95df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kownse/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing model 2 of 5 ../model_weights/best/best_fix2_resunet_tgs_slt_fold-1.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b299eaeb9701461e844fc08f5c05fe34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing model 3 of 5 ../model_weights/best/best_fix2_resunet_tgs_slt_fold-2.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ad9a20f80e457a8698febd573aef48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing model 4 of 5 ../model_weights/best/best_fix2_resunet_tgs_slt_fold-3.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ff3b5b9f254272bfeda1d39b01009c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing model 5 of 5 ../model_weights/best/best_fix2_resunet_tgs_slt_fold-4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05a9a6e84574bc29730cdcae0c5612c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for fold, wf in tqdm_notebook(enumerate(weights)):\n",
    "    print('Doing model {} of {}'.format(fold+1, len(weights)), wf)\n",
    "\n",
    "    #if fold > 0:\n",
    "    #    break\n",
    "\n",
    "    # set model filenames\n",
    "    train_loader, valid_loader = get_data_loaders(imsize=imsize,\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      num_folds=5,\n",
    "                                                      fold=w_idx)\n",
    "    \n",
    "    net = ResUNet(use_bool=True)\n",
    "    net.load_state_dict(torch.load(wf,map_location=lambda storage, loc: storage))\n",
    "    net.eval() \n",
    "    net.to(device)\n",
    "    \n",
    "    tar_msks, msk_preds, bool_preds = predict_img(net, valid_loader)\n",
    "\n",
    "    tot_msk_preds.append(msk_preds)\n",
    "    tot_bool_preds.append(bool_preds)\n",
    "    tot_tar_msks.append(tar_msks)\n",
    "    \n",
    "tar_msks = np.concatenate(tot_tar_msks, axis= 0)\n",
    "msk_preds = np.concatenate(tot_msk_preds, axis= 0)\n",
    "bool_preds = np.concatenate(tot_bool_preds, axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998234"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_preds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a5498626ef407996a886cd7e46d479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold vs IoU (0.5263157894736842, 0.9439500000000001)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f647b4e7d68>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thresholds = np.linspace(0.4, 0.6, 20)\n",
    "ious = np.array([iou_metric_batch(tar_msks, msk_preds > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "title = \"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best)\n",
    "print(title)\n",
    "plt.title(title)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.874125"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_metric_batch(tar_msks, msk_preds > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_best_iou = 0\n",
    "tot_best_threshold = 0\n",
    "tot_best_bool_threshold = 0\n",
    "\n",
    "bool_msk_ious = []\n",
    "bool_thresholds = np.linspace(0.5, 0.9, 20)\n",
    "for bool_thred in tqdm_notebook(bool_thresholds):\n",
    "    bool_binary = (bool_preds > bool_thred) * 1\n",
    "    bool_msk = np.zeros_like(msk_preds)\n",
    "    for i in range(msk_preds.shape[0]):\n",
    "        bool_msk[i] = msk_preds[i] * bool_binary[i]\n",
    "        \n",
    "    thresholds = np.linspace(0.445, 0.445, 1)\n",
    "    ious = np.array([iou_metric_batch(tar_msks, bool_msk > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "    threshold_best_index = np.argmax(ious) \n",
    "    iou_best = ious[threshold_best_index]\n",
    "    threshold_best = thresholds[threshold_best_index]\n",
    "    \n",
    "    bool_msk_ious.append(ious)\n",
    "    \n",
    "    if iou_best > tot_best_iou:\n",
    "        tot_best_threshold = threshold_best\n",
    "        tot_best_bool_threshold = bool_thred\n",
    "        tot_best_iou = iou_best\n",
    "        print('new best iou', iou_best, tot_best_threshold, tot_best_bool_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_bool = np.concatenate([val.data.cpu().numpy() for val in averaged_bool_preds], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_bool /= float(len(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_bool.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
