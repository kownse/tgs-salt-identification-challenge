{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook #, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers import Input, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, concatenate, Concatenate, UpSampling2D, Activation\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras import layers\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n",
    "\n",
    "import time\n",
    "from kaggle_util import *\n",
    "from models import *\n",
    "import cv2\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "img_size_ori = 101\n",
    "img_size_target = 128\n",
    "\n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of training/testing ids and depths\n",
    "train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)\n",
    "\n",
    "train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=False)) for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)\n",
    "train_df['hassalt'] = train_df['masks'].apply(lambda x: (x.max()!=0) * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET = len(train_df)\n",
    "train_df = train_df.head(SUBSET)\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "train_df.index.values,\n",
    "np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 3), \n",
    "np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "train_df.coverage.values,\n",
    "train_df.z.values,\n",
    "test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data augmentation\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inception_resnet_v2_unet_sigmoid(inp,input_shape, start_neurons, DropoutRatio = 0.5, weights='imagenet'):\n",
    "    print('get_inception_resnet_v2_unet_softmax')\n",
    "    # Stem block: 35 x 35 x 192\n",
    "    x = conv2d_bn(inp, start_neurons, 3, strides=2, padding='same')\n",
    "    x = conv2d_bn(x, 32, 3, padding='same')\n",
    "    x = conv2d_bn(x, 64, 3)\n",
    "    conv1 = x\n",
    "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    \n",
    "    x = conv2d_bn(x, 80, 1, padding='same')\n",
    "    x = conv2d_bn(x, 192, 3, padding='same')\n",
    "    conv2 = x\n",
    "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "\n",
    "    # Mixed 5b (Inception-A block): 35 x 35 x 320\n",
    "    branch_0 = conv2d_bn(x, 96, 1)\n",
    "    branch_1 = conv2d_bn(x, 48, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 64, 5)\n",
    "    branch_2 = conv2d_bn(x, 64, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3)\n",
    "    branch_pool = AveragePooling2D(3, strides=1, padding='same')(x)\n",
    "    \n",
    "    branch_pool = conv2d_bn(branch_pool, 64, 1)\n",
    "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "    x = Concatenate(axis=channel_axis, name='mixed_5b')(branches)\n",
    "\n",
    "    # 10x block35 (Inception-ResNet-A block): 35 x 35 x 320\n",
    "    for block_idx in range(1, 11):\n",
    "        x = inception_resnet_block(x,\n",
    "                       scale=0.17,\n",
    "                       block_type='block35',\n",
    "                       block_idx=block_idx)\n",
    "        \n",
    "    conv3 = x\n",
    "    # Mixed 6a (Reduction-A block): 17 x 17 x 1088\n",
    "    branch_0 = conv2d_bn(x, 384, 3, strides=2, padding='same')\n",
    "    branch_1 = conv2d_bn(x, 256, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 3)\n",
    "    branch_1 = conv2d_bn(branch_1, 384, 3, strides=2, padding='same')\n",
    "    branch_pool = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    branches = [branch_0, branch_1, branch_pool]\n",
    "    x = Concatenate(axis=channel_axis, name='mixed_6a')(branches)\n",
    "\n",
    "    # 20x block17 (Inception-ResNet-B block): 17 x 17 x 1088\n",
    "    for block_idx in range(1, 21):\n",
    "        x = inception_resnet_block(x,\n",
    "                       scale=0.11,\n",
    "                       block_type='block17',\n",
    "                       block_idx=block_idx)\n",
    "    conv4 = x\n",
    "    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n",
    "    branch_0 = conv2d_bn(x, 256, 1)\n",
    "    branch_0 = conv2d_bn(branch_0, 384, 3, strides=2, padding='same')\n",
    "    branch_1 = conv2d_bn(x, 256, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 288, 3, strides=2, padding='same')\n",
    "    branch_2 = conv2d_bn(x, 256, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 288, 3)\n",
    "    branch_2 = conv2d_bn(branch_2, 320, 3, strides=2, padding='same')\n",
    "    branch_pool = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    \n",
    "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
    "    x = Concatenate(axis=channel_axis, name='mixed_7a')(branches)\n",
    "\n",
    "    # 10x block8 (Inception-ResNet-C block): 8 x 8 x 2080\n",
    "    for block_idx in range(1, 10):\n",
    "        x = inception_resnet_block(x,\n",
    "                       scale=0.2,\n",
    "                       block_type='block8',\n",
    "                       block_idx=block_idx)\n",
    "    \n",
    "    x = inception_resnet_block(x,\n",
    "                       scale=1.,\n",
    "                       activation=None,\n",
    "                       block_type='block8',\n",
    "                       block_idx=10)\n",
    "\n",
    "    # Final convolution block: 8 x 8 x 1536\n",
    "    x = conv2d_bn(x, 1536, 1, name='conv_7b')\n",
    "    if DropoutRatio > 0:\n",
    "        x = Dropout(DropoutRatio)(x)\n",
    "    conv5 = x\n",
    "    \n",
    "    conv6 = conv_block(UpSampling2D()(conv5), 320)\n",
    "    conv6 = concatenate([conv6, conv4], axis=-1)\n",
    "    if DropoutRatio > 0:\n",
    "        conv6 = Dropout(DropoutRatio)(conv6)\n",
    "    conv6 = conv_block(conv6, 320)\n",
    "\n",
    "    conv7 = conv_block(UpSampling2D()(conv6), 256)\n",
    "    conv7 = concatenate([conv7, conv3], axis=-1)  \n",
    "    if DropoutRatio > 0:\n",
    "        conv7 = Dropout(DropoutRatio)(conv7)\n",
    "    conv7 = conv_block(conv7, 256)\n",
    "\n",
    "    conv8 = conv_block(UpSampling2D()(conv7), 128)\n",
    "    conv8 = concatenate([conv8, conv2], axis=-1)\n",
    "    if DropoutRatio > 0:\n",
    "        conv8 = Dropout(DropoutRatio)(conv8)\n",
    "    conv8 = conv_block(conv8, 128)\n",
    "\n",
    "    conv9 = conv_block(UpSampling2D()(conv8), 96)\n",
    "    conv9 = concatenate([conv9, conv1], axis=-1)\n",
    "    if DropoutRatio > 0:\n",
    "        conv9 = Dropout(DropoutRatio)(conv9)\n",
    "    conv9 = conv_block(conv9, 96)\n",
    "\n",
    "    conv10 = conv_block(UpSampling2D()(conv9), 64)\n",
    "    conv10 = conv_block(conv10, 64)\n",
    "    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(conv10)\n",
    "    res = Activation('sigmoid')(output_layer_noActi)\n",
    "    \n",
    "    model = Model(inp, res)\n",
    "    \n",
    "    if weights == 'imagenet':\n",
    "        print('load weights from imagenet')\n",
    "        inception_resnet_v2 = InceptionResNetV2(weights=weights, include_top=False, input_shape=input_shape + (3,))\n",
    "        j = 2\n",
    "        for i in range(2, len(inception_resnet_v2.layers)-1):\n",
    "            if type(model.layers[j]) == keras.layers.core.Dropout:\n",
    "                print('skip dropout at', j)\n",
    "                j += 1\n",
    "            model.layers[j].set_weights(inception_resnet_v2.layers[i].get_weights())\n",
    "            j += 1\n",
    "            model.layers[i].trainable = False\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dropout = 0.0\n",
    "weights = 'imagenet'\n",
    "basic_name = '../model/inception_simple_{}_{}'.format(dropout, weights)\n",
    "save_model_name = basic_name + '.model'\n",
    "submission_file = basic_name + '.csv'\n",
    "\n",
    "print(save_model_name)\n",
    "print(submission_file)\n",
    "\n",
    "# model\n",
    "\n",
    "input_layer = Input((img_size_target, img_size_target, 3))\n",
    "model1 = get_inception_resnet_v2_unet_sigmoid(input_layer,\n",
    "                                              (img_size_target, img_size_target), \n",
    "                                              32, dropout, weights)\n",
    "\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "model1.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=[my_iou_metric])\n",
    "\n",
    "board = keras.callbacks.TensorBoard(log_dir='log/inception_simple_{}_{}'.format(dropout, weights),\n",
    "                       histogram_freq=0, write_graph=True, write_images=False)\n",
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric', mode = 'max',patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric', mode = 'max',factor=0.5, patience=3, min_lr=0.00001, verbose=1)\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "history = model1.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[board, early_stopping, model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model(save_model_name,custom_objects={'my_iou_metric': my_iou_metric})\n",
    "\n",
    "basic_name = '../model/inception_simple_stage2_{}_{}'.format(dropout, weights)\n",
    "save_model_name = basic_name + '.model'\n",
    "submission_file = basic_name + '.csv'\n",
    "\n",
    "# remove layter activation layer and use losvasz loss\n",
    "input_x = model1.layers[0].input\n",
    "output_layer = model1.layers[-1].input\n",
    "model = Model(input_x, output_layer)\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "\n",
    "# lovasz_loss need input range (-∞，+∞), so cancel the last \"sigmoid\" activation  \n",
    "# Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n",
    "model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\n",
    "\n",
    "#model.summary()\n",
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric_2', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.5, patience=3, min_lr=0.00001, verbose=1)\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[board, model_checkpoint,reduce_lr,early_stopping], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n",
    "                                                   'lovasz_loss': lovasz_loss})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = predict_result(model,x_valid,img_size_target)\n",
    "## Scoring for last model, choose threshold by validation data \n",
    "thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
    "# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
    "thresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n",
    "\n",
    "# ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "# print(ious)\n",
    "ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "print(ious)\n",
    "\n",
    "# instead of using default 0 as threshold, use validation data to find the best threshold.\n",
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test = np.array([(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale = False))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)\n",
    "# x_test = [upsample(make_4(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale=False)))) for idx in tqdm_notebook(test_df.index)]\n",
    "# x_test = np.array(x_test).reshape(-1, img_size_target, img_size_target, 4)\n",
    "x_test = [upsample(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale=True))) for idx in tqdm_notebook(test_df.index)]\n",
    "x_test = np.array(x_test).reshape(-1, img_size_target, img_size_target, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = predict_result(model,x_test,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "pred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "t2 = time.time()\n",
    "\n",
    "print(f\"Usedtime = {t2-t1} s\")\n",
    "\n",
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub = sub.reset_index()\n",
    "save_result(sub, '../result/inception.csv', \n",
    "                        competition = 'tgs-salt-identification-challenge', \n",
    "                        send = False, index = False)\n",
    "\n",
    "t_finish = time.time()\n",
    "print(f\"Kernel run time = {(t_finish-t_start)/3600} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
