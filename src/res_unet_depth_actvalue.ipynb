{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook #, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n",
    "\n",
    "import time\n",
    "from kaggle_util import *\n",
    "from models import *\n",
    "\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "\n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n",
    "\n",
    "\n",
    "# Build model\n",
    "\n",
    "def build_model_deeper(input_layer, start_neurons, DropoutRatio = 0.5):\n",
    "    # 101 -> 50\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1, True)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "    # 50 -> 25\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2, True)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "    # 25 -> 12\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4, True)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "    # 12 -> 6\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8, True)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = residual_block(convm,start_neurons * 16, True)\n",
    "    \n",
    "    # 6 -> 12\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n",
    "    \n",
    "    # 12 -> 25\n",
    "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])    \n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n",
    "\n",
    "    # 25 -> 50\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "        \n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n",
    "    \n",
    "    # 50 -> 101\n",
    "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n",
    "    \n",
    "    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
    "    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n",
    "    output_layer =  Activation('sigmoid')(output_layer_noActi)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee214c07d9c3484aab0a36565c99180f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kownse/.local/lib/python3.6/site-packages/keras_preprocessing/image.py:487: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d661198e67d843fa9a37d7a08aa8d384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Loading of training/testing ids and depths\n",
    "train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)\n",
    "\n",
    "train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['z'] = (train_df['z'] - train_df['z'].min()) / (train_df['z'].max() - train_df['z'].min()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBSET = len(train_df)\n",
    "train_df = train_df.head(SUBSET)\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "train_df.index.values,\n",
    "np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target), \n",
    "np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "train_df.coverage.values,\n",
    "train_df.z.values,\n",
    "test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 101, 101)\n",
      "(800, 101, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "#Data augmentation\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "depth_train = np.append(depth_train, depth_train)\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70594714, 0.27863436, 0.91519824, 0.46365639, 0.35792952,\n",
       "       0.38325991, 0.11894273, 0.90748899, 0.81828194, 0.69052863])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20e1d9fdfdc4dc883cc7e506d1d7dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18460805cd97435e9fce29953df39688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=800), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_train = add_depth_bulk_act(x_train, depth_train)\n",
    "x_valid = add_depth_bulk_act(x_valid, depth_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../model/Unet_resnet_depth_act_trainlonger32_0.5_stage1.model\n",
      "../model/Unet_resnet_depth_act_trainlonger32_0.5.csv\n"
     ]
    }
   ],
   "source": [
    "start_feature = 32\n",
    "dropout = 0.5\n",
    "basic_name = '../model/Unet_resnet_depth_act_trainlonger{}_{}'.format(start_feature, dropout)\n",
    "save_model_name = basic_name + '_stage1.model'\n",
    "submission_file = basic_name + '.csv'\n",
    "\n",
    "print(save_model_name)\n",
    "print(submission_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/200\n",
      "6400/6400 [==============================] - 81s 13ms/step - loss: 0.5583 - my_iou_metric: 0.3396 - val_loss: 0.6009 - val_my_iou_metric: 0.1888\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.18875, saving model to ../model/Unet_resnet_depth_act_trainlonger32_0.5_stage1.model\n",
      "Epoch 2/200\n",
      "6400/6400 [==============================] - 70s 11ms/step - loss: 0.5487 - my_iou_metric: 0.3680 - val_loss: 2.6826 - val_my_iou_metric: 0.1266\n",
      "\n",
      "Epoch 00002: val_my_iou_metric did not improve from 0.18875\n",
      "Epoch 3/200\n",
      "6400/6400 [==============================] - 69s 11ms/step - loss: 0.4062 - my_iou_metric: 0.4213 - val_loss: 0.5047 - val_my_iou_metric: 0.4412\n",
      "\n",
      "Epoch 00003: val_my_iou_metric improved from 0.18875 to 0.44125, saving model to ../model/Unet_resnet_depth_act_trainlonger32_0.5_stage1.model\n",
      "Epoch 4/200\n",
      "6384/6400 [============================>.] - ETA: 0s - loss: 0.3589 - my_iou_metric: 0.4828"
     ]
    }
   ],
   "source": [
    "# model\n",
    "input_layer = Input((img_size_target, img_size_target, 3))\n",
    "output_layer = build_model_deeper(input_layer, start_feature,dropout)\n",
    "\n",
    "model1 = Model(input_layer, output_layer)\n",
    "\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "model1.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=[my_iou_metric])\n",
    "\n",
    "board = keras.callbacks.TensorBoard(log_dir='log/resunet_depth_act_longer_{}_{}'.format(start_feature, dropout),\n",
    "                       histogram_freq=0, write_graph=True, write_images=False)\n",
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric', mode = 'max',patience=20, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric', mode = 'max',factor=0.5, patience=5, min_lr=0.000001, verbose=1)\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 16\n",
    "history = model1.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[board, early_stopping, model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/200\n",
      "6400/6400 [==============================] - 119s 19ms/step - loss: 0.0060 - my_iou_metric_2: 0.7690 - val_loss: 0.4817 - val_my_iou_metric_2: 0.6575\n",
      "\n",
      "Epoch 00001: val_my_iou_metric_2 improved from -inf to 0.65750, saving model to ../model/Unet_resnet_depth_act_trainlonger32_0.5.model\n",
      "Epoch 2/200\n",
      "6400/6400 [==============================] - 107s 17ms/step - loss: -0.0487 - my_iou_metric_2: 0.7754 - val_loss: -0.0032 - val_my_iou_metric_2: 0.7636\n",
      "\n",
      "Epoch 00002: val_my_iou_metric_2 improved from 0.65750 to 0.76363, saving model to ../model/Unet_resnet_depth_act_trainlonger32_0.5.model\n",
      "Epoch 3/200\n",
      "6400/6400 [==============================] - 107s 17ms/step - loss: -0.0780 - my_iou_metric_2: 0.7793 - val_loss: 0.0638 - val_my_iou_metric_2: 0.7610\n",
      "\n",
      "Epoch 00003: val_my_iou_metric_2 did not improve from 0.76363\n",
      "Epoch 4/200\n",
      "6400/6400 [==============================] - 107s 17ms/step - loss: -0.0892 - my_iou_metric_2: 0.7840 - val_loss: 0.0999 - val_my_iou_metric_2: 0.7516\n",
      "\n",
      "Epoch 00004: val_my_iou_metric_2 did not improve from 0.76363\n",
      "Epoch 5/200\n",
      "6400/6400 [==============================] - 107s 17ms/step - loss: -0.0920 - my_iou_metric_2: 0.7833 - val_loss: 0.0334 - val_my_iou_metric_2: 0.7660\n",
      "\n",
      "Epoch 00005: val_my_iou_metric_2 improved from 0.76363 to 0.76600, saving model to ../model/Unet_resnet_depth_act_trainlonger32_0.5.model\n",
      "Epoch 6/200\n",
      "6400/6400 [==============================] - 107s 17ms/step - loss: -0.1142 - my_iou_metric_2: 0.7881 - val_loss: 0.0444 - val_my_iou_metric_2: 0.7678\n",
      "\n",
      "Epoch 00006: val_my_iou_metric_2 improved from 0.76600 to 0.76775, saving model to ../model/Unet_resnet_depth_act_trainlonger32_0.5.model\n",
      "Epoch 7/200\n",
      "6400/6400 [==============================] - 107s 17ms/step - loss: -0.1315 - my_iou_metric_2: 0.7917 - val_loss: 0.0289 - val_my_iou_metric_2: 0.7662\n",
      "\n",
      "Epoch 00007: val_my_iou_metric_2 did not improve from 0.76775\n",
      "Epoch 8/200\n",
      "6400/6400 [==============================] - 107s 17ms/step - loss: -0.1365 - my_iou_metric_2: 0.7937 - val_loss: 0.0267 - val_my_iou_metric_2: 0.7851\n",
      "\n",
      "Epoch 00008: val_my_iou_metric_2 improved from 0.76775 to 0.78512, saving model to ../model/Unet_resnet_depth_act_trainlonger32_0.5.model\n",
      "Epoch 9/200\n",
      "6400/6400 [==============================] - 108s 17ms/step - loss: -0.1260 - my_iou_metric_2: 0.7906 - val_loss: 0.0753 - val_my_iou_metric_2: 0.7635\n",
      "\n",
      "Epoch 00009: val_my_iou_metric_2 did not improve from 0.78512\n",
      "Epoch 10/200\n",
      "6400/6400 [==============================] - 107s 17ms/step - loss: -0.1726 - my_iou_metric_2: 0.7997 - val_loss: 0.4192 - val_my_iou_metric_2: 0.6984\n",
      "\n",
      "Epoch 00010: val_my_iou_metric_2 did not improve from 0.78512\n",
      "Epoch 11/200\n",
      "6400/6400 [==============================] - 108s 17ms/step - loss: -0.1661 - my_iou_metric_2: 0.7978 - val_loss: -0.0418 - val_my_iou_metric_2: 0.7805\n",
      "\n",
      "Epoch 00011: val_my_iou_metric_2 did not improve from 0.78512\n",
      "Epoch 12/200\n",
      "6400/6400 [==============================] - 108s 17ms/step - loss: -0.1795 - my_iou_metric_2: 0.8003 - val_loss: 0.0089 - val_my_iou_metric_2: 0.7701\n",
      "\n",
      "Epoch 00012: val_my_iou_metric_2 did not improve from 0.78512\n",
      "Epoch 13/200\n",
      "6400/6400 [==============================] - 108s 17ms/step - loss: -0.1917 - my_iou_metric_2: 0.8034 - val_loss: 0.1380 - val_my_iou_metric_2: 0.7496\n",
      "\n",
      "Epoch 00013: val_my_iou_metric_2 did not improve from 0.78512\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 14/200\n",
      "6400/6400 [==============================] - 108s 17ms/step - loss: -0.2698 - my_iou_metric_2: 0.8186 - val_loss: -0.0597 - val_my_iou_metric_2: 0.7881\n",
      "\n",
      "Epoch 00014: val_my_iou_metric_2 improved from 0.78512 to 0.78812, saving model to ../model/Unet_resnet_depth_act_trainlonger32_0.5.model\n",
      "Epoch 15/200\n",
      "6400/6400 [==============================] - 108s 17ms/step - loss: -0.2901 - my_iou_metric_2: 0.8255 - val_loss: -0.1087 - val_my_iou_metric_2: 0.8020\n",
      "\n",
      "Epoch 00015: val_my_iou_metric_2 improved from 0.78812 to 0.80200, saving model to ../model/Unet_resnet_depth_act_trainlonger32_0.5.model\n",
      "Epoch 16/200\n",
      "6400/6400 [==============================] - 108s 17ms/step - loss: -0.3054 - my_iou_metric_2: 0.8274 - val_loss: -0.1268 - val_my_iou_metric_2: 0.7979\n",
      "\n",
      "Epoch 00016: val_my_iou_metric_2 did not improve from 0.80200\n",
      "Epoch 17/200\n",
      "6400/6400 [==============================] - 108s 17ms/step - loss: -0.3018 - my_iou_metric_2: 0.8252 - val_loss: -0.1218 - val_my_iou_metric_2: 0.7986\n",
      "\n",
      "Epoch 00017: val_my_iou_metric_2 did not improve from 0.80200\n",
      "Epoch 18/200\n",
      "6400/6400 [==============================] - 108s 17ms/step - loss: -0.3105 - my_iou_metric_2: 0.8274 - val_loss: -0.1303 - val_my_iou_metric_2: 0.7924\n",
      "\n",
      "Epoch 00018: val_my_iou_metric_2 did not improve from 0.80200\n",
      "Epoch 19/200\n",
      "6400/6400 [==============================] - 109s 17ms/step - loss: -0.3239 - my_iou_metric_2: 0.8305 - val_loss: -0.0761 - val_my_iou_metric_2: 0.7985\n",
      "\n",
      "Epoch 00019: val_my_iou_metric_2 did not improve from 0.80200\n",
      "Epoch 20/200\n",
      "6400/6400 [==============================] - 107s 17ms/step - loss: -0.3477 - my_iou_metric_2: 0.8359 - val_loss: -0.1191 - val_my_iou_metric_2: 0.7999\n",
      "\n",
      "Epoch 00020: val_my_iou_metric_2 did not improve from 0.80200\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 21/200\n",
      "6400/6400 [==============================] - 109s 17ms/step - loss: -0.3737 - my_iou_metric_2: 0.8411 - val_loss: -0.1427 - val_my_iou_metric_2: 0.8063\n",
      "\n",
      "Epoch 00021: val_my_iou_metric_2 improved from 0.80200 to 0.80625, saving model to ../model/Unet_resnet_depth_act_trainlonger32_0.5.model\n",
      "Epoch 22/200\n",
      "6400/6400 [==============================] - 110s 17ms/step - loss: -0.3974 - my_iou_metric_2: 0.8457 - val_loss: -0.1729 - val_my_iou_metric_2: 0.8116\n",
      "\n",
      "Epoch 00022: val_my_iou_metric_2 improved from 0.80625 to 0.81163, saving model to ../model/Unet_resnet_depth_act_trainlonger32_0.5.model\n",
      "Epoch 23/200\n",
      "6400/6400 [==============================] - 109s 17ms/step - loss: -0.4105 - my_iou_metric_2: 0.8498 - val_loss: -0.1006 - val_my_iou_metric_2: 0.8008\n",
      "\n",
      "Epoch 00023: val_my_iou_metric_2 did not improve from 0.81163\n",
      "Epoch 24/200\n",
      "6400/6400 [==============================] - 110s 17ms/step - loss: -0.4109 - my_iou_metric_2: 0.8493 - val_loss: -0.1757 - val_my_iou_metric_2: 0.8129\n",
      "\n",
      "Epoch 00024: val_my_iou_metric_2 improved from 0.81163 to 0.81288, saving model to ../model/Unet_resnet_depth_act_trainlonger32_0.5.model\n",
      "Epoch 25/200\n",
      "6400/6400 [==============================] - 110s 17ms/step - loss: -0.4221 - my_iou_metric_2: 0.8512 - val_loss: -0.1274 - val_my_iou_metric_2: 0.7980\n",
      "\n",
      "Epoch 00025: val_my_iou_metric_2 did not improve from 0.81288\n",
      "Epoch 26/200\n",
      "6400/6400 [==============================] - 111s 17ms/step - loss: -0.4151 - my_iou_metric_2: 0.8495 - val_loss: -0.0762 - val_my_iou_metric_2: 0.7988\n",
      "\n",
      "Epoch 00026: val_my_iou_metric_2 did not improve from 0.81288\n",
      "Epoch 27/200\n",
      "6400/6400 [==============================] - 111s 17ms/step - loss: -0.4172 - my_iou_metric_2: 0.8488 - val_loss: -0.1604 - val_my_iou_metric_2: 0.8113\n",
      "\n",
      "Epoch 00027: val_my_iou_metric_2 did not improve from 0.81288\n",
      "Epoch 28/200\n",
      "6400/6400 [==============================] - 111s 17ms/step - loss: -0.4196 - my_iou_metric_2: 0.8507 - val_loss: -0.1614 - val_my_iou_metric_2: 0.8145\n",
      "\n",
      "Epoch 00028: val_my_iou_metric_2 improved from 0.81288 to 0.81450, saving model to ../model/Unet_resnet_depth_act_trainlonger32_0.5.model\n",
      "Epoch 29/200\n",
      "6400/6400 [==============================] - 111s 17ms/step - loss: -0.4181 - my_iou_metric_2: 0.8484 - val_loss: -0.1291 - val_my_iou_metric_2: 0.8073\n",
      "\n",
      "Epoch 00029: val_my_iou_metric_2 did not improve from 0.81450\n",
      "Epoch 30/200\n",
      "6400/6400 [==============================] - 111s 17ms/step - loss: -0.4271 - my_iou_metric_2: 0.8515 - val_loss: -0.1330 - val_my_iou_metric_2: 0.8080\n",
      "\n",
      "Epoch 00030: val_my_iou_metric_2 did not improve from 0.81450\n",
      "Epoch 31/200\n",
      "6400/6400 [==============================] - 111s 17ms/step - loss: -0.4463 - my_iou_metric_2: 0.8558 - val_loss: -0.1551 - val_my_iou_metric_2: 0.8133\n",
      "\n",
      "Epoch 00031: val_my_iou_metric_2 did not improve from 0.81450\n",
      "Epoch 32/200\n",
      "6400/6400 [==============================] - 111s 17ms/step - loss: -0.4362 - my_iou_metric_2: 0.8535 - val_loss: -0.1348 - val_my_iou_metric_2: 0.8065\n",
      "\n",
      "Epoch 00032: val_my_iou_metric_2 did not improve from 0.81450\n",
      "Epoch 33/200\n",
      "6400/6400 [==============================] - 112s 17ms/step - loss: -0.4499 - my_iou_metric_2: 0.8564 - val_loss: -0.1195 - val_my_iou_metric_2: 0.8087\n",
      "\n",
      "Epoch 00033: val_my_iou_metric_2 did not improve from 0.81450\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 34/200\n",
      "6400/6400 [==============================] - 112s 17ms/step - loss: -0.4714 - my_iou_metric_2: 0.8601 - val_loss: -0.1023 - val_my_iou_metric_2: 0.8072\n",
      "\n",
      "Epoch 00034: val_my_iou_metric_2 did not improve from 0.81450\n",
      "Epoch 35/200\n",
      "6400/6400 [==============================] - 112s 17ms/step - loss: -0.4762 - my_iou_metric_2: 0.8617 - val_loss: -0.1170 - val_my_iou_metric_2: 0.8091\n",
      "\n",
      "Epoch 00035: val_my_iou_metric_2 did not improve from 0.81450\n",
      "Epoch 36/200\n",
      "6400/6400 [==============================] - 112s 17ms/step - loss: -0.4770 - my_iou_metric_2: 0.8605 - val_loss: -0.1273 - val_my_iou_metric_2: 0.8105\n",
      "\n",
      "Epoch 00036: val_my_iou_metric_2 did not improve from 0.81450\n",
      "Epoch 37/200\n",
      "6400/6400 [==============================] - 112s 17ms/step - loss: -0.4776 - my_iou_metric_2: 0.8619 - val_loss: -0.1385 - val_my_iou_metric_2: 0.8141\n",
      "\n",
      "Epoch 00037: val_my_iou_metric_2 did not improve from 0.81450\n",
      "Epoch 38/200\n",
      "6400/6400 [==============================] - 112s 17ms/step - loss: -0.4832 - my_iou_metric_2: 0.8615 - val_loss: -0.1455 - val_my_iou_metric_2: 0.8110\n",
      "\n",
      "Epoch 00038: val_my_iou_metric_2 did not improve from 0.81450\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 39/200\n",
      "6400/6400 [==============================] - 112s 17ms/step - loss: -0.4937 - my_iou_metric_2: 0.8652 - val_loss: -0.1531 - val_my_iou_metric_2: 0.8166\n",
      "\n",
      "Epoch 00039: val_my_iou_metric_2 improved from 0.81450 to 0.81663, saving model to ../model/Unet_resnet_depth_act_trainlonger32_0.5.model\n",
      "Epoch 40/200\n",
      "6400/6400 [==============================] - 112s 18ms/step - loss: -0.4937 - my_iou_metric_2: 0.8641 - val_loss: -0.1466 - val_my_iou_metric_2: 0.8168\n",
      "\n",
      "Epoch 00040: val_my_iou_metric_2 improved from 0.81663 to 0.81675, saving model to ../model/Unet_resnet_depth_act_trainlonger32_0.5.model\n",
      "Epoch 41/200\n",
      "6400/6400 [==============================] - 111s 17ms/step - loss: -0.4957 - my_iou_metric_2: 0.8650 - val_loss: -0.1502 - val_my_iou_metric_2: 0.8151\n",
      "\n",
      "Epoch 00041: val_my_iou_metric_2 did not improve from 0.81675\n",
      "Epoch 42/200\n",
      "6400/6400 [==============================] - 112s 18ms/step - loss: -0.4973 - my_iou_metric_2: 0.8660 - val_loss: -0.1499 - val_my_iou_metric_2: 0.8145\n",
      "\n",
      "Epoch 00042: val_my_iou_metric_2 did not improve from 0.81675\n",
      "Epoch 43/200\n",
      "6400/6400 [==============================] - 112s 17ms/step - loss: -0.5101 - my_iou_metric_2: 0.8672 - val_loss: -0.1334 - val_my_iou_metric_2: 0.8164\n",
      "\n",
      "Epoch 00043: val_my_iou_metric_2 did not improve from 0.81675\n",
      "Epoch 44/200\n",
      "6400/6400 [==============================] - 112s 18ms/step - loss: -0.4980 - my_iou_metric_2: 0.8654 - val_loss: -0.1365 - val_my_iou_metric_2: 0.8183\n",
      "\n",
      "Epoch 00044: val_my_iou_metric_2 improved from 0.81675 to 0.81825, saving model to ../model/Unet_resnet_depth_act_trainlonger32_0.5.model\n",
      "Epoch 45/200\n",
      "6400/6400 [==============================] - 112s 18ms/step - loss: -0.5034 - my_iou_metric_2: 0.8663 - val_loss: -0.1203 - val_my_iou_metric_2: 0.8126\n",
      "\n",
      "Epoch 00045: val_my_iou_metric_2 did not improve from 0.81825\n",
      "Epoch 46/200\n",
      "6400/6400 [==============================] - 112s 18ms/step - loss: -0.5025 - my_iou_metric_2: 0.8661 - val_loss: -0.1432 - val_my_iou_metric_2: 0.8160\n",
      "\n",
      "Epoch 00046: val_my_iou_metric_2 did not improve from 0.81825\n",
      "Epoch 47/200\n",
      "6400/6400 [==============================] - 112s 18ms/step - loss: -0.4974 - my_iou_metric_2: 0.8669 - val_loss: -0.1654 - val_my_iou_metric_2: 0.8220\n",
      "\n",
      "Epoch 00047: val_my_iou_metric_2 improved from 0.81825 to 0.82200, saving model to ../model/Unet_resnet_depth_act_trainlonger32_0.5.model\n",
      "Epoch 48/200\n",
      "6400/6400 [==============================] - 112s 18ms/step - loss: -0.5116 - my_iou_metric_2: 0.8662 - val_loss: -0.1484 - val_my_iou_metric_2: 0.8187\n",
      "\n",
      "Epoch 00048: val_my_iou_metric_2 did not improve from 0.82200\n",
      "Epoch 49/200\n",
      "6400/6400 [==============================] - 112s 18ms/step - loss: -0.5221 - my_iou_metric_2: 0.8691 - val_loss: -0.1420 - val_my_iou_metric_2: 0.8164\n",
      "\n",
      "Epoch 00049: val_my_iou_metric_2 did not improve from 0.82200\n",
      "Epoch 50/200\n",
      "6400/6400 [==============================] - 112s 18ms/step - loss: -0.5114 - my_iou_metric_2: 0.8683 - val_loss: -0.1371 - val_my_iou_metric_2: 0.8185\n",
      "\n",
      "Epoch 00050: val_my_iou_metric_2 did not improve from 0.82200\n",
      "Epoch 51/200\n",
      "6400/6400 [==============================] - 112s 18ms/step - loss: -0.5057 - my_iou_metric_2: 0.8686 - val_loss: -0.1505 - val_my_iou_metric_2: 0.8196\n",
      "\n",
      "Epoch 00051: val_my_iou_metric_2 did not improve from 0.82200\n",
      "Epoch 52/200\n",
      "6400/6400 [==============================] - 110s 17ms/step - loss: -0.5118 - my_iou_metric_2: 0.8680 - val_loss: -0.1590 - val_my_iou_metric_2: 0.8194\n",
      "\n",
      "Epoch 00052: val_my_iou_metric_2 did not improve from 0.82200\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 53/200\n",
      "6400/6400 [==============================] - 109s 17ms/step - loss: -0.5144 - my_iou_metric_2: 0.8685 - val_loss: -0.1415 - val_my_iou_metric_2: 0.8183\n",
      "\n",
      "Epoch 00053: val_my_iou_metric_2 did not improve from 0.82200\n",
      "Epoch 54/200\n",
      "6400/6400 [==============================] - 109s 17ms/step - loss: -0.5216 - my_iou_metric_2: 0.8701 - val_loss: -0.1398 - val_my_iou_metric_2: 0.8193\n",
      "\n",
      "Epoch 00054: val_my_iou_metric_2 did not improve from 0.82200\n",
      "Epoch 55/200\n",
      "6400/6400 [==============================] - 110s 17ms/step - loss: -0.5201 - my_iou_metric_2: 0.8684 - val_loss: -0.1334 - val_my_iou_metric_2: 0.8152\n",
      "\n",
      "Epoch 00055: val_my_iou_metric_2 did not improve from 0.82200\n",
      "Epoch 56/200\n",
      "6400/6400 [==============================] - 109s 17ms/step - loss: -0.5265 - my_iou_metric_2: 0.8703 - val_loss: -0.1334 - val_my_iou_metric_2: 0.8185\n",
      "\n",
      "Epoch 00056: val_my_iou_metric_2 did not improve from 0.82200\n",
      "Epoch 57/200\n",
      "6400/6400 [==============================] - 109s 17ms/step - loss: -0.5296 - my_iou_metric_2: 0.8711 - val_loss: -0.1370 - val_my_iou_metric_2: 0.8196\n",
      "\n",
      "Epoch 00057: val_my_iou_metric_2 did not improve from 0.82200\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Epoch 58/200\n",
      "6400/6400 [==============================] - 109s 17ms/step - loss: -0.5306 - my_iou_metric_2: 0.8706 - val_loss: -0.1322 - val_my_iou_metric_2: 0.8172\n",
      "\n",
      "Epoch 00058: val_my_iou_metric_2 did not improve from 0.82200\n",
      "Epoch 59/200\n",
      "6400/6400 [==============================] - 109s 17ms/step - loss: -0.5199 - my_iou_metric_2: 0.8700 - val_loss: -0.1307 - val_my_iou_metric_2: 0.8185\n",
      "\n",
      "Epoch 00059: val_my_iou_metric_2 did not improve from 0.82200\n",
      "Epoch 60/200\n",
      "6400/6400 [==============================] - 108s 17ms/step - loss: -0.5332 - my_iou_metric_2: 0.8709 - val_loss: -0.1337 - val_my_iou_metric_2: 0.8162\n",
      "\n",
      "Epoch 00060: val_my_iou_metric_2 did not improve from 0.82200\n",
      "Epoch 61/200\n",
      "6400/6400 [==============================] - 108s 17ms/step - loss: -0.5305 - my_iou_metric_2: 0.8725 - val_loss: -0.1384 - val_my_iou_metric_2: 0.8184\n",
      "\n",
      "Epoch 00061: val_my_iou_metric_2 did not improve from 0.82200\n",
      "Epoch 62/200\n",
      "6400/6400 [==============================] - 108s 17ms/step - loss: -0.5302 - my_iou_metric_2: 0.8710 - val_loss: -0.1222 - val_my_iou_metric_2: 0.8104\n",
      "\n",
      "Epoch 00062: val_my_iou_metric_2 did not improve from 0.82200\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Epoch 63/200\n",
      "6400/6400 [==============================] - 108s 17ms/step - loss: -0.5301 - my_iou_metric_2: 0.8706 - val_loss: -0.1280 - val_my_iou_metric_2: 0.8152\n",
      "\n",
      "Epoch 00063: val_my_iou_metric_2 did not improve from 0.82200\n",
      "Epoch 64/200\n",
      "6400/6400 [==============================] - 108s 17ms/step - loss: -0.5262 - my_iou_metric_2: 0.8713 - val_loss: -0.1326 - val_my_iou_metric_2: 0.8181\n",
      "\n",
      "Epoch 00064: val_my_iou_metric_2 did not improve from 0.82200\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 108s 17ms/step - loss: -0.5361 - my_iou_metric_2: 0.8720 - val_loss: -0.1341 - val_my_iou_metric_2: 0.8178\n",
      "\n",
      "Epoch 00065: val_my_iou_metric_2 did not improve from 0.82200\n",
      "Epoch 66/200\n",
      " 352/6400 [>.............................] - ETA: 1:36 - loss: -0.5148 - my_iou_metric_2: 0.8710"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7408c7488ade>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_model_name = basic_name + '_stage1.model'\n",
    "model1 = load_model(save_model_name,custom_objects={'my_iou_metric': my_iou_metric})\n",
    "save_model_name = basic_name + '.model'\n",
    "# remove layter activation layer and use losvasz loss\n",
    "input_x = model1.layers[0].input\n",
    "output_layer = model1.layers[-1].input\n",
    "model = Model(input_x, output_layer)\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "\n",
    "# lovasz_loss need input range (-∞，+∞), so cancel the last \"sigmoid\" activation  \n",
    "# Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n",
    "model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\n",
    "\n",
    "#model.summary()\n",
    "board = keras.callbacks.TensorBoard(log_dir='log/resunet_depth_act_longer_{}_{}'.format(start_feature, dropout),\n",
    "                       histogram_freq=0, write_graph=True, write_images=False)\n",
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=20, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric_2', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.5, patience=5, min_lr=0.000001, verbose=1)\n",
    "epochs = 200\n",
    "batch_size = 16\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[board, model_checkpoint,reduce_lr,early_stopping], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n",
    "                                                   'lovasz_loss': lovasz_loss})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = predict_result(model,x_valid,img_size_target)\n",
    "## Scoring for last model, choose threshold by validation data \n",
    "thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
    "# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
    "thresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n",
    "\n",
    "# ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "# print(ious)\n",
    "ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "print(ious)\n",
    "\n",
    "# instead of using default 0 as threshold, use validation data to find the best threshold.\n",
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target)\n",
    "x_test = add_depth_bulk(x_test)\n",
    "\n",
    "preds_test = predict_result(model,x_test,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "pred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "t2 = time.time()\n",
    "\n",
    "print(f\"Usedtime = {t2-t1} s\")\n",
    "\n",
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub = sub.reset_index()\n",
    "save_result(sub, '../result/res_depthinchannel.csv', \n",
    "                        competition = 'tgs-salt-identification-challenge', \n",
    "                        send = False, index = False)\n",
    "\n",
    "t_finish = time.time()\n",
    "print(f\"Kernel run time = {(t_finish-t_start)/3600} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
