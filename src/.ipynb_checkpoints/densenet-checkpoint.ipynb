{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook #, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers import Input, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, concatenate, Concatenate, UpSampling2D, Activation\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras import layers\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n",
    "\n",
    "import time\n",
    "from kaggle_util import *\n",
    "from models import *\n",
    "\n",
    "import cv2\n",
    "\n",
    "t_start = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../model/densenet_1channel_0_None.model\n",
      "../model/densenet_1channel_0_None.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e15b5cfbcae4941bb3ae44192d99a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kownse/.local/lib/python3.6/site-packages/keras_preprocessing/image.py:487: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3e175adb054ac791205869f3679826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loading of training/testing ids and depths\n",
    "train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)\n",
    "\n",
    "train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=True)) for idx in tqdm_notebook(train_df.index)]\n",
    "train_df.images = train_df.images.apply(preprocess_input)\n",
    "train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBSET = len(train_df)\n",
    "train_df = train_df.head(SUBSET)\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "train_df.index.values,\n",
    "np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "train_df.coverage.values,\n",
    "train_df.z.values,\n",
    "test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 128, 128, 1)\n",
      "(800, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "#Data augmentation\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_densenet121_unet_sigmoid\n",
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/200\n",
      "6400/6400 [==============================] - 84s 13ms/step - loss: 0.4276 - my_iou_metric: 0.3327 - val_loss: 1.2319 - val_my_iou_metric: 0.0420\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.04200, saving model to ../model/densenet_1channel_0_None.model\n",
      "Epoch 2/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.3299 - my_iou_metric: 0.4743 - val_loss: 0.9711 - val_my_iou_metric: 0.3504\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.04200 to 0.35037, saving model to ../model/densenet_1channel_0_None.model\n",
      "Epoch 3/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.2856 - my_iou_metric: 0.5393 - val_loss: 0.2913 - val_my_iou_metric: 0.5403\n",
      "\n",
      "Epoch 00003: val_my_iou_metric improved from 0.35037 to 0.54025, saving model to ../model/densenet_1channel_0_None.model\n",
      "Epoch 4/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.2700 - my_iou_metric: 0.5511 - val_loss: 0.4093 - val_my_iou_metric: 0.2913\n",
      "\n",
      "Epoch 00004: val_my_iou_metric did not improve from 0.54025\n",
      "Epoch 5/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.2514 - my_iou_metric: 0.5505 - val_loss: 0.2779 - val_my_iou_metric: 0.5403\n",
      "\n",
      "Epoch 00005: val_my_iou_metric did not improve from 0.54025\n",
      "Epoch 6/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.2349 - my_iou_metric: 0.5794 - val_loss: 0.2678 - val_my_iou_metric: 0.5604\n",
      "\n",
      "Epoch 00006: val_my_iou_metric improved from 0.54025 to 0.56038, saving model to ../model/densenet_1channel_0_None.model\n",
      "Epoch 7/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.2200 - my_iou_metric: 0.5882 - val_loss: 0.2423 - val_my_iou_metric: 0.5375\n",
      "\n",
      "Epoch 00007: val_my_iou_metric did not improve from 0.56038\n",
      "Epoch 8/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.2145 - my_iou_metric: 0.6012 - val_loss: 0.3197 - val_my_iou_metric: 0.5515\n",
      "\n",
      "Epoch 00008: val_my_iou_metric did not improve from 0.56038\n",
      "Epoch 9/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.2095 - my_iou_metric: 0.6021 - val_loss: 0.3341 - val_my_iou_metric: 0.5304\n",
      "\n",
      "Epoch 00009: val_my_iou_metric did not improve from 0.56038\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 10/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.1793 - my_iou_metric: 0.6482 - val_loss: 0.1854 - val_my_iou_metric: 0.6831\n",
      "\n",
      "Epoch 00010: val_my_iou_metric improved from 0.56038 to 0.68312, saving model to ../model/densenet_1channel_0_None.model\n",
      "Epoch 11/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.1719 - my_iou_metric: 0.6579 - val_loss: 0.1713 - val_my_iou_metric: 0.6736\n",
      "\n",
      "Epoch 00011: val_my_iou_metric did not improve from 0.68312\n",
      "Epoch 12/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.1685 - my_iou_metric: 0.6607 - val_loss: 0.2047 - val_my_iou_metric: 0.6661\n",
      "\n",
      "Epoch 00012: val_my_iou_metric did not improve from 0.68312\n",
      "Epoch 13/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.1664 - my_iou_metric: 0.6624 - val_loss: 0.1789 - val_my_iou_metric: 0.6719\n",
      "\n",
      "Epoch 00013: val_my_iou_metric did not improve from 0.68312\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 14/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.1424 - my_iou_metric: 0.6913 - val_loss: 0.1661 - val_my_iou_metric: 0.6877\n",
      "\n",
      "Epoch 00014: val_my_iou_metric improved from 0.68312 to 0.68775, saving model to ../model/densenet_1channel_0_None.model\n",
      "Epoch 15/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.1386 - my_iou_metric: 0.6975 - val_loss: 0.1661 - val_my_iou_metric: 0.6944\n",
      "\n",
      "Epoch 00015: val_my_iou_metric improved from 0.68775 to 0.69437, saving model to ../model/densenet_1channel_0_None.model\n",
      "Epoch 16/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.1316 - my_iou_metric: 0.7035 - val_loss: 0.1835 - val_my_iou_metric: 0.6887\n",
      "\n",
      "Epoch 00016: val_my_iou_metric did not improve from 0.69437\n",
      "Epoch 17/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.1265 - my_iou_metric: 0.7044 - val_loss: 0.1723 - val_my_iou_metric: 0.6785\n",
      "\n",
      "Epoch 00017: val_my_iou_metric did not improve from 0.69437\n",
      "Epoch 18/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.1194 - my_iou_metric: 0.7163 - val_loss: 0.1731 - val_my_iou_metric: 0.6905\n",
      "\n",
      "Epoch 00018: val_my_iou_metric did not improve from 0.69437\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 19/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.1041 - my_iou_metric: 0.7311 - val_loss: 0.1847 - val_my_iou_metric: 0.6924\n",
      "\n",
      "Epoch 00019: val_my_iou_metric did not improve from 0.69437\n",
      "Epoch 20/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.0970 - my_iou_metric: 0.7347 - val_loss: 0.1786 - val_my_iou_metric: 0.7019\n",
      "\n",
      "Epoch 00020: val_my_iou_metric improved from 0.69437 to 0.70188, saving model to ../model/densenet_1channel_0_None.model\n",
      "Epoch 21/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.0978 - my_iou_metric: 0.7298 - val_loss: 0.2044 - val_my_iou_metric: 0.6954\n",
      "\n",
      "Epoch 00021: val_my_iou_metric did not improve from 0.70188\n",
      "Epoch 22/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.0892 - my_iou_metric: 0.7448 - val_loss: 0.1880 - val_my_iou_metric: 0.6935\n",
      "\n",
      "Epoch 00022: val_my_iou_metric did not improve from 0.70188\n",
      "Epoch 23/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.0815 - my_iou_metric: 0.7521 - val_loss: 0.2018 - val_my_iou_metric: 0.7041\n",
      "\n",
      "Epoch 00023: val_my_iou_metric improved from 0.70188 to 0.70412, saving model to ../model/densenet_1channel_0_None.model\n",
      "Epoch 24/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.0882 - my_iou_metric: 0.7496 - val_loss: 0.2066 - val_my_iou_metric: 0.7113\n",
      "\n",
      "Epoch 00024: val_my_iou_metric improved from 0.70412 to 0.71125, saving model to ../model/densenet_1channel_0_None.model\n",
      "Epoch 25/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.0766 - my_iou_metric: 0.7585 - val_loss: 0.2100 - val_my_iou_metric: 0.7131\n",
      "\n",
      "Epoch 00025: val_my_iou_metric improved from 0.71125 to 0.71313, saving model to ../model/densenet_1channel_0_None.model\n",
      "Epoch 26/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.0790 - my_iou_metric: 0.7568 - val_loss: 0.2082 - val_my_iou_metric: 0.7032\n",
      "\n",
      "Epoch 00026: val_my_iou_metric did not improve from 0.71313\n",
      "Epoch 27/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.0737 - my_iou_metric: 0.7594 - val_loss: 0.1922 - val_my_iou_metric: 0.7233\n",
      "\n",
      "Epoch 00027: val_my_iou_metric improved from 0.71313 to 0.72325, saving model to ../model/densenet_1channel_0_None.model\n",
      "Epoch 28/200\n",
      "6400/6400 [==============================] - 63s 10ms/step - loss: 0.0680 - my_iou_metric: 0.7704 - val_loss: 0.2279 - val_my_iou_metric: 0.7025\n",
      "\n",
      "Epoch 00028: val_my_iou_metric did not improve from 0.72325\n",
      "Epoch 29/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.0665 - my_iou_metric: 0.7765 - val_loss: 0.2085 - val_my_iou_metric: 0.7013\n",
      "\n",
      "Epoch 00029: val_my_iou_metric did not improve from 0.72325\n",
      "Epoch 30/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.0693 - my_iou_metric: 0.7707 - val_loss: 0.2208 - val_my_iou_metric: 0.7015\n",
      "\n",
      "Epoch 00030: val_my_iou_metric did not improve from 0.72325\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 31/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.0605 - my_iou_metric: 0.7885 - val_loss: 0.2211 - val_my_iou_metric: 0.7084\n",
      "\n",
      "Epoch 00031: val_my_iou_metric did not improve from 0.72325\n",
      "Epoch 32/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.0583 - my_iou_metric: 0.7858 - val_loss: 0.2414 - val_my_iou_metric: 0.7109\n",
      "\n",
      "Epoch 00032: val_my_iou_metric did not improve from 0.72325\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.0572 - my_iou_metric: 0.7888 - val_loss: 0.2241 - val_my_iou_metric: 0.7015\n",
      "\n",
      "Epoch 00033: val_my_iou_metric did not improve from 0.72325\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 34/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.0544 - my_iou_metric: 0.7981 - val_loss: 0.2319 - val_my_iou_metric: 0.7079\n",
      "\n",
      "Epoch 00034: val_my_iou_metric did not improve from 0.72325\n",
      "Epoch 35/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.0527 - my_iou_metric: 0.7987 - val_loss: 0.2408 - val_my_iou_metric: 0.7048\n",
      "\n",
      "Epoch 00035: val_my_iou_metric did not improve from 0.72325\n",
      "Epoch 36/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.0523 - my_iou_metric: 0.7957 - val_loss: 0.2373 - val_my_iou_metric: 0.7071\n",
      "\n",
      "Epoch 00036: val_my_iou_metric did not improve from 0.72325\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Epoch 37/200\n",
      "6400/6400 [==============================] - 64s 10ms/step - loss: 0.0508 - my_iou_metric: 0.8013 - val_loss: 0.2431 - val_my_iou_metric: 0.7106\n",
      "\n",
      "Epoch 00037: val_my_iou_metric did not improve from 0.72325\n",
      "Epoch 00037: early stopping\n"
     ]
    }
   ],
   "source": [
    "dropout = 0.0\n",
    "weights = 'None'\n",
    "basic_name = '../model/densenet_1channel_{}_{}'.format(dropout, weights)\n",
    "save_model_name = basic_name + '.model'\n",
    "submission_file = basic_name + '.csv'\n",
    "\n",
    "print(save_model_name)\n",
    "print(submission_file)\n",
    "\n",
    "# model\n",
    "\n",
    "input_layer = Input((img_size_target, img_size_target, 1))\n",
    "model1 = get_densenet121_unet_sigmoid(input_layer,(img_size_target, img_size_target), 0.0, None)\n",
    "\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "model1.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=[my_iou_metric])\n",
    "\n",
    "board = keras.callbacks.TensorBoard(log_dir='log/densenet_1_channel_{}_{}'.format(dropout, weights),\n",
    "                       histogram_freq=0, write_graph=True, write_images=False)\n",
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric', mode = 'max',patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric', mode = 'max',factor=0.5, patience=3, min_lr=0.00001, verbose=1)\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "history = model1.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[board, early_stopping, model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/200\n",
      "6400/6400 [==============================] - 155s 24ms/step - loss: 0.2583 - my_iou_metric_2: 0.6742 - val_loss: 0.2285 - val_my_iou_metric_2: 0.6635\n",
      "\n",
      "Epoch 00001: val_my_iou_metric_2 improved from -inf to 0.66350, saving model to ../model/densenet_1channel_0_None.model\n",
      "Epoch 2/200\n",
      "6400/6400 [==============================] - 134s 21ms/step - loss: 0.1912 - my_iou_metric_2: 0.6787 - val_loss: 0.2837 - val_my_iou_metric_2: 0.6741\n",
      "\n",
      "Epoch 00002: val_my_iou_metric_2 improved from 0.66350 to 0.67412, saving model to ../model/densenet_1channel_0_None.model\n",
      "Epoch 3/200\n",
      "6400/6400 [==============================] - 134s 21ms/step - loss: 0.1329 - my_iou_metric_2: 0.6907 - val_loss: 0.2766 - val_my_iou_metric_2: 0.6545\n",
      "\n",
      "Epoch 00003: val_my_iou_metric_2 did not improve from 0.67412\n",
      "Epoch 4/200\n",
      "6400/6400 [==============================] - 134s 21ms/step - loss: 0.1003 - my_iou_metric_2: 0.6943 - val_loss: 0.1003 - val_my_iou_metric_2: 0.6929\n",
      "\n",
      "Epoch 00004: val_my_iou_metric_2 improved from 0.67412 to 0.69288, saving model to ../model/densenet_1channel_0_None.model\n",
      "Epoch 5/200\n",
      "1728/6400 [=======>......................] - ETA: 1:30 - loss: 0.2007 - my_iou_metric_2: 0.6633"
     ]
    }
   ],
   "source": [
    "model1 = load_model(save_model_name,custom_objects={'my_iou_metric': my_iou_metric})\n",
    "# remove layter activation layer and use losvasz loss\n",
    "input_x = model1.layers[0].input\n",
    "output_layer = model1.layers[-1].input\n",
    "model = Model(input_x, output_layer)\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "\n",
    "# lovasz_loss need input range (-∞，+∞), so cancel the last \"sigmoid\" activation  \n",
    "# Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n",
    "model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\n",
    "\n",
    "#model.summary()\n",
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric_2', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.5, patience=3, min_lr=0.00001, verbose=1)\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[board, model_checkpoint,reduce_lr,early_stopping], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n",
    "                                                   'lovasz_loss': lovasz_loss})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = predict_result(model,x_valid,img_size_target)\n",
    "## Scoring for last model, choose threshold by validation data \n",
    "thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
    "# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
    "thresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n",
    "\n",
    "# ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "# print(ious)\n",
    "ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "print(ious)\n",
    "\n",
    "# instead of using default 0 as threshold, use validation data to find the best threshold.\n",
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test = np.array([(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale = False))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)\n",
    "x_test = [upsample(preprocess_input(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale=True)))) for idx in tqdm_notebook(test_df.index)]\n",
    "x_test = np.array(x_test).reshape(-1, img_size_target, img_size_target, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = predict_result(model,x_test,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "pred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "t2 = time.time()\n",
    "\n",
    "print(f\"Usedtime = {t2-t1} s\")\n",
    "\n",
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub = sub.reset_index()\n",
    "save_result(sub, '../result/inception.csv', \n",
    "                        competition = 'tgs-salt-identification-challenge', \n",
    "                        send = False, index = False)\n",
    "\n",
    "t_finish = time.time()\n",
    "print(f\"Kernel run time = {(t_finish-t_start)/3600} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
