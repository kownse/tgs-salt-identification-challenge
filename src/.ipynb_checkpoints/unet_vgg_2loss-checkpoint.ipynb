{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook #, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n",
    "\n",
    "import time\n",
    "from kaggle_util import *\n",
    "from models import *\n",
    "\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 128\n",
    "\n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n",
    "\n",
    "# Build model\n",
    "def build_vgg_unet_model(input_shape, DropoutRatio = 0.5, weights = 'imagenet'):\n",
    "    input_layer = Input(input_shape)\n",
    "    \n",
    "    # block 1\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding=\"same\")(input_layer)\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding=\"same\")(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2), strides=(2,2))(conv1)\n",
    "\n",
    "    # block 2\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding=\"same\")(pool1)\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding=\"same\")(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2), strides=(2,2))(conv2)\n",
    "    \n",
    "    # block3\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding=\"same\")(pool2)\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding=\"same\")(conv3)\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding=\"same\")(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2), strides=(2,2))(conv3)\n",
    "    \n",
    "    # block4\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding=\"same\")(pool3)\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding=\"same\")(conv4)\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding=\"same\")(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2), strides=(2,2))(conv4)\n",
    "    \n",
    "    # block5\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding=\"same\")(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding=\"same\")(conv5)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding=\"same\")(conv5)\n",
    "    pool5 = MaxPooling2D((2, 2), strides=(2,2))(conv5)\n",
    "    \n",
    "    # Middle\n",
    "    if DropoutRatio > 0:\n",
    "        pool5 = Dropout(DropoutRatio)(pool5)\n",
    "    convm = Conv2D(1024, (3, 3), activation=\"relu\", padding=\"same\")(pool5)\n",
    "    \n",
    "    # uconv5\n",
    "    deconv5 = Conv2DTranspose(512, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv5 = concatenate([deconv5, conv5])\n",
    "    if DropoutRatio > 0:\n",
    "        uconv5 = Dropout(DropoutRatio)(uconv5)\n",
    "    uconv5 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(uconv5)\n",
    "#     uconv5 = residual_block(uconv5,512)\n",
    "    uconv5 = residual_block(uconv5,512, True)\n",
    "    \n",
    "    # uconv4\n",
    "    deconv4 = Conv2DTranspose(512, (3, 3), strides=(2, 2), padding=\"same\")(uconv5)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    if DropoutRatio > 0:\n",
    "        uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    uconv4 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "#     uconv4 = residual_block(uconv4,512)\n",
    "    uconv4 = residual_block(uconv4,512, True)\n",
    "    \n",
    "    # uconv3\n",
    "    deconv3 = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])\n",
    "    if DropoutRatio > 0:\n",
    "        uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    uconv3 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "#     uconv3 = residual_block(uconv3,256)\n",
    "    uconv3 = residual_block(uconv3,256, True)\n",
    "    \n",
    "    # uconv2\n",
    "    deconv2 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    if DropoutRatio > 0:\n",
    "        uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    uconv2 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "#     uconv2 = residual_block(uconv2,128)\n",
    "    uconv2 = residual_block(uconv2,128, True)\n",
    "    \n",
    "    # uconv1\n",
    "    deconv1 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    if DropoutRatio > 0:\n",
    "        uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    uconv1 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "#     uconv1 = residual_block(uconv1,64)\n",
    "    uconv1 = residual_block(uconv1,64, True)\n",
    "\n",
    "    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n",
    "#     output_layer =  Activation('sigmoid')(output_layer_noActi)\n",
    "    \n",
    "    class_out = layers.Flatten(name='flatten')(pool5)\n",
    "\n",
    "    class_out = Dense(256)(class_out)\n",
    "    class_out = BatchActivate(class_out)\n",
    "    class_out = Dropout(0.5)(class_out)\n",
    "\n",
    "    class_out = Dense(64)(class_out)\n",
    "    class_out = BatchActivate(class_out)\n",
    "    class_out = Dropout(0.5)(class_out)\n",
    "    \n",
    "    class_out_layer = layers.Dense(1, activation = 'sigmoid', name='empty_out')(class_out)\n",
    "    \n",
    "    final_out_noact = multiply([output_layer_noActi, class_out_layer])\n",
    "    final_out_noact = BatchNormalization()(final_out_noact)\n",
    "    final_out =  Activation('sigmoid', name = 'segment_out')(final_out_noact)\n",
    "    \n",
    "    model = Model(input_layer, [final_out, class_out_layer])\n",
    "    \n",
    "    if weights == 'imagenet':\n",
    "        vgg = VGG16(input_shape = input_shape, include_top = False, weights = 'imagenet')\n",
    "        for i in range(1, len(vgg.layers)):\n",
    "            model.layers[i].set_weights(vgg.layers[i].get_weights())\n",
    "            model.layers[i].trainable = False\n",
    "            \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f594c5b1885f4bf6988eabdc704c08ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6cf69919644e73936054be7282c934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kownse/.local/lib/python3.6/site-packages/keras_preprocessing/image.py:487: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading of training/testing ids and depths\n",
    "train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)\n",
    "\n",
    "train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=False)) for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)\n",
    "train_df['empty'] = train_df['masks'].apply(lambda x: (x.max()!=0) * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBSET = len(train_df)\n",
    "train_df = train_df.head(SUBSET)\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test, empty_train, empty_test = train_test_split(\n",
    "train_df.index.values,\n",
    "np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 3), \n",
    "np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "train_df.coverage.values,\n",
    "train_df.z.values,\n",
    "train_df['empty'].values,\n",
    "test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 128, 128, 3)\n",
      "(800, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "#Data augmentation\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "empty_train = np.append(empty_train, empty_train, axis=0)\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../model/Unet_vgg_2loss_32_0.5.model\n",
      "../model/Unet_vgg_2loss_32_0.5.csv\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "dropout = 0.5\n",
    "base_name = 'Unet_vgg_2loss_{}_{}'.format(batch_size, dropout)\n",
    "basic_name = '../model/{}'.format(base_name)\n",
    "save_model_name = basic_name + '.model'\n",
    "submission_file = basic_name + '.csv'\n",
    "\n",
    "print(save_model_name)\n",
    "print(submission_file)\n",
    "\n",
    "losses = {\n",
    "    'empty_out' : 'binary_crossentropy',\n",
    "    'segment_out': 'binary_crossentropy',\n",
    "}\n",
    "lossWeights = {\n",
    "    'empty_out' : 0.2,\n",
    "    'segment_out':2,\n",
    "}\n",
    "\n",
    "y_combine_rain = {\n",
    "    'empty_out' : empty_train,\n",
    "    'segment_out':y_train,\n",
    "    #'final_out' : y_train,\n",
    "}\n",
    "\n",
    "y_combine_test = {\n",
    "    'empty_out' : empty_test,\n",
    "    'segment_out':y_valid,\n",
    "    #'final_out' : y_valid,\n",
    "}\n",
    "\n",
    "board = keras.callbacks.TensorBoard(log_dir='log/{}'.format(base_name),\n",
    "                       histogram_freq=0, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/200\n",
      "6400/6400 [==============================] - 103s 16ms/step - loss: 0.7667 - segment_out_loss: 0.3449 - empty_out_loss: 0.3852 - segment_out_my_iou_metric: 0.5235 - empty_out_my_iou_metric: 0.8270 - val_loss: 0.5344 - val_segment_out_loss: 0.2244 - val_empty_out_loss: 0.4283 - val_segment_out_my_iou_metric: 0.6556 - val_empty_out_my_iou_metric: 0.8250\n",
      "\n",
      "Epoch 00001: val_segment_out_my_iou_metric improved from -inf to 0.65562, saving model to ../model/Unet_vgg_2loss_32_0.5.model\n",
      "Epoch 2/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.4517 - segment_out_loss: 0.1952 - empty_out_loss: 0.3063 - segment_out_my_iou_metric: 0.6712 - empty_out_my_iou_metric: 0.8670 - val_loss: 0.4227 - val_segment_out_loss: 0.1806 - val_empty_out_loss: 0.3071 - val_segment_out_my_iou_metric: 0.7061 - val_empty_out_my_iou_metric: 0.8638\n",
      "\n",
      "Epoch 00002: val_segment_out_my_iou_metric improved from 0.65562 to 0.70613, saving model to ../model/Unet_vgg_2loss_32_0.5.model\n",
      "Epoch 3/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.3699 - segment_out_loss: 0.1589 - empty_out_loss: 0.2605 - segment_out_my_iou_metric: 0.7142 - empty_out_my_iou_metric: 0.8878 - val_loss: 0.4152 - val_segment_out_loss: 0.1767 - val_empty_out_loss: 0.3092 - val_segment_out_my_iou_metric: 0.7070 - val_empty_out_my_iou_metric: 0.8638\n",
      "\n",
      "Epoch 00003: val_segment_out_my_iou_metric improved from 0.70613 to 0.70700, saving model to ../model/Unet_vgg_2loss_32_0.5.model\n",
      "Epoch 4/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.3263 - segment_out_loss: 0.1382 - empty_out_loss: 0.2491 - segment_out_my_iou_metric: 0.7301 - empty_out_my_iou_metric: 0.8895 - val_loss: 0.4317 - val_segment_out_loss: 0.1875 - val_empty_out_loss: 0.2838 - val_segment_out_my_iou_metric: 0.7198 - val_empty_out_my_iou_metric: 0.8788\n",
      "\n",
      "Epoch 00004: val_segment_out_my_iou_metric improved from 0.70700 to 0.71975, saving model to ../model/Unet_vgg_2loss_32_0.5.model\n",
      "Epoch 5/200\n",
      "6400/6400 [==============================] - 96s 15ms/step - loss: 0.2919 - segment_out_loss: 0.1228 - empty_out_loss: 0.2318 - segment_out_my_iou_metric: 0.7531 - empty_out_my_iou_metric: 0.9022 - val_loss: 0.4186 - val_segment_out_loss: 0.1768 - val_empty_out_loss: 0.3252 - val_segment_out_my_iou_metric: 0.7286 - val_empty_out_my_iou_metric: 0.8738\n",
      "\n",
      "Epoch 00005: val_segment_out_my_iou_metric improved from 0.71975 to 0.72862, saving model to ../model/Unet_vgg_2loss_32_0.5.model\n",
      "Epoch 6/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.2592 - segment_out_loss: 0.1076 - empty_out_loss: 0.2197 - segment_out_my_iou_metric: 0.7706 - empty_out_my_iou_metric: 0.9059 - val_loss: 0.4096 - val_segment_out_loss: 0.1738 - val_empty_out_loss: 0.3098 - val_segment_out_my_iou_metric: 0.7414 - val_empty_out_my_iou_metric: 0.8750\n",
      "\n",
      "Epoch 00006: val_segment_out_my_iou_metric improved from 0.72862 to 0.74138, saving model to ../model/Unet_vgg_2loss_32_0.5.model\n",
      "Epoch 7/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.2487 - segment_out_loss: 0.1033 - empty_out_loss: 0.2105 - segment_out_my_iou_metric: 0.7775 - empty_out_my_iou_metric: 0.9111 - val_loss: 0.3931 - val_segment_out_loss: 0.1670 - val_empty_out_loss: 0.2957 - val_segment_out_my_iou_metric: 0.7440 - val_empty_out_my_iou_metric: 0.8825\n",
      "\n",
      "Epoch 00007: val_segment_out_my_iou_metric improved from 0.74138 to 0.74400, saving model to ../model/Unet_vgg_2loss_32_0.5.model\n",
      "Epoch 8/200\n",
      "6400/6400 [==============================] - 96s 15ms/step - loss: 0.2175 - segment_out_loss: 0.0897 - empty_out_loss: 0.1903 - segment_out_my_iou_metric: 0.7916 - empty_out_my_iou_metric: 0.9202 - val_loss: 0.4160 - val_segment_out_loss: 0.1752 - val_empty_out_loss: 0.3277 - val_segment_out_my_iou_metric: 0.7388 - val_empty_out_my_iou_metric: 0.8775\n",
      "\n",
      "Epoch 00008: val_segment_out_my_iou_metric did not improve from 0.74400\n",
      "Epoch 9/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.1984 - segment_out_loss: 0.0807 - empty_out_loss: 0.1848 - segment_out_my_iou_metric: 0.8033 - empty_out_my_iou_metric: 0.9269 - val_loss: 0.4865 - val_segment_out_loss: 0.2118 - val_empty_out_loss: 0.3144 - val_segment_out_my_iou_metric: 0.7218 - val_empty_out_my_iou_metric: 0.8588\n",
      "\n",
      "Epoch 00009: val_segment_out_my_iou_metric did not improve from 0.74400\n",
      "Epoch 10/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.1822 - segment_out_loss: 0.0736 - empty_out_loss: 0.1748 - segment_out_my_iou_metric: 0.8123 - empty_out_my_iou_metric: 0.9250 - val_loss: 0.4544 - val_segment_out_loss: 0.1941 - val_empty_out_loss: 0.3309 - val_segment_out_my_iou_metric: 0.7401 - val_empty_out_my_iou_metric: 0.8688\n",
      "\n",
      "Epoch 00010: val_segment_out_my_iou_metric did not improve from 0.74400\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 11/200\n",
      "6400/6400 [==============================] - 96s 15ms/step - loss: 0.1487 - segment_out_loss: 0.0586 - empty_out_loss: 0.1578 - segment_out_my_iou_metric: 0.8315 - empty_out_my_iou_metric: 0.9402 - val_loss: 0.4291 - val_segment_out_loss: 0.1823 - val_empty_out_loss: 0.3228 - val_segment_out_my_iou_metric: 0.7333 - val_empty_out_my_iou_metric: 0.8738\n",
      "\n",
      "Epoch 00011: val_segment_out_my_iou_metric did not improve from 0.74400\n",
      "Epoch 12/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.1314 - segment_out_loss: 0.0521 - empty_out_loss: 0.1362 - segment_out_my_iou_metric: 0.8448 - empty_out_my_iou_metric: 0.9472 - val_loss: 0.4870 - val_segment_out_loss: 0.2087 - val_empty_out_loss: 0.3482 - val_segment_out_my_iou_metric: 0.7402 - val_empty_out_my_iou_metric: 0.8725\n",
      "\n",
      "Epoch 00012: val_segment_out_my_iou_metric did not improve from 0.74400\n",
      "Epoch 13/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.1170 - segment_out_loss: 0.0465 - empty_out_loss: 0.1203 - segment_out_my_iou_metric: 0.8523 - empty_out_my_iou_metric: 0.9550 - val_loss: 0.4696 - val_segment_out_loss: 0.2000 - val_empty_out_loss: 0.3482 - val_segment_out_my_iou_metric: 0.7404 - val_empty_out_my_iou_metric: 0.8788\n",
      "\n",
      "Epoch 00013: val_segment_out_my_iou_metric did not improve from 0.74400\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 14/200\n",
      "6400/6400 [==============================] - 96s 15ms/step - loss: 0.1035 - segment_out_loss: 0.0404 - empty_out_loss: 0.1133 - segment_out_my_iou_metric: 0.8611 - empty_out_my_iou_metric: 0.9577 - val_loss: 0.4753 - val_segment_out_loss: 0.2008 - val_empty_out_loss: 0.3680 - val_segment_out_my_iou_metric: 0.7343 - val_empty_out_my_iou_metric: 0.8712\n",
      "\n",
      "Epoch 00014: val_segment_out_my_iou_metric did not improve from 0.74400\n",
      "Epoch 15/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.0970 - segment_out_loss: 0.0381 - empty_out_loss: 0.1045 - segment_out_my_iou_metric: 0.8655 - empty_out_my_iou_metric: 0.9613 - val_loss: 0.4696 - val_segment_out_loss: 0.1992 - val_empty_out_loss: 0.3565 - val_segment_out_my_iou_metric: 0.7389 - val_empty_out_my_iou_metric: 0.8725\n",
      "\n",
      "Epoch 00015: val_segment_out_my_iou_metric did not improve from 0.74400\n",
      "Epoch 16/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.0928 - segment_out_loss: 0.0363 - empty_out_loss: 0.1010 - segment_out_my_iou_metric: 0.8674 - empty_out_my_iou_metric: 0.9613 - val_loss: 0.5223 - val_segment_out_loss: 0.2250 - val_empty_out_loss: 0.3612 - val_segment_out_my_iou_metric: 0.7342 - val_empty_out_my_iou_metric: 0.8775\n",
      "\n",
      "Epoch 00016: val_segment_out_my_iou_metric did not improve from 0.74400\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 17/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.0845 - segment_out_loss: 0.0332 - empty_out_loss: 0.0905 - segment_out_my_iou_metric: 0.8737 - empty_out_my_iou_metric: 0.9634 - val_loss: 0.5099 - val_segment_out_loss: 0.2182 - val_empty_out_loss: 0.3674 - val_segment_out_my_iou_metric: 0.7388 - val_empty_out_my_iou_metric: 0.8775\n",
      "\n",
      "Epoch 00017: val_segment_out_my_iou_metric did not improve from 0.74400\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model\n",
    "model1 = build_vgg_unet_model((img_size_target, img_size_target, 3), \n",
    "                              DropoutRatio = dropout, weights = 'imagenet')\n",
    "\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "model1.compile(loss=losses, loss_weights=lossWeights, optimizer=c, metrics=[my_iou_metric])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_segment_out_my_iou_metric', mode = 'max',patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_segment_out_my_iou_metric', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_segment_out_my_iou_metric', mode = 'max',factor=0.5, patience=3, min_lr=0.00001, verbose=1)\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "history = model1.fit(x_train, y_combine_rain,\n",
    "                    validation_data=[x_valid, y_combine_test], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[board, early_stopping, model_checkpoint,reduce_lr], \n",
    "                    verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "model1 = load_model(save_model_name,custom_objects={'my_iou_metric': my_iou_metric})\n",
    "\n",
    "base_name = 'Unet_vgg_2loss_stage2_{}_{}'.format(batch_size, dropout)\n",
    "basic_name = '../model/{}'.format(base_name)\n",
    "save_model_name = basic_name + '.model'\n",
    "submission_file = basic_name + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/200\n",
      "6400/6400 [==============================] - 100s 16ms/step - loss: 0.6721 - segment_out_loss: 0.3032 - empty_out_loss: 0.3286 - segment_out_my_iou_metric_2: 0.6655 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 1.5707 - val_segment_out_loss: 0.7505 - val_empty_out_loss: 0.3488 - val_segment_out_my_iou_metric_2: 0.7186 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00001: val_segment_out_my_iou_metric_2 improved from -inf to 0.71862, saving model to ../model/Unet_vgg_2loss_stage2_32_0.5.model\n",
      "Epoch 2/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.6080 - segment_out_loss: 0.2675 - empty_out_loss: 0.3653 - segment_out_my_iou_metric_2: 0.4729 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.9143 - val_segment_out_loss: 0.4236 - val_empty_out_loss: 0.3360 - val_segment_out_my_iou_metric_2: 0.5951 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00002: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "Epoch 3/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.3849 - segment_out_loss: 0.1613 - empty_out_loss: 0.3117 - segment_out_my_iou_metric_2: 0.4844 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.7164 - val_segment_out_loss: 0.3247 - val_empty_out_loss: 0.3348 - val_segment_out_my_iou_metric_2: 0.4755 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00003: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "Epoch 4/200\n",
      "6400/6400 [==============================] - 96s 15ms/step - loss: 0.3270 - segment_out_loss: 0.1352 - empty_out_loss: 0.2827 - segment_out_my_iou_metric_2: 0.4721 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.6481 - val_segment_out_loss: 0.2886 - val_empty_out_loss: 0.3541 - val_segment_out_my_iou_metric_2: 0.3946 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00004: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "Epoch 5/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.3110 - segment_out_loss: 0.1286 - empty_out_loss: 0.2690 - segment_out_my_iou_metric_2: 0.4880 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.8058 - val_segment_out_loss: 0.3673 - val_empty_out_loss: 0.3560 - val_segment_out_my_iou_metric_2: 0.4886 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00005: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "Epoch 6/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.4710 - segment_out_loss: 0.2062 - empty_out_loss: 0.2935 - segment_out_my_iou_metric_2: 0.4471 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.8760 - val_segment_out_loss: 0.4053 - val_empty_out_loss: 0.3271 - val_segment_out_my_iou_metric_2: 0.4866 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00006: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 7/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.3002 - segment_out_loss: 0.1243 - empty_out_loss: 0.2580 - segment_out_my_iou_metric_2: 0.4832 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.5978 - val_segment_out_loss: 0.2666 - val_empty_out_loss: 0.3235 - val_segment_out_my_iou_metric_2: 0.4795 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00007: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "Epoch 8/200\n",
      "6400/6400 [==============================] - 96s 15ms/step - loss: 0.3034 - segment_out_loss: 0.1265 - empty_out_loss: 0.2525 - segment_out_my_iou_metric_2: 0.4830 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.6528 - val_segment_out_loss: 0.2933 - val_empty_out_loss: 0.3307 - val_segment_out_my_iou_metric_2: 0.4558 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00008: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "Epoch 9/200\n",
      "6400/6400 [==============================] - 96s 15ms/step - loss: 0.2538 - segment_out_loss: 0.1028 - empty_out_loss: 0.2408 - segment_out_my_iou_metric_2: 0.5278 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.7171 - val_segment_out_loss: 0.3255 - val_empty_out_loss: 0.3303 - val_segment_out_my_iou_metric_2: 0.5280 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00009: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "Epoch 10/200\n",
      "6400/6400 [==============================] - 96s 15ms/step - loss: 0.2622 - segment_out_loss: 0.1071 - empty_out_loss: 0.2398 - segment_out_my_iou_metric_2: 0.5171 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.7391 - val_segment_out_loss: 0.3374 - val_empty_out_loss: 0.3217 - val_segment_out_my_iou_metric_2: 0.5248 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00010: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "Epoch 11/200\n",
      "6400/6400 [==============================] - 96s 15ms/step - loss: 0.3106 - segment_out_loss: 0.1278 - empty_out_loss: 0.2750 - segment_out_my_iou_metric_2: 0.4421 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.5955 - val_segment_out_loss: 0.2632 - val_empty_out_loss: 0.3451 - val_segment_out_my_iou_metric_2: 0.4121 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00011: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 12/200\n",
      "6400/6400 [==============================] - 96s 15ms/step - loss: 0.2432 - segment_out_loss: 0.0962 - empty_out_loss: 0.2538 - segment_out_my_iou_metric_2: 0.5023 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.6756 - val_segment_out_loss: 0.3046 - val_empty_out_loss: 0.3321 - val_segment_out_my_iou_metric_2: 0.4778 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00012: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "Epoch 13/200\n",
      "6400/6400 [==============================] - 96s 15ms/step - loss: 0.2596 - segment_out_loss: 0.1045 - empty_out_loss: 0.2526 - segment_out_my_iou_metric_2: 0.4880 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.6689 - val_segment_out_loss: 0.3018 - val_empty_out_loss: 0.3263 - val_segment_out_my_iou_metric_2: 0.4540 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00013: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "Epoch 14/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.2445 - segment_out_loss: 0.0976 - empty_out_loss: 0.2467 - segment_out_my_iou_metric_2: 0.4722 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.8061 - val_segment_out_loss: 0.3692 - val_empty_out_loss: 0.3391 - val_segment_out_my_iou_metric_2: 0.4792 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00014: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "Epoch 15/200\n",
      "6400/6400 [==============================] - 96s 15ms/step - loss: 0.2368 - segment_out_loss: 0.0943 - empty_out_loss: 0.2411 - segment_out_my_iou_metric_2: 0.4998 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.6946 - val_segment_out_loss: 0.3136 - val_empty_out_loss: 0.3368 - val_segment_out_my_iou_metric_2: 0.4984 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00015: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "Epoch 16/200\n",
      "6400/6400 [==============================] - 96s 15ms/step - loss: 0.2181 - segment_out_loss: 0.0860 - empty_out_loss: 0.2310 - segment_out_my_iou_metric_2: 0.5232 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.7319 - val_segment_out_loss: 0.3321 - val_empty_out_loss: 0.3385 - val_segment_out_my_iou_metric_2: 0.5439 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00016: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 17/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.2211 - segment_out_loss: 0.0883 - empty_out_loss: 0.2227 - segment_out_my_iou_metric_2: 0.5415 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.7632 - val_segment_out_loss: 0.3488 - val_empty_out_loss: 0.3276 - val_segment_out_my_iou_metric_2: 0.5589 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00017: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "Epoch 18/200\n",
      "6400/6400 [==============================] - 96s 15ms/step - loss: 0.2312 - segment_out_loss: 0.0930 - empty_out_loss: 0.2261 - segment_out_my_iou_metric_2: 0.5229 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.7127 - val_segment_out_loss: 0.3229 - val_empty_out_loss: 0.3346 - val_segment_out_my_iou_metric_2: 0.5142 - val_empty_out_my_iou_metric_2: 0.6100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00018: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "Epoch 19/200\n",
      "6400/6400 [==============================] - 96s 15ms/step - loss: 0.2002 - segment_out_loss: 0.0772 - empty_out_loss: 0.2292 - segment_out_my_iou_metric_2: 0.5395 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.7434 - val_segment_out_loss: 0.3386 - val_empty_out_loss: 0.3308 - val_segment_out_my_iou_metric_2: 0.5444 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00019: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "Epoch 20/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.1914 - segment_out_loss: 0.0746 - empty_out_loss: 0.2106 - segment_out_my_iou_metric_2: 0.5665 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.7394 - val_segment_out_loss: 0.3371 - val_empty_out_loss: 0.3265 - val_segment_out_my_iou_metric_2: 0.5508 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00020: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "Epoch 21/200\n",
      "6400/6400 [==============================] - 97s 15ms/step - loss: 0.1821 - segment_out_loss: 0.0703 - empty_out_loss: 0.2069 - segment_out_my_iou_metric_2: 0.5759 - empty_out_my_iou_metric_2: 0.6094 - val_loss: 0.7661 - val_segment_out_loss: 0.3509 - val_empty_out_loss: 0.3219 - val_segment_out_my_iou_metric_2: 0.5725 - val_empty_out_my_iou_metric_2: 0.6100\n",
      "\n",
      "Epoch 00021: val_segment_out_my_iou_metric_2 did not improve from 0.71862\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 00021: early stopping\n"
     ]
    }
   ],
   "source": [
    "# remove layter activation layer and use losvasz loss\n",
    "input_x = model1.layers[0].input\n",
    "model1.layers[-1].name = 'segment_out_old'\n",
    "\n",
    "output_layer = model1.layers[-2]\n",
    "output_layer.name = 'segment_out'\n",
    "output_layer = output_layer.output\n",
    "\n",
    "empty_out = model1.get_layer(\"empty_out\").output\n",
    "model = Model(input_x, [output_layer, empty_out])\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "\n",
    "# lovasz_loss need input range (-∞，+∞), so cancel the last \"sigmoid\" activation  \n",
    "# Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n",
    "model.compile(loss=losses, loss_weights=lossWeights, optimizer=c, metrics=[my_iou_metric_2])\n",
    "del model1\n",
    "\n",
    "#model.summary()\n",
    "early_stopping = EarlyStopping(monitor='val_segment_out_my_iou_metric_2', mode = 'max',patience=20, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_segment_out_my_iou_metric_2', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_segment_out_my_iou_metric_2', mode = 'max',factor=0.5, patience=5, min_lr=0.00001, verbose=1)\n",
    "epochs = 200\n",
    "\n",
    "history = model.fit(x_train, y_combine_rain,\n",
    "                    validation_data=[x_valid, y_combine_test], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[board, model_checkpoint,reduce_lr,early_stopping], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n",
    "                                                   'lovasz_loss': lovasz_loss})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-20da40c9c7c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_size_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m## Scoring for last model, choose threshold by validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mthresholds_ori\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresholds_ori\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mthresholds_ori\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/extend/code/kaggle/salt/src/models.py\u001b[0m in \u001b[0;36mpredict_result\u001b[0;34m(model, x_test, img_size_target)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_size_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# predict both orginal and reflect x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0mx_test_reflect\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfliplr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     \u001b[0mpreds_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m     \u001b[0mpreds_test2_refect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_reflect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mpreds_test\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfliplr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds_test2_refect\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "preds_valid = predict_result(model,x_valid,img_size_target)\n",
    "## Scoring for last model, choose threshold by validation data \n",
    "thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
    "# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
    "thresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n",
    "\n",
    "# ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "# print(ious)\n",
    "ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "print(ious)\n",
    "\n",
    "# instead of using default 0 as threshold, use validation data to find the best threshold.\n",
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 3)\n",
    "\n",
    "preds_test = predict_result(model,x_test,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "pred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "t2 = time.time()\n",
    "\n",
    "print(f\"Usedtime = {t2-t1} s\")\n",
    "\n",
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub = sub.reset_index()\n",
    "save_result(sub, '../result/{}.csv'.format(base_name), \n",
    "                        competition = 'tgs-salt-identification-challenge', \n",
    "                        send = True, index = False)\n",
    "\n",
    "t_finish = time.time()\n",
    "print(f\"Kernel run time = {(t_finish-t_start)/3600} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
