{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from tqdm import tqdm #, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n",
    "\n",
    "from albumentations import (\n",
    "    PadIfNeeded,\n",
    "    HorizontalFlip,\n",
    "    VerticalFlip,    \n",
    "    CenterCrop,    \n",
    "    Crop,\n",
    "    Compose,\n",
    "    Transpose,\n",
    "    RandomRotate90,\n",
    "    ElasticTransform,\n",
    "    GridDistortion, \n",
    "    OpticalDistortion,\n",
    "    RandomSizedCrop,\n",
    "    OneOf,\n",
    "    CLAHE,\n",
    "    RandomContrast,\n",
    "    RandomGamma,\n",
    "    RandomBrightness\n",
    ")\n",
    "\n",
    "import time\n",
    "from kaggle_util import *\n",
    "from models import *\n",
    "\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "\n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n",
    "\n",
    "def build_model_deeper(input_layer, start_neurons, DropoutRatio = 0.5):\n",
    "    # 101 -> 50\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n",
    "    conv1 = residual_block_sc(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block_sc(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block_sc(conv1,start_neurons * 1, True)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "    # 50 -> 25\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
    "    conv2 = residual_block_sc(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block_sc(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block_sc(conv2,start_neurons * 2, True)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "    # 25 -> 12\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
    "    conv3 = residual_block_sc(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block_sc(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block_sc(conv3,start_neurons * 4, True)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "    # 12 -> 6\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
    "    conv4 = residual_block_sc(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block_sc(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block_sc(conv4,start_neurons * 8, True)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block_sc(convm,start_neurons * 16)\n",
    "    convm = residual_block_sc(convm,start_neurons * 16)\n",
    "    convm = residual_block_sc(convm,start_neurons * 16, True)\n",
    "    \n",
    "    # 6 -> 12\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block_sc(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block_sc(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block_sc(uconv4,start_neurons * 8, True)\n",
    "    \n",
    "    # 12 -> 25\n",
    "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])    \n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block_sc(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block_sc(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block_sc(uconv3,start_neurons * 4, True)\n",
    "\n",
    "    # 25 -> 50\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "        \n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block_sc(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block_sc(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block_sc(uconv2,start_neurons * 2, True)\n",
    "    \n",
    "    # 50 -> 101\n",
    "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block_sc(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block_sc(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block_sc(uconv1,start_neurons * 1, True)\n",
    "    \n",
    "    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
    "    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n",
    "    output_layer =  Activation('sigmoid')(output_layer_noActi)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4000 [00:00<?, ?it/s]/home/kownse/.local/lib/python3.6/site-packages/keras_preprocessing/image.py:487: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n",
      "100%|██████████| 4000/4000 [00:02<00:00, 1544.75it/s]\n",
      "100%|██████████| 4000/4000 [00:01<00:00, 2195.62it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Loading of training/testing ids and depths\n",
    "train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)\n",
    "\n",
    "train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm(train_df.index)]\n",
    "train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm(train_df.index)]\n",
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)\n",
    "train_df['hassalt'] = train_df['masks'].apply(lambda x: (x.max()!=0) * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splits(train_df, train_idx, val_idx):\n",
    "    X_train = train_df.iloc[train_idx]\n",
    "    X_valid = train_df.iloc[val_idx]\n",
    "    x_train = np.array(X_train.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)\n",
    "    x_valid = np.array(X_valid.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)\n",
    "    msk_train = np.array(X_train.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)\n",
    "    msk_val = np.array(X_valid.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)\n",
    "    y_train = X_train.hassalt.values\n",
    "    y_valid = X_valid.hassalt.values\n",
    "    id_train = X_train.index.values\n",
    "    id_valid = X_valid.index.values\n",
    "    return x_train, x_valid, msk_train, msk_val, y_train, y_valid, id_train, id_valid\n",
    "\n",
    "def argument(x_train, msk_train, y_train):\n",
    "    aug_img = []\n",
    "    aug_msk = []\n",
    "    aug_y = []\n",
    "    augments = [\n",
    "        (1, HorizontalFlip(p=1)),\n",
    "#         (0.25, VerticalFlip(p=1)),\n",
    "#         (0.25, RandomRotate90(p=1)),\n",
    "#         (0.25, Transpose(p=1)),\n",
    "        (0.15, ElasticTransform(p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03)),\n",
    "        (0.15, GridDistortion(p=1)),\n",
    "        (0.15, OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)),\n",
    "#         (0.5, RandomSizedCrop(p=1, min_max_height=(int(img_size_ori / 2), img_size_ori), height=img_size_ori, width=img_size_ori)),\n",
    "    ]\n",
    "\n",
    "    for ratio, aug in tqdm(augments):\n",
    "        selidx = np.random.choice(x_train.shape[0], int(x_train.shape[0] * ratio), replace=False)\n",
    "        for idx in tqdm(selidx):\n",
    "            augmented = aug(image=x_train[idx], mask=msk_train[idx])\n",
    "            aimg = augmented['image']\n",
    "            amsk = augmented['mask']\n",
    "            if len(aimg.shape) < 3:\n",
    "                aimg = aimg[...,np.newaxis]\n",
    "            if len(amsk.shape) < 3:\n",
    "                amsk = amsk[...,np.newaxis]\n",
    "            aug_img.append(aimg)\n",
    "            aug_msk.append(amsk)\n",
    "            aug_y.append(y_train[idx])\n",
    "\n",
    "    aug_img = np.asarray(aug_img)\n",
    "    aug_msk = np.asarray(aug_msk)\n",
    "    aug_y = np.asarray(aug_y)\n",
    "    x_train = np.append(x_train, aug_img, axis=0)\n",
    "    msk_train = np.append(msk_train, aug_msk, axis=0)\n",
    "    y_train = np.append(y_train, aug_y, axis=0)\n",
    "    print(x_train.shape)\n",
    "    print(msk_train.shape)\n",
    "    print(y_train.shape)\n",
    "    \n",
    "    return x_train, msk_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model(fold, x_train, y_train, x_valid, y_valid, id_valid):\n",
    "    start_feature = 32\n",
    "    batch_size = 32\n",
    "    dropout = 0.5\n",
    "    base_name = 'Unet_seresnet2_deeper_{}_{}_{}_{}'.format(start_feature, batch_size, dropout, fold)\n",
    "    save_model_name = '../model/segmenter/{}.model'.format(base_name)\n",
    "    submission_dir = '../result/segmenter/{}.csv'.format(base_name)\n",
    "    oof_dir = '../result/segmenter_oof/{}'.format(base_name)\n",
    "\n",
    "    print(save_model_name)\n",
    "    print(submission_dir)\n",
    "    print(oof_dir)\n",
    "\n",
    "    # model\n",
    "    input_layer = Input((img_size_target, img_size_target, 1))\n",
    "    output_layer = build_model_deeper(input_layer, start_feature,dropout)\n",
    "\n",
    "    model1 = Model(input_layer, output_layer)\n",
    "\n",
    "    c = optimizers.adam(lr = 0.01)\n",
    "    model1.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=[my_iou_metric])\n",
    "\n",
    "    board = keras.callbacks.TensorBoard(log_dir='log/segmenter/{}'.format(base_name),\n",
    "                           histogram_freq=0, write_graph=True, write_images=False)\n",
    "    early_stopping = EarlyStopping(monitor='val_my_iou_metric', mode = 'max',patience=12, verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric', \n",
    "                                       mode = 'max', save_best_only=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric', mode = 'max',factor=0.5, patience=3, min_lr=0.00001, verbose=1)\n",
    "\n",
    "    epochs = 200\n",
    "\n",
    "    history = model1.fit(x_train, y_train,\n",
    "                        validation_data=[x_valid, y_valid], \n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[board, early_stopping, model_checkpoint,reduce_lr], \n",
    "                        verbose=1)\n",
    "    \n",
    "    model1 = load_model(save_model_name,custom_objects={'my_iou_metric': my_iou_metric})\n",
    "    # remove layter activation layer and use losvasz loss\n",
    "    input_x = model1.layers[0].input\n",
    "    output_layer = model1.layers[-1].input\n",
    "    model = Model(input_x, output_layer)\n",
    "    c = optimizers.adam(lr = 0.01)\n",
    "\n",
    "    # lovasz_loss need input range (-∞，+∞), so cancel the last \"sigmoid\" activation  \n",
    "    # Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n",
    "    model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\n",
    "\n",
    "    #model.summary()\n",
    "    early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=20, verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric_2', \n",
    "                                       mode = 'max', save_best_only=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.5, patience=5, min_lr=0.00001, verbose=1)\n",
    "    epochs = 200\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        validation_data=[x_valid, y_valid], \n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[board, model_checkpoint,reduce_lr,early_stopping], \n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3199 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 555/3199 [00:00<00:00, 5506.63it/s]\u001b[A\n",
      " 36%|███▌      | 1136/3199 [00:00<00:00, 5654.56it/s]\u001b[A\n",
      " 51%|█████▏    | 1647/3199 [00:00<00:00, 5469.11it/s]\u001b[A\n",
      " 70%|███████   | 2242/3199 [00:00<00:00, 5587.59it/s]\u001b[A\n",
      " 87%|████████▋ | 2792/3199 [00:00<00:00, 5569.40it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  1.73it/s].72it/s]\u001b[A\n",
      "  0%|          | 0/479 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|▋         | 32/479 [00:00<00:01, 310.98it/s]\u001b[A\n",
      " 13%|█▎        | 63/479 [00:00<00:01, 308.18it/s]\u001b[A\n",
      " 20%|█▉        | 95/479 [00:00<00:01, 309.13it/s]\u001b[A\n",
      " 26%|██▌       | 125/479 [00:00<00:01, 303.85it/s]\u001b[A\n",
      " 33%|███▎      | 156/479 [00:00<00:01, 304.28it/s]\u001b[A\n",
      " 39%|███▉      | 187/479 [00:00<00:00, 304.85it/s]\u001b[A\n",
      " 46%|████▌     | 218/479 [00:00<00:00, 305.29it/s]\u001b[A\n",
      " 52%|█████▏    | 249/479 [00:00<00:00, 305.44it/s]\u001b[A\n",
      " 59%|█████▊    | 281/479 [00:00<00:00, 306.11it/s]\u001b[A\n",
      " 65%|██████▍   | 311/479 [00:01<00:00, 299.22it/s]\u001b[A\n",
      " 72%|███████▏  | 344/479 [00:01<00:00, 301.27it/s]\u001b[A\n",
      " 78%|███████▊  | 374/479 [00:01<00:00, 298.57it/s]\u001b[A\n",
      " 84%|████████▍ | 404/479 [00:01<00:00, 298.30it/s]\u001b[A\n",
      " 91%|█████████ | 435/479 [00:01<00:00, 298.89it/s]\u001b[A\n",
      " 98%|█████████▊| 468/479 [00:01<00:00, 300.80it/s]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.09s/it]it/s]\u001b[A\n",
      "  0%|          | 0/479 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 137/479 [00:00<00:00, 1349.68it/s]\u001b[A\n",
      " 57%|█████▋    | 271/479 [00:00<00:00, 1344.66it/s]\u001b[A\n",
      " 85%|████████▌ | 409/479 [00:00<00:00, 1354.26it/s]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:02<00:00,  1.19it/s]8it/s]\u001b[A\n",
      "  0%|          | 0/479 [00:00<?, ?it/s]\u001b[A\n",
      " 51%|█████     | 243/479 [00:00<00:00, 2406.88it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.47it/s]0it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7835, 101, 101, 1)\n",
      "(7835, 101, 101, 1)\n",
      "(7835,)\n",
      "../model/segmenter/Unet_seresnet_deeper_32_32_0.5_0.model\n",
      "../result/segmenter/Unet_seresnet_deeper_32_32_0.5_0.csv\n",
      "../result/segmenter_oof/Unet_seresnet_deeper_32_32_0.5_0\n",
      "Train on 7835 samples, validate on 801 samples\n",
      "Epoch 1/200\n",
      "7835/7835 [==============================] - 121s 15ms/step - loss: 0.4581 - my_iou_metric: 0.3127 - val_loss: 1.3412 - val_my_iou_metric: 0.3295\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.32946, saving model to ../model/segmenter/Unet_seresnet_deeper_32_32_0.5_0.model\n",
      "Epoch 2/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.3826 - my_iou_metric: 0.4439 - val_loss: 0.4527 - val_my_iou_metric: 0.3022\n",
      "\n",
      "Epoch 00002: val_my_iou_metric did not improve from 0.32946\n",
      "Epoch 3/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.3328 - my_iou_metric: 0.5030 - val_loss: 0.4761 - val_my_iou_metric: 0.3820\n",
      "\n",
      "Epoch 00003: val_my_iou_metric improved from 0.32946 to 0.38202, saving model to ../model/segmenter/Unet_seresnet_deeper_32_32_0.5_0.model\n",
      "Epoch 4/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.2786 - my_iou_metric: 0.5420 - val_loss: 0.2936 - val_my_iou_metric: 0.3166\n",
      "\n",
      "Epoch 00004: val_my_iou_metric did not improve from 0.38202\n",
      "Epoch 5/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.2772 - my_iou_metric: 0.5584 - val_loss: 0.4209 - val_my_iou_metric: 0.3803\n",
      "\n",
      "Epoch 00005: val_my_iou_metric did not improve from 0.38202\n",
      "Epoch 6/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.2465 - my_iou_metric: 0.5793 - val_loss: 0.2266 - val_my_iou_metric: 0.5916\n",
      "\n",
      "Epoch 00006: val_my_iou_metric improved from 0.38202 to 0.59164, saving model to ../model/segmenter/Unet_seresnet_deeper_32_32_0.5_0.model\n",
      "Epoch 7/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.2312 - my_iou_metric: 0.6043 - val_loss: 0.3618 - val_my_iou_metric: 0.4032\n",
      "\n",
      "Epoch 00007: val_my_iou_metric did not improve from 0.59164\n",
      "Epoch 8/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.2188 - my_iou_metric: 0.6165 - val_loss: 0.7239 - val_my_iou_metric: 0.4117\n",
      "\n",
      "Epoch 00008: val_my_iou_metric did not improve from 0.59164\n",
      "Epoch 9/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.2133 - my_iou_metric: 0.6292 - val_loss: 0.4236 - val_my_iou_metric: 0.4526\n",
      "\n",
      "Epoch 00009: val_my_iou_metric did not improve from 0.59164\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 10/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.1906 - my_iou_metric: 0.6610 - val_loss: 0.2187 - val_my_iou_metric: 0.6778\n",
      "\n",
      "Epoch 00010: val_my_iou_metric improved from 0.59164 to 0.67778, saving model to ../model/segmenter/Unet_seresnet_deeper_32_32_0.5_0.model\n",
      "Epoch 11/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.1777 - my_iou_metric: 0.6773 - val_loss: 0.1764 - val_my_iou_metric: 0.6903\n",
      "\n",
      "Epoch 00011: val_my_iou_metric improved from 0.67778 to 0.69026, saving model to ../model/segmenter/Unet_seresnet_deeper_32_32_0.5_0.model\n",
      "Epoch 12/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.1740 - my_iou_metric: 0.6874 - val_loss: 0.1674 - val_my_iou_metric: 0.7061\n",
      "\n",
      "Epoch 00012: val_my_iou_metric improved from 0.69026 to 0.70612, saving model to ../model/segmenter/Unet_seresnet_deeper_32_32_0.5_0.model\n",
      "Epoch 13/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.1678 - my_iou_metric: 0.6889 - val_loss: 0.1748 - val_my_iou_metric: 0.7089\n",
      "\n",
      "Epoch 00013: val_my_iou_metric improved from 0.70612 to 0.70886, saving model to ../model/segmenter/Unet_seresnet_deeper_32_32_0.5_0.model\n",
      "Epoch 14/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.1653 - my_iou_metric: 0.6937 - val_loss: 0.1690 - val_my_iou_metric: 0.7000\n",
      "\n",
      "Epoch 00014: val_my_iou_metric did not improve from 0.70886\n",
      "Epoch 15/200\n",
      "7835/7835 [==============================] - 106s 14ms/step - loss: 0.1599 - my_iou_metric: 0.6965 - val_loss: 0.1743 - val_my_iou_metric: 0.6978\n",
      "\n",
      "Epoch 00015: val_my_iou_metric did not improve from 0.70886\n",
      "Epoch 16/200\n",
      "7835/7835 [==============================] - 106s 14ms/step - loss: 0.1564 - my_iou_metric: 0.7043 - val_loss: 0.2015 - val_my_iou_metric: 0.6959\n",
      "\n",
      "Epoch 00016: val_my_iou_metric did not improve from 0.70886\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 17/200\n",
      "7835/7835 [==============================] - 106s 14ms/step - loss: 0.1443 - my_iou_metric: 0.7152 - val_loss: 0.1444 - val_my_iou_metric: 0.7371\n",
      "\n",
      "Epoch 00017: val_my_iou_metric improved from 0.70886 to 0.73708, saving model to ../model/segmenter/Unet_seresnet_deeper_32_32_0.5_0.model\n",
      "Epoch 18/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.1378 - my_iou_metric: 0.7231 - val_loss: 0.1416 - val_my_iou_metric: 0.7313\n",
      "\n",
      "Epoch 00018: val_my_iou_metric did not improve from 0.73708\n",
      "Epoch 19/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.1353 - my_iou_metric: 0.7219 - val_loss: 0.1480 - val_my_iou_metric: 0.7462\n",
      "\n",
      "Epoch 00019: val_my_iou_metric improved from 0.73708 to 0.74619, saving model to ../model/segmenter/Unet_seresnet_deeper_32_32_0.5_0.model\n",
      "Epoch 20/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.1314 - my_iou_metric: 0.7254 - val_loss: 0.1815 - val_my_iou_metric: 0.7261\n",
      "\n",
      "Epoch 00020: val_my_iou_metric did not improve from 0.74619\n",
      "Epoch 21/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.1346 - my_iou_metric: 0.7277 - val_loss: 0.1415 - val_my_iou_metric: 0.7567\n",
      "\n",
      "Epoch 00021: val_my_iou_metric improved from 0.74619 to 0.75668, saving model to ../model/segmenter/Unet_seresnet_deeper_32_32_0.5_0.model\n",
      "Epoch 22/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.1272 - my_iou_metric: 0.7321 - val_loss: 0.1461 - val_my_iou_metric: 0.7407\n",
      "\n",
      "Epoch 00022: val_my_iou_metric did not improve from 0.75668\n",
      "Epoch 23/200\n",
      "7835/7835 [==============================] - 106s 14ms/step - loss: 0.1276 - my_iou_metric: 0.7311 - val_loss: 0.1661 - val_my_iou_metric: 0.7124\n",
      "\n",
      "Epoch 00023: val_my_iou_metric did not improve from 0.75668\n",
      "Epoch 24/200\n",
      "7835/7835 [==============================] - 106s 14ms/step - loss: 0.1247 - my_iou_metric: 0.7355 - val_loss: 0.1803 - val_my_iou_metric: 0.7109\n",
      "\n",
      "Epoch 00024: val_my_iou_metric did not improve from 0.75668\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 25/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.1188 - my_iou_metric: 0.7377 - val_loss: 0.1574 - val_my_iou_metric: 0.7483\n",
      "\n",
      "Epoch 00025: val_my_iou_metric did not improve from 0.75668\n",
      "Epoch 26/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.1100 - my_iou_metric: 0.7480 - val_loss: 0.1590 - val_my_iou_metric: 0.7576\n",
      "\n",
      "Epoch 00026: val_my_iou_metric improved from 0.75668 to 0.75755, saving model to ../model/segmenter/Unet_seresnet_deeper_32_32_0.5_0.model\n",
      "Epoch 27/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.1101 - my_iou_metric: 0.7472 - val_loss: 0.1514 - val_my_iou_metric: 0.7502\n",
      "\n",
      "Epoch 00027: val_my_iou_metric did not improve from 0.75755\n",
      "Epoch 28/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.1053 - my_iou_metric: 0.7488 - val_loss: 0.1795 - val_my_iou_metric: 0.7474\n",
      "\n",
      "Epoch 00028: val_my_iou_metric did not improve from 0.75755\n",
      "Epoch 29/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.1060 - my_iou_metric: 0.7512 - val_loss: 0.1706 - val_my_iou_metric: 0.7388\n",
      "\n",
      "Epoch 00029: val_my_iou_metric did not improve from 0.75755\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 30/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.1032 - my_iou_metric: 0.7560 - val_loss: 0.1619 - val_my_iou_metric: 0.7552\n",
      "\n",
      "Epoch 00030: val_my_iou_metric did not improve from 0.75755\n",
      "Epoch 31/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.0990 - my_iou_metric: 0.7599 - val_loss: 0.1574 - val_my_iou_metric: 0.7574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00031: val_my_iou_metric did not improve from 0.75755\n",
      "Epoch 32/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.0998 - my_iou_metric: 0.7563 - val_loss: 0.1538 - val_my_iou_metric: 0.7546\n",
      "\n",
      "Epoch 00032: val_my_iou_metric did not improve from 0.75755\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 33/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.0939 - my_iou_metric: 0.7605 - val_loss: 0.1527 - val_my_iou_metric: 0.7668\n",
      "\n",
      "Epoch 00033: val_my_iou_metric improved from 0.75755 to 0.76679, saving model to ../model/segmenter/Unet_seresnet_deeper_32_32_0.5_0.model\n",
      "Epoch 34/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.0956 - my_iou_metric: 0.7588 - val_loss: 0.1539 - val_my_iou_metric: 0.7605\n",
      "\n",
      "Epoch 00034: val_my_iou_metric did not improve from 0.76679\n",
      "Epoch 35/200\n",
      "7835/7835 [==============================] - 106s 14ms/step - loss: 0.0941 - my_iou_metric: 0.7647 - val_loss: 0.1563 - val_my_iou_metric: 0.7596\n",
      "\n",
      "Epoch 00035: val_my_iou_metric did not improve from 0.76679\n",
      "Epoch 36/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.0957 - my_iou_metric: 0.7613 - val_loss: 0.1594 - val_my_iou_metric: 0.7632\n",
      "\n",
      "Epoch 00036: val_my_iou_metric did not improve from 0.76679\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Epoch 37/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.0910 - my_iou_metric: 0.7658 - val_loss: 0.1594 - val_my_iou_metric: 0.7665\n",
      "\n",
      "Epoch 00037: val_my_iou_metric did not improve from 0.76679\n",
      "Epoch 38/200\n",
      "7835/7835 [==============================] - 106s 14ms/step - loss: 0.0899 - my_iou_metric: 0.7634 - val_loss: 0.1576 - val_my_iou_metric: 0.7635\n",
      "\n",
      "Epoch 00038: val_my_iou_metric did not improve from 0.76679\n",
      "Epoch 39/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.0913 - my_iou_metric: 0.7643 - val_loss: 0.1586 - val_my_iou_metric: 0.7613\n",
      "\n",
      "Epoch 00039: val_my_iou_metric did not improve from 0.76679\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Epoch 40/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.0887 - my_iou_metric: 0.7653 - val_loss: 0.1624 - val_my_iou_metric: 0.7630\n",
      "\n",
      "Epoch 00040: val_my_iou_metric did not improve from 0.76679\n",
      "Epoch 41/200\n",
      "7835/7835 [==============================] - 106s 14ms/step - loss: 0.0914 - my_iou_metric: 0.7643 - val_loss: 0.1623 - val_my_iou_metric: 0.7638\n",
      "\n",
      "Epoch 00041: val_my_iou_metric did not improve from 0.76679\n",
      "Epoch 42/200\n",
      "7835/7835 [==============================] - 106s 14ms/step - loss: 0.0898 - my_iou_metric: 0.7669 - val_loss: 0.1614 - val_my_iou_metric: 0.7648\n",
      "\n",
      "Epoch 00042: val_my_iou_metric did not improve from 0.76679\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Epoch 43/200\n",
      "7835/7835 [==============================] - 106s 14ms/step - loss: 0.0876 - my_iou_metric: 0.7662 - val_loss: 0.1623 - val_my_iou_metric: 0.7654\n",
      "\n",
      "Epoch 00043: val_my_iou_metric did not improve from 0.76679\n",
      "Epoch 44/200\n",
      "7835/7835 [==============================] - 106s 13ms/step - loss: 0.0884 - my_iou_metric: 0.7634 - val_loss: 0.1627 - val_my_iou_metric: 0.7640\n",
      "\n",
      "Epoch 00044: val_my_iou_metric did not improve from 0.76679\n",
      "Epoch 45/200\n",
      "7835/7835 [==============================] - 106s 14ms/step - loss: 0.0884 - my_iou_metric: 0.7671 - val_loss: 0.1622 - val_my_iou_metric: 0.7640\n",
      "\n",
      "Epoch 00045: val_my_iou_metric did not improve from 0.76679\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Epoch 00045: early stopping\n",
      "Train on 7835 samples, validate on 801 samples\n",
      "Epoch 1/200\n",
      "7835/7835 [==============================] - 177s 23ms/step - loss: 0.1759 - my_iou_metric_2: 0.7189 - val_loss: 0.1482 - val_my_iou_metric_2: 0.7281\n",
      "\n",
      "Epoch 00001: val_my_iou_metric_2 improved from -inf to 0.72809, saving model to ../model/segmenter/Unet_seresnet_deeper_32_32_0.5_0.model\n",
      "Epoch 2/200\n",
      "7835/7835 [==============================] - 161s 21ms/step - loss: 0.2011 - my_iou_metric_2: 0.7090 - val_loss: 0.4052 - val_my_iou_metric_2: 0.6715\n",
      "\n",
      "Epoch 00002: val_my_iou_metric_2 did not improve from 0.72809\n",
      "Epoch 3/200\n",
      "7835/7835 [==============================] - 161s 21ms/step - loss: 0.1266 - my_iou_metric_2: 0.7271 - val_loss: 0.4310 - val_my_iou_metric_2: 0.6218\n",
      "\n",
      "Epoch 00003: val_my_iou_metric_2 did not improve from 0.72809\n",
      "Epoch 4/200\n",
      "2944/7835 [==========>...................] - ETA: 1:35 - loss: 0.1262 - my_iou_metric_2: 0.7246"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d81230f025bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsk_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsk_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsk_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsk_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-77c8111182b3>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(fold, x_train, y_train, x_valid, y_valid, id_valid)\u001b[0m\n\u001b[1;32m     60\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                         verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folds = [0]\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['hassalt'])):\n",
    "    if fold not in folds:\n",
    "        print('skip fold', fold)\n",
    "        continue\n",
    "        \n",
    "    x_train, x_valid, msk_train, msk_val, y_train, y_valid, id_train, id_valid = get_splits(train_df, train_idx, val_idx)\n",
    "    x_train, msk_train, y_train = argument(x_train, msk_train, y_train)\n",
    "    \n",
    "    model = train_model(fold, x_train, msk_train, x_valid, msk_val, id_valid)\n",
    "    \n",
    "    from keras import backend as K\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
