{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook #, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n",
    "\n",
    "import time\n",
    "from kaggle_util import *\n",
    "from models import *\n",
    "\n",
    "from albumentations import (\n",
    "    PadIfNeeded,\n",
    "    HorizontalFlip,\n",
    "    VerticalFlip,    \n",
    "    CenterCrop,    \n",
    "    Crop,\n",
    "    Compose,\n",
    "    Transpose,\n",
    "    RandomRotate90,\n",
    "    ElasticTransform,\n",
    "    GridDistortion, \n",
    "    OpticalDistortion,\n",
    "    RandomSizedCrop,\n",
    "    OneOf,\n",
    "    CLAHE,\n",
    "    RandomContrast,\n",
    "    RandomGamma,\n",
    "    RandomBrightness\n",
    ")\n",
    "\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "\n",
    "def visualize(image, mask, original_image=None, original_mask=None):\n",
    "    fontsize = 18\n",
    "    \n",
    "    if original_image is None and original_mask is None:\n",
    "        f, ax = plt.subplots(2, 1, figsize=(8, 8))\n",
    "\n",
    "        ax[0].imshow(image)\n",
    "        ax[1].imshow(mask)\n",
    "    else:\n",
    "        f, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "        ax[0, 0].imshow(original_image)\n",
    "        ax[0, 0].set_title('Original image', fontsize=fontsize)\n",
    "        \n",
    "        ax[1, 0].imshow(original_mask)\n",
    "        ax[1, 0].set_title('Original mask', fontsize=fontsize)\n",
    "        \n",
    "        ax[0, 1].imshow(image)\n",
    "        ax[0, 1].set_title('Transformed image', fontsize=fontsize)\n",
    "        \n",
    "        ax[1, 1].imshow(mask)\n",
    "        ax[1, 1].set_title('Transformed mask', fontsize=fontsize)\n",
    "\n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n",
    "\n",
    "# Build model\n",
    "\n",
    "def build_model_deeper(input_layer, start_neurons, DropoutRatio = 0.5):\n",
    "    # 101 -> 50\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n",
    "    conv1 = residual_block_cSE(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block_cSE(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block_cSE(conv1,start_neurons * 1, True)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "    # 50 -> 25\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
    "    conv2 = residual_block_cSE(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block_cSE(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block_cSE(conv2,start_neurons * 2, True)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "    # 25 -> 12\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
    "    conv3 = residual_block_cSE(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block_cSE(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block_cSE(conv3,start_neurons * 4, True)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "    # 12 -> 6\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
    "    conv4 = residual_block_cSE(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block_cSE(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block_cSE(conv4,start_neurons * 8, True)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block_cSE(convm,start_neurons * 16)\n",
    "    convm = residual_block_cSE(convm,start_neurons * 16)\n",
    "    convm = residual_block_cSE(convm,start_neurons * 16, True)\n",
    "    \n",
    "    # 6 -> 12\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block_cSE(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block_cSE(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block_cSE(uconv4,start_neurons * 8, True)\n",
    "    \n",
    "    # 12 -> 25\n",
    "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])    \n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block_cSE(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block_cSE(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block_cSE(uconv3,start_neurons * 4, True)\n",
    "\n",
    "    # 25 -> 50\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "        \n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block_cSE(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block_cSE(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block_cSE(uconv2,start_neurons * 2, True)\n",
    "    \n",
    "    # 50 -> 101\n",
    "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block_cSE(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block_cSE(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block_cSE(uconv1,start_neurons * 1, True)\n",
    "    \n",
    "    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
    "    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n",
    "    output_layer =  Activation('sigmoid')(output_layer_noActi)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d36186472064dc19bd353dfb9b4f69d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kownse/.local/lib/python3.6/site-packages/keras_preprocessing/image.py:487: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35781b1c42db458e99e71d0ae6bc5936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Loading of training/testing ids and depths\n",
    "train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)\n",
    "\n",
    "train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBSET = len(train_df)\n",
    "train_df = train_df.head(SUBSET)\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "train_df.index.values,\n",
    "np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "train_df.coverage.values,\n",
    "train_df.z.values,\n",
    "test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 0, 1, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(5,5, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba27b8e527ea40e0af8085635b8f9403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfd67edaced4f049a1ef953d6f0ddad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dba2304eb47484e885f3b5dad04dbed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a74c5b4c1434924b00280044b66aa84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8b6a0b26fb4c6f82e767f809500572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1120), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528ad5e56d8747ee97dd849ddbeca393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=640), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac416daa85949bfb2401cd069e29f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=640), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71f6b1f55af434e905efb831c6eb3e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=320), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1630ac6059149348e6a699adf440f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=320), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aug_img = []\n",
    "aug_msk = []\n",
    "augments = [\n",
    "    (1.0, HorizontalFlip(p=1)),\n",
    "#     (0.35, VerticalFlip(p=1)),\n",
    "#     (0.35, RandomRotate90(p=1)),\n",
    "#     (0.35, Transpose(p=1)),\n",
    "    (0.2, ElasticTransform(p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03)),\n",
    "    (0.2, GridDistortion(p=1)),\n",
    "    (0.1, OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)),\n",
    "#     (0.1, RandomSizedCrop(p=1, min_max_height=(int(img_size_ori / 2), img_size_ori), height=img_size_ori, width=img_size_ori)),\n",
    "]\n",
    "\n",
    "for ratio, aug in tqdm_notebook(augments):\n",
    "    selidx = np.random.choice(x_train.shape[0], int(x_train.shape[0] * ratio), replace=False)\n",
    "    for idx in tqdm_notebook(selidx):\n",
    "        augmented = aug(image=x_train[idx], mask=y_train[idx])\n",
    "        aimg = augmented['image']\n",
    "        amsk = augmented['mask']\n",
    "        if len(aimg.shape) < 3:\n",
    "            aimg = aimg[...,np.newaxis]\n",
    "        if len(amsk.shape) < 3:\n",
    "            amsk = amsk[...,np.newaxis]\n",
    "        aug_img.append(aimg)\n",
    "        aug_msk.append(amsk)\n",
    "\n",
    "aug_img = np.asarray(aug_img)\n",
    "aug_msk = np.asarray(aug_msk)\n",
    "x_train = np.append(x_train, aug_img, axis=0)\n",
    "y_train = np.append(y_train, aug_msk, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11680, 101, 101, 1)\n",
      "(800, 101, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "../model/Unet_resnet_deeper_cse_aug2_32_0.5.csv\n",
      "Train on 11680 samples, validate on 800 samples\n",
      "Epoch 1/200\n",
      "11680/11680 [==============================] - 76s 6ms/step - loss: 0.4404 - my_iou_metric: 0.3863 - val_loss: 1.2463 - val_my_iou_metric: 0.3266\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.32662, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 2/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.3759 - my_iou_metric: 0.5023 - val_loss: 0.3052 - val_my_iou_metric: 0.5735\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.32662 to 0.57350, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 3/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.3299 - my_iou_metric: 0.5292 - val_loss: 0.3489 - val_my_iou_metric: 0.5404\n",
      "\n",
      "Epoch 00003: val_my_iou_metric did not improve from 0.57350\n",
      "Epoch 4/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.3079 - my_iou_metric: 0.5311 - val_loss: 0.3131 - val_my_iou_metric: 0.5614\n",
      "\n",
      "Epoch 00004: val_my_iou_metric did not improve from 0.57350\n",
      "Epoch 5/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.2822 - my_iou_metric: 0.5521 - val_loss: 0.3264 - val_my_iou_metric: 0.5693\n",
      "\n",
      "Epoch 00005: val_my_iou_metric did not improve from 0.57350\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 6/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.2473 - my_iou_metric: 0.5876 - val_loss: 0.2367 - val_my_iou_metric: 0.6343\n",
      "\n",
      "Epoch 00006: val_my_iou_metric improved from 0.57350 to 0.63425, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 7/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.2307 - my_iou_metric: 0.6030 - val_loss: 0.2058 - val_my_iou_metric: 0.6417\n",
      "\n",
      "Epoch 00007: val_my_iou_metric improved from 0.63425 to 0.64175, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 8/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.2201 - my_iou_metric: 0.6141 - val_loss: 0.1863 - val_my_iou_metric: 0.6609\n",
      "\n",
      "Epoch 00008: val_my_iou_metric improved from 0.64175 to 0.66088, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 9/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.2069 - my_iou_metric: 0.6353 - val_loss: 0.4094 - val_my_iou_metric: 0.5745\n",
      "\n",
      "Epoch 00009: val_my_iou_metric did not improve from 0.66088\n",
      "Epoch 10/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.2044 - my_iou_metric: 0.6466 - val_loss: 0.1773 - val_my_iou_metric: 0.6888\n",
      "\n",
      "Epoch 00010: val_my_iou_metric improved from 0.66088 to 0.68875, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 11/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.2007 - my_iou_metric: 0.6507 - val_loss: 0.2169 - val_my_iou_metric: 0.6500\n",
      "\n",
      "Epoch 00011: val_my_iou_metric did not improve from 0.68875\n",
      "Epoch 12/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1935 - my_iou_metric: 0.6570 - val_loss: 0.4585 - val_my_iou_metric: 0.5376\n",
      "\n",
      "Epoch 00012: val_my_iou_metric did not improve from 0.68875\n",
      "Epoch 13/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1872 - my_iou_metric: 0.6666 - val_loss: 0.2414 - val_my_iou_metric: 0.6573\n",
      "\n",
      "Epoch 00013: val_my_iou_metric did not improve from 0.68875\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 14/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1728 - my_iou_metric: 0.6782 - val_loss: 0.1580 - val_my_iou_metric: 0.7104\n",
      "\n",
      "Epoch 00014: val_my_iou_metric improved from 0.68875 to 0.71037, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 15/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1713 - my_iou_metric: 0.6812 - val_loss: 0.1699 - val_my_iou_metric: 0.7129\n",
      "\n",
      "Epoch 00015: val_my_iou_metric improved from 0.71037 to 0.71287, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 16/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1671 - my_iou_metric: 0.6891 - val_loss: 0.1645 - val_my_iou_metric: 0.7222\n",
      "\n",
      "Epoch 00016: val_my_iou_metric improved from 0.71287 to 0.72225, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 17/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1672 - my_iou_metric: 0.6911 - val_loss: 0.1651 - val_my_iou_metric: 0.7269\n",
      "\n",
      "Epoch 00017: val_my_iou_metric improved from 0.72225 to 0.72688, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 18/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1620 - my_iou_metric: 0.6922 - val_loss: 0.1553 - val_my_iou_metric: 0.7240\n",
      "\n",
      "Epoch 00018: val_my_iou_metric did not improve from 0.72688\n",
      "Epoch 19/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1593 - my_iou_metric: 0.6998 - val_loss: 0.1586 - val_my_iou_metric: 0.7259\n",
      "\n",
      "Epoch 00019: val_my_iou_metric did not improve from 0.72688\n",
      "Epoch 20/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1578 - my_iou_metric: 0.6982 - val_loss: 0.2367 - val_my_iou_metric: 0.6838\n",
      "\n",
      "Epoch 00020: val_my_iou_metric did not improve from 0.72688\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 21/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1472 - my_iou_metric: 0.7113 - val_loss: 0.1468 - val_my_iou_metric: 0.7357\n",
      "\n",
      "Epoch 00021: val_my_iou_metric improved from 0.72688 to 0.73575, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 22/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1474 - my_iou_metric: 0.7110 - val_loss: 0.1407 - val_my_iou_metric: 0.7450\n",
      "\n",
      "Epoch 00022: val_my_iou_metric improved from 0.73575 to 0.74500, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 23/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1440 - my_iou_metric: 0.7165 - val_loss: 0.1477 - val_my_iou_metric: 0.7431\n",
      "\n",
      "Epoch 00023: val_my_iou_metric did not improve from 0.74500\n",
      "Epoch 24/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1424 - my_iou_metric: 0.7199 - val_loss: 0.1583 - val_my_iou_metric: 0.7383\n",
      "\n",
      "Epoch 00024: val_my_iou_metric did not improve from 0.74500\n",
      "Epoch 25/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1415 - my_iou_metric: 0.7161 - val_loss: 0.1686 - val_my_iou_metric: 0.7321\n",
      "\n",
      "Epoch 00025: val_my_iou_metric did not improve from 0.74500\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 26/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1377 - my_iou_metric: 0.7218 - val_loss: 0.1451 - val_my_iou_metric: 0.7477\n",
      "\n",
      "Epoch 00026: val_my_iou_metric improved from 0.74500 to 0.74775, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 27/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1359 - my_iou_metric: 0.7235 - val_loss: 0.1437 - val_my_iou_metric: 0.7395\n",
      "\n",
      "Epoch 00027: val_my_iou_metric did not improve from 0.74775\n",
      "Epoch 28/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1354 - my_iou_metric: 0.7224 - val_loss: 0.1421 - val_my_iou_metric: 0.7450\n",
      "\n",
      "Epoch 00028: val_my_iou_metric did not improve from 0.74775\n",
      "Epoch 29/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1326 - my_iou_metric: 0.7255 - val_loss: 0.1455 - val_my_iou_metric: 0.7496\n",
      "\n",
      "Epoch 00029: val_my_iou_metric improved from 0.74775 to 0.74963, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 30/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1324 - my_iou_metric: 0.7266 - val_loss: 0.1421 - val_my_iou_metric: 0.7482\n",
      "\n",
      "Epoch 00030: val_my_iou_metric did not improve from 0.74963\n",
      "Epoch 31/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1314 - my_iou_metric: 0.7266 - val_loss: 0.1444 - val_my_iou_metric: 0.7446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00031: val_my_iou_metric did not improve from 0.74963\n",
      "Epoch 32/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1297 - my_iou_metric: 0.7244 - val_loss: 0.1477 - val_my_iou_metric: 0.7496\n",
      "\n",
      "Epoch 00032: val_my_iou_metric did not improve from 0.74963\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 33/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1275 - my_iou_metric: 0.7288 - val_loss: 0.1435 - val_my_iou_metric: 0.7490\n",
      "\n",
      "Epoch 00033: val_my_iou_metric did not improve from 0.74963\n",
      "Epoch 34/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1252 - my_iou_metric: 0.7322 - val_loss: 0.1428 - val_my_iou_metric: 0.7470\n",
      "\n",
      "Epoch 00034: val_my_iou_metric did not improve from 0.74963\n",
      "Epoch 35/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1257 - my_iou_metric: 0.7283 - val_loss: 0.1435 - val_my_iou_metric: 0.7502\n",
      "\n",
      "Epoch 00035: val_my_iou_metric improved from 0.74963 to 0.75025, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 36/200\n",
      "11680/11680 [==============================] - 62s 5ms/step - loss: 0.1268 - my_iou_metric: 0.7294 - val_loss: 0.1391 - val_my_iou_metric: 0.7516\n",
      "\n",
      "Epoch 00036: val_my_iou_metric improved from 0.75025 to 0.75162, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 37/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1252 - my_iou_metric: 0.7311 - val_loss: 0.1425 - val_my_iou_metric: 0.7470\n",
      "\n",
      "Epoch 00037: val_my_iou_metric did not improve from 0.75162\n",
      "Epoch 38/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1230 - my_iou_metric: 0.7315 - val_loss: 0.1410 - val_my_iou_metric: 0.7534\n",
      "\n",
      "Epoch 00038: val_my_iou_metric improved from 0.75162 to 0.75338, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 39/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1248 - my_iou_metric: 0.7318 - val_loss: 0.1451 - val_my_iou_metric: 0.7485\n",
      "\n",
      "Epoch 00039: val_my_iou_metric did not improve from 0.75338\n",
      "Epoch 40/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1236 - my_iou_metric: 0.7305 - val_loss: 0.1413 - val_my_iou_metric: 0.7451\n",
      "\n",
      "Epoch 00040: val_my_iou_metric did not improve from 0.75338\n",
      "Epoch 41/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1233 - my_iou_metric: 0.7327 - val_loss: 0.1427 - val_my_iou_metric: 0.7539\n",
      "\n",
      "Epoch 00041: val_my_iou_metric improved from 0.75338 to 0.75387, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 42/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1244 - my_iou_metric: 0.7303 - val_loss: 0.1438 - val_my_iou_metric: 0.7495\n",
      "\n",
      "Epoch 00042: val_my_iou_metric did not improve from 0.75387\n",
      "Epoch 43/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1216 - my_iou_metric: 0.7355 - val_loss: 0.1406 - val_my_iou_metric: 0.7566\n",
      "\n",
      "Epoch 00043: val_my_iou_metric improved from 0.75387 to 0.75662, saving model to ../model/Unet_resnet_deeper_cse_aug2_32_0.5.model\n",
      "Epoch 44/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1239 - my_iou_metric: 0.7311 - val_loss: 0.1459 - val_my_iou_metric: 0.7499\n",
      "\n",
      "Epoch 00044: val_my_iou_metric did not improve from 0.75662\n",
      "Epoch 45/200\n",
      "11680/11680 [==============================] - 61s 5ms/step - loss: 0.1220 - my_iou_metric: 0.7328 - val_loss: 0.1406 - val_my_iou_metric: 0.7465\n",
      "\n",
      "Epoch 00045: val_my_iou_metric did not improve from 0.75662\n",
      "Epoch 46/200\n",
      " 7200/11680 [=================>............] - ETA: 23s - loss: 0.1211 - my_iou_metric: 0.7343"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-458715f8a5bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_feature = 16\n",
    "batch_size = 32\n",
    "dropout = 0.5\n",
    "base_name = 'Unet_resnet_deeper_cse_aug3_{}_{}'.format(batch_size, dropout)\n",
    "basic_name = '../model/{}'.format(base_name)\n",
    "save_model_name = basic_name + '.model'\n",
    "submission_file = basic_name + '.csv'\n",
    "\n",
    "print(save_model_name)\n",
    "print(submission_file)\n",
    "\n",
    "# model\n",
    "input_layer = Input((img_size_target, img_size_target, 1))\n",
    "output_layer = build_model_deeper(input_layer, start_feature,dropout)\n",
    "\n",
    "model1 = Model(input_layer, output_layer)\n",
    "\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "model1.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=[my_iou_metric])\n",
    "\n",
    "board = keras.callbacks.TensorBoard(log_dir='log/{}'.format(base_name),\n",
    "                       histogram_freq=0, write_graph=True, write_images=False)\n",
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric', mode = 'max',patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric', mode = 'max',factor=0.5, patience=3, min_lr=0.00001, verbose=1)\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "history = model1.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[board, early_stopping, model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model(save_model_name,custom_objects={'my_iou_metric': my_iou_metric})\n",
    "# remove layter activation layer and use losvasz loss\n",
    "input_x = model1.layers[0].input\n",
    "output_layer = model1.layers[-1].input\n",
    "model = Model(input_x, output_layer)\n",
    "c = optimizers.adam(lr = 0.01)\n",
    "\n",
    "# lovasz_loss need input range (-∞，+∞), so cancel the last \"sigmoid\" activation  \n",
    "# Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n",
    "model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\n",
    "\n",
    "#model.summary()\n",
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=12, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric_2', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.5, patience=3, min_lr=0.00001, verbose=1)\n",
    "epochs = 200\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[board, model_checkpoint,reduce_lr,early_stopping], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n",
    "                                                   'lovasz_loss': lovasz_loss})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = predict_result(model,x_valid,img_size_target)\n",
    "## Scoring for last model, choose threshold by validation data \n",
    "thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
    "# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
    "thresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n",
    "\n",
    "# ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "# print(ious)\n",
    "ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "print(ious)\n",
    "\n",
    "# instead of using default 0 as threshold, use validation data to find the best threshold.\n",
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)\n",
    "\n",
    "preds_test = predict_result(model,x_test,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "pred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "t2 = time.time()\n",
    "\n",
    "print(f\"Usedtime = {t2-t1} s\")\n",
    "\n",
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub = sub.reset_index()\n",
    "save_result(sub, '../result/{}.csv'.format(base_name), \n",
    "                        competition = 'tgs-salt-identification-challenge', \n",
    "                        send = True, index = False)\n",
    "\n",
    "t_finish = time.time()\n",
    "print(f\"Kernel run time = {(t_finish-t_start)/3600} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
