{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook #, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add, Dense, Input, Dropout\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n",
    "\n",
    "import time\n",
    "from kaggle_util import *\n",
    "from models import *\n",
    "\n",
    "from albumentations import (\n",
    "    PadIfNeeded,\n",
    "    HorizontalFlip,\n",
    "    VerticalFlip,    \n",
    "    CenterCrop,    \n",
    "    Crop,\n",
    "    Compose,\n",
    "    Transpose,\n",
    "    RandomRotate90,\n",
    "    ElasticTransform,\n",
    "    GridDistortion, \n",
    "    OpticalDistortion,\n",
    "    RandomSizedCrop,\n",
    "    OneOf,\n",
    "    CLAHE,\n",
    "    RandomContrast,\n",
    "    RandomGamma,\n",
    "    RandomBrightness\n",
    ")\n",
    "\n",
    "\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of training/testing ids and depths\n",
    "train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)\n",
    "\n",
    "train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=False)) for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]\n",
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)\n",
    "train_df['hassalt'] = train_df['masks'].apply(lambda x: (x.max()!=0) * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET = len(train_df)\n",
    "train_df = train_df.head(SUBSET)\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, msk_train, msk_val, y_train, y_valid, depth_train, depth_test = train_test_split(\n",
    "np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 3), \n",
    "np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "train_df.hassalt.values,\n",
    "train_df.z.values,\n",
    "test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_img = []\n",
    "aug_y = []\n",
    "augments = [\n",
    "    (0.5, HorizontalFlip(p=1)),\n",
    "#     (0.2, VerticalFlip(p=1)),\n",
    "#     (0.5, RandomRotate90(p=1)),\n",
    "#     (0.5, Transpose(p=1)),\n",
    "    (0.5, ElasticTransform(p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03)),\n",
    "    (0.5, GridDistortion(p=1)),\n",
    "    (0.5, OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)),\n",
    "#     (0.5, RandomSizedCrop(p=1, min_max_height=(int(img_size_ori / 2), img_size_ori), height=img_size_ori, width=img_size_ori)),\n",
    "]\n",
    "\n",
    "for ratio, aug in tqdm_notebook(augments):\n",
    "    selidx = np.random.choice(x_train.shape[0], int(x_train.shape[0] * ratio), replace=False)\n",
    "    for idx in tqdm_notebook(selidx):\n",
    "        augmented = aug(image=x_train[idx], mask=msk_train[idx])\n",
    "        aimg = augmented['image']\n",
    "        if len(aimg.shape) < 3:\n",
    "            aimg = aimg[...,np.newaxis]\n",
    "\n",
    "        aug_img.append(aimg)\n",
    "        aug_y.append(y_train[idx])\n",
    "\n",
    "aug_img = np.asarray(aug_img)\n",
    "aug_y = np.asarray(aug_y)\n",
    "x_train = np.append(x_train, aug_img, axis=0)\n",
    "y_train = np.append(y_train, aug_y, axis=0)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(BASE_MODEL):\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    if BASE_MODEL=='VGG16':\n",
    "        from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n",
    "    elif BASE_MODEL=='RESNET52':\n",
    "        from keras.applications.resnet50 import ResNet50 as PTModel, preprocess_input\n",
    "    elif BASE_MODEL=='InceptionV3':\n",
    "        from keras.applications.inception_v3 import InceptionV3 as PTModel, preprocess_input\n",
    "    elif BASE_MODEL=='Xception':\n",
    "        from keras.applications.xception import Xception as PTModel, preprocess_input\n",
    "    elif BASE_MODEL=='DenseNet169': \n",
    "        from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\n",
    "    elif BASE_MODEL=='DenseNet121':\n",
    "        from keras.applications.densenet import DenseNet121 as PTModel, preprocess_input\n",
    "    else:\n",
    "        raise ValueError('Unknown model: {}'.format(BASE_MODEL))\n",
    "        \n",
    "    return PTModel, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(base_name = 'VGG16'):\n",
    "    print(base_name)\n",
    "    PTModel, preprocess_input = get_model(base_name)\n",
    "    x_train_act = x_train.copy()\n",
    "#     for idx in range(len(x_train_act)):\n",
    "#         x_train_act[idx] = preprocess_input(x_train_act[idx])\n",
    "\n",
    "    x_val_act = x_valid.copy()\n",
    "#     for idx in range(len(x_val_act)):\n",
    "#         x_val_act[idx] = preprocess_input(x_val_act[idx])\n",
    "\n",
    "    inputshape = (img_size_target, img_size_target, 3)\n",
    "    PTModel, preprocess_input = get_model('VGG16')\n",
    "    base_pretrained_model = PTModel(input_shape = inputshape, \n",
    "                                  include_top = False, weights = 'imagenet')\n",
    "    # base_pretrained_model.trainable = False\n",
    "\n",
    "    from keras import models, layers\n",
    "    from keras.optimizers import Adam\n",
    "    img_in = layers.Input(inputshape, name='Image_RGB_In')\n",
    "    x = base_pretrained_model(img_in)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "    x = Dense(256)(x)\n",
    "    x = BatchActivate(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(64)(x)\n",
    "    x = BatchActivate(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    out_layer = layers.Dense(1, activation = 'sigmoid')(x)\n",
    "    class_model = models.Model(inputs = [img_in], outputs = [out_layer], name = 'full_model')\n",
    "\n",
    "    class_model.compile(optimizer = Adam(lr=0.01), \n",
    "                       loss = 'binary_crossentropy',\n",
    "                       metrics = ['binary_accuracy', my_iou_metric])\n",
    "\n",
    "    batch_size = 32\n",
    "    basic_name = '../model/classifier/{}_argu'.format(base_name)\n",
    "    save_model_name = basic_name + '.model'\n",
    "    submission_file = basic_name + '.csv'\n",
    "\n",
    "    print(save_model_name)\n",
    "    print(submission_file)\n",
    "\n",
    "\n",
    "    board = keras.callbacks.TensorBoard(log_dir='log/classifier/{}_argu'.format(base_name),\n",
    "                           histogram_freq=0, write_graph=True, write_images=False)\n",
    "    early_stopping = EarlyStopping(monitor='val_binary_accuracy', mode = 'max',patience=6, verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_binary_accuracy', \n",
    "                                       mode = 'max', save_best_only=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_binary_accuracy', mode = 'max',factor=0.5, patience=2, min_lr=0.00001, verbose=1)\n",
    "\n",
    "    epochs = 200\n",
    "\n",
    "    history = class_model.fit(x_train, y_train,\n",
    "                        validation_data=[x_valid, y_valid], \n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[board, early_stopping, model_checkpoint,reduce_lr], \n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lst = ['Xception', 'DenseNet169', 'DenseNet121']\n",
    "for base_model in model_lst:\n",
    "    train_classifier(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n",
    "#                                                    'lovasz_loss': lovasz_loss})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_valid = predict_result(model,x_valid,img_size_target)\n",
    "# ## Scoring for last model, choose threshold by validation data \n",
    "# thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
    "# # Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
    "# thresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n",
    "\n",
    "# # ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "# # print(ious)\n",
    "# ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
    "# print(ious)\n",
    "\n",
    "# # instead of using default 0 as threshold, use validation data to find the best threshold.\n",
    "# threshold_best_index = np.argmax(ious) \n",
    "# iou_best = ious[threshold_best_index]\n",
    "# threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "# plt.plot(thresholds, ious)\n",
    "# plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "# plt.xlabel(\"Threshold\")\n",
    "# plt.ylabel(\"IoU\")\n",
    "# plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test = np.array([(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)\n",
    "\n",
    "# preds_test = predict_result(model,x_test,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
