{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from tqdm import tqdm #, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n",
    "\n",
    "from albumentations import (\n",
    "    PadIfNeeded,\n",
    "    HorizontalFlip,\n",
    "    VerticalFlip,    \n",
    "    CenterCrop,    \n",
    "    Crop,\n",
    "    Compose,\n",
    "    Transpose,\n",
    "    RandomRotate90,\n",
    "    ElasticTransform,\n",
    "    GridDistortion, \n",
    "    OpticalDistortion,\n",
    "    RandomSizedCrop,\n",
    "    OneOf,\n",
    "    CLAHE,\n",
    "    RandomContrast,\n",
    "    RandomGamma,\n",
    "    RandomBrightness\n",
    ")\n",
    "\n",
    "import time\n",
    "from kaggle_util import *\n",
    "from models import *\n",
    "\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "\n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "    \n",
    "def downsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n",
    "\n",
    "def build_model_deeper(input_layer, start_neurons, DropoutRatio = 0.5):\n",
    "    # 101 -> 50\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n",
    "    conv1 = residual_block_sc(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block_sc(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block_sc(conv1,start_neurons * 1, True)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "    # 50 -> 25\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
    "    conv2 = residual_block_sc(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block_sc(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block_sc(conv2,start_neurons * 2, True)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "    # 25 -> 12\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
    "    conv3 = residual_block_sc(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block_sc(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block_sc(conv3,start_neurons * 4, True)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "    # 12 -> 6\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
    "    conv4 = residual_block_sc(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block_sc(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block_sc(conv4,start_neurons * 8, True)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block_sc(convm,start_neurons * 16)\n",
    "    convm = residual_block_sc(convm,start_neurons * 16)\n",
    "    convm = residual_block_sc(convm,start_neurons * 16, True)\n",
    "    \n",
    "    # 6 -> 12\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block_sc(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block_sc(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block_sc(uconv4,start_neurons * 8, True)\n",
    "    \n",
    "    # 12 -> 25\n",
    "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])    \n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block_sc(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block_sc(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block_sc(uconv3,start_neurons * 4, True)\n",
    "\n",
    "    # 25 -> 50\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "        \n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block_sc(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block_sc(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block_sc(uconv2,start_neurons * 2, True)\n",
    "    \n",
    "    # 50 -> 101\n",
    "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block_sc(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block_sc(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block_sc(uconv1,start_neurons * 1, True)\n",
    "    \n",
    "    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
    "    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n",
    "    output_layer =  Activation('sigmoid')(output_layer_noActi)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4000 [00:00<?, ?it/s]/home/kownse/.local/lib/python3.6/site-packages/keras_preprocessing/image.py:487: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n",
      "100%|██████████| 4000/4000 [00:02<00:00, 1558.66it/s]\n",
      "100%|██████████| 4000/4000 [00:01<00:00, 2079.87it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Loading of training/testing ids and depths\n",
    "train_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)\n",
    "\n",
    "train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm(train_df.index)]\n",
    "train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm(train_df.index)]\n",
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)\n",
    "train_df['hassalt'] = train_df['masks'].apply(lambda x: (x.max()!=0) * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splits(train_df, train_idx, val_idx):\n",
    "    X_train = train_df.iloc[train_idx]\n",
    "    X_valid = train_df.iloc[val_idx]\n",
    "    x_train = np.array(X_train.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)\n",
    "    x_valid = np.array(X_valid.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)\n",
    "    msk_train = np.array(X_train.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)\n",
    "    msk_val = np.array(X_valid.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)\n",
    "    y_train = X_train.hassalt.values\n",
    "    y_valid = X_valid.hassalt.values\n",
    "    id_train = X_train.index.values\n",
    "    id_valid = X_valid.index.values\n",
    "    return x_train, x_valid, msk_train, msk_val, y_train, y_valid, id_train, id_valid\n",
    "\n",
    "def argument(x_train, msk_train, y_train):\n",
    "    aug_img = []\n",
    "    aug_msk = []\n",
    "    aug_y = []\n",
    "    augments = [\n",
    "        (1, HorizontalFlip(p=1)),\n",
    "#         (0.25, VerticalFlip(p=1)),\n",
    "#         (0.25, RandomRotate90(p=1)),\n",
    "#         (0.25, Transpose(p=1)),\n",
    "        (0.15, ElasticTransform(p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03)),\n",
    "        (0.15, GridDistortion(p=1)),\n",
    "        (0.15, OpticalDistortion(p=1, distort_limit=2, shift_limit=0.5)),\n",
    "#         (0.5, RandomSizedCrop(p=1, min_max_height=(int(img_size_ori / 2), img_size_ori), height=img_size_ori, width=img_size_ori)),\n",
    "    ]\n",
    "\n",
    "    for ratio, aug in tqdm(augments):\n",
    "        selidx = np.random.choice(x_train.shape[0], int(x_train.shape[0] * ratio), replace=False)\n",
    "        for idx in tqdm(selidx):\n",
    "            augmented = aug(image=x_train[idx], mask=msk_train[idx])\n",
    "            aimg = augmented['image']\n",
    "            amsk = augmented['mask']\n",
    "            if len(aimg.shape) < 3:\n",
    "                aimg = aimg[...,np.newaxis]\n",
    "            if len(amsk.shape) < 3:\n",
    "                amsk = amsk[...,np.newaxis]\n",
    "            aug_img.append(aimg)\n",
    "            aug_msk.append(amsk)\n",
    "            aug_y.append(y_train[idx])\n",
    "\n",
    "    aug_img = np.asarray(aug_img)\n",
    "    aug_msk = np.asarray(aug_msk)\n",
    "    aug_y = np.asarray(aug_y)\n",
    "    x_train = np.append(x_train, aug_img, axis=0)\n",
    "    msk_train = np.append(msk_train, aug_msk, axis=0)\n",
    "    y_train = np.append(y_train, aug_y, axis=0)\n",
    "    print(x_train.shape)\n",
    "    print(msk_train.shape)\n",
    "    print(y_train.shape)\n",
    "    \n",
    "    return x_train, msk_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model(fold, x_train, y_train, x_valid, y_valid, id_valid):\n",
    "    start_feature = 32\n",
    "    batch_size = 32\n",
    "    dropout = 0.5\n",
    "    base_name = 'Unet_seresnet2_deeper_{}_{}_{}_{}'.format(start_feature, batch_size, dropout, fold)\n",
    "    save_model_name = '../model/segmenter/{}.model'.format(base_name)\n",
    "    submission_dir = '../result/segmenter/{}.csv'.format(base_name)\n",
    "    oof_dir = '../result/segmenter_oof/{}'.format(base_name)\n",
    "\n",
    "    print(save_model_name)\n",
    "    print(submission_dir)\n",
    "    print(oof_dir)\n",
    "\n",
    "    # model\n",
    "    input_layer = Input((img_size_target, img_size_target, 1))\n",
    "    output_layer = build_model_deeper(input_layer, start_feature,dropout)\n",
    "\n",
    "    model1 = Model(input_layer, output_layer)\n",
    "\n",
    "    c = optimizers.adam(lr = 0.01)\n",
    "    model1.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=[my_iou_metric])\n",
    "\n",
    "    board = keras.callbacks.TensorBoard(log_dir='log/segmenter/{}'.format(base_name),\n",
    "                           histogram_freq=0, write_graph=True, write_images=False)\n",
    "    early_stopping = EarlyStopping(monitor='val_my_iou_metric', mode = 'max',patience=12, verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric', \n",
    "                                       mode = 'max', save_best_only=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric', mode = 'max',factor=0.5, patience=3, min_lr=0.00001, verbose=1)\n",
    "\n",
    "    epochs = 200\n",
    "\n",
    "    history = model1.fit(x_train, y_train,\n",
    "                        validation_data=[x_valid, y_valid], \n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[board, early_stopping, model_checkpoint,reduce_lr], \n",
    "                        verbose=1)\n",
    "    \n",
    "    model1 = load_model(save_model_name,custom_objects={'my_iou_metric': my_iou_metric})\n",
    "    # remove layter activation layer and use losvasz loss\n",
    "    input_x = model1.layers[0].input\n",
    "    output_layer = model1.layers[-1].input\n",
    "    model = Model(input_x, output_layer)\n",
    "    c = optimizers.adam(lr = 0.01)\n",
    "\n",
    "    # lovasz_loss need input range (-∞，+∞), so cancel the last \"sigmoid\" activation  \n",
    "    # Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n",
    "    model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\n",
    "\n",
    "    #model.summary()\n",
    "    early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=20, verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric_2', \n",
    "                                       mode = 'max', save_best_only=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.5, patience=5, min_lr=0.00001, verbose=1)\n",
    "    epochs = 200\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        validation_data=[x_valid, y_valid], \n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[board, model_checkpoint,reduce_lr,early_stopping], \n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3199 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|█▊        | 570/3199 [00:00<00:00, 5647.40it/s]\u001b[A\n",
      " 34%|███▎      | 1078/3199 [00:00<00:00, 5362.93it/s]\u001b[A\n",
      " 51%|█████▏    | 1645/3199 [00:00<00:00, 5460.20it/s]\u001b[A\n",
      " 69%|██████▊   | 2196/3199 [00:00<00:00, 5470.01it/s]\u001b[A\n",
      " 86%|████████▌ | 2742/3199 [00:00<00:00, 5468.07it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:00<00:01,  1.71it/s].82it/s]\u001b[A\n",
      "  0%|          | 0/479 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|▋         | 33/479 [00:00<00:01, 319.02it/s]\u001b[A\n",
      " 14%|█▎        | 65/479 [00:00<00:01, 316.47it/s]\u001b[A\n",
      " 20%|██        | 96/479 [00:00<00:01, 314.10it/s]\u001b[A\n",
      " 27%|██▋       | 128/479 [00:00<00:01, 313.43it/s]\u001b[A\n",
      " 33%|███▎      | 159/479 [00:00<00:01, 311.03it/s]\u001b[A\n",
      " 40%|███▉      | 191/479 [00:00<00:00, 311.41it/s]\u001b[A\n",
      " 47%|████▋     | 223/479 [00:00<00:00, 311.37it/s]\u001b[A\n",
      " 53%|█████▎    | 254/479 [00:00<00:00, 310.58it/s]\u001b[A\n",
      " 60%|█████▉    | 286/479 [00:00<00:00, 310.63it/s]\u001b[A\n",
      " 66%|██████▋   | 318/479 [00:01<00:00, 310.86it/s]\u001b[A\n",
      " 73%|███████▎  | 349/479 [00:01<00:00, 310.47it/s]\u001b[A\n",
      " 79%|███████▉  | 380/479 [00:01<00:00, 309.84it/s]\u001b[A\n",
      " 86%|████████▌ | 412/479 [00:01<00:00, 309.96it/s]\u001b[A\n",
      " 92%|█████████▏| 443/479 [00:01<00:00, 309.57it/s]\u001b[A\n",
      " 99%|█████████▉| 475/479 [00:01<00:00, 309.65it/s]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.07s/it]it/s]\u001b[A\n",
      "  0%|          | 0/479 [00:00<?, ?it/s]\u001b[A\n",
      " 28%|██▊       | 136/479 [00:00<00:00, 1341.27it/s]\u001b[A\n",
      " 57%|█████▋    | 273/479 [00:00<00:00, 1353.74it/s]\u001b[A\n",
      " 85%|████████▌ | 408/479 [00:00<00:00, 1349.23it/s]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:02<00:00,  1.20it/s]1it/s]\u001b[A\n",
      "  0%|          | 0/479 [00:00<?, ?it/s]\u001b[A\n",
      " 51%|█████▏    | 246/479 [00:00<00:00, 2443.77it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.49it/s]4it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7835, 101, 101, 1)\n",
      "(7835, 101, 101, 1)\n",
      "(7835,)\n",
      "../model/segmenter/Unet_seresnet2_deeper_32_32_0.5_0.model\n",
      "../result/segmenter/Unet_seresnet2_deeper_32_32_0.5_0.csv\n",
      "../result/segmenter_oof/Unet_seresnet2_deeper_32_32_0.5_0\n",
      "Train on 7835 samples, validate on 801 samples\n",
      "Epoch 1/200\n",
      "7835/7835 [==============================] - 115s 15ms/step - loss: 0.4980 - my_iou_metric: 0.3625 - val_loss: 0.7845 - val_my_iou_metric: 0.3908\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.39076, saving model to ../model/segmenter/Unet_seresnet2_deeper_32_32_0.5_0.model\n",
      "Epoch 2/200\n",
      "7835/7835 [==============================] - 101s 13ms/step - loss: 0.3653 - my_iou_metric: 0.4792 - val_loss: 0.6326 - val_my_iou_metric: 0.3769\n",
      "\n",
      "Epoch 00002: val_my_iou_metric did not improve from 0.39076\n",
      "Epoch 3/200\n",
      "7835/7835 [==============================] - 101s 13ms/step - loss: 0.3163 - my_iou_metric: 0.5311 - val_loss: 0.6335 - val_my_iou_metric: 0.3205\n",
      "\n",
      "Epoch 00003: val_my_iou_metric did not improve from 0.39076\n",
      "Epoch 4/200\n",
      "7835/7835 [==============================] - 101s 13ms/step - loss: 0.2842 - my_iou_metric: 0.5448 - val_loss: 0.3236 - val_my_iou_metric: 0.4447\n",
      "\n",
      "Epoch 00004: val_my_iou_metric improved from 0.39076 to 0.44469, saving model to ../model/segmenter/Unet_seresnet2_deeper_32_32_0.5_0.model\n",
      "Epoch 5/200\n",
      "7835/7835 [==============================] - 101s 13ms/step - loss: 0.2684 - my_iou_metric: 0.5577 - val_loss: 1.2324 - val_my_iou_metric: 0.3883\n",
      "\n",
      "Epoch 00005: val_my_iou_metric did not improve from 0.44469\n",
      "Epoch 6/200\n",
      "7835/7835 [==============================] - 101s 13ms/step - loss: 0.2536 - my_iou_metric: 0.5704 - val_loss: 0.2548 - val_my_iou_metric: 0.5935\n",
      "\n",
      "Epoch 00006: val_my_iou_metric improved from 0.44469 to 0.59351, saving model to ../model/segmenter/Unet_seresnet2_deeper_32_32_0.5_0.model\n",
      "Epoch 7/200\n",
      "7835/7835 [==============================] - 101s 13ms/step - loss: 0.2441 - my_iou_metric: 0.5785 - val_loss: 0.2160 - val_my_iou_metric: 0.6300\n",
      "\n",
      "Epoch 00007: val_my_iou_metric improved from 0.59351 to 0.62996, saving model to ../model/segmenter/Unet_seresnet2_deeper_32_32_0.5_0.model\n",
      "Epoch 8/200\n",
      "7835/7835 [==============================] - 101s 13ms/step - loss: 0.2366 - my_iou_metric: 0.5903 - val_loss: 0.3583 - val_my_iou_metric: 0.5306\n",
      "\n",
      "Epoch 00008: val_my_iou_metric did not improve from 0.62996\n",
      "Epoch 9/200\n",
      "7835/7835 [==============================] - 101s 13ms/step - loss: 0.2286 - my_iou_metric: 0.5978 - val_loss: 0.2488 - val_my_iou_metric: 0.6031\n",
      "\n",
      "Epoch 00009: val_my_iou_metric did not improve from 0.62996\n",
      "Epoch 10/200\n",
      "7835/7835 [==============================] - 101s 13ms/step - loss: 0.2173 - my_iou_metric: 0.6051 - val_loss: 0.2839 - val_my_iou_metric: 0.6124\n",
      "\n",
      "Epoch 00010: val_my_iou_metric did not improve from 0.62996\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 11/200\n",
      "7835/7835 [==============================] - 101s 13ms/step - loss: 0.2047 - my_iou_metric: 0.6124 - val_loss: 0.2202 - val_my_iou_metric: 0.6196\n",
      "\n",
      "Epoch 00011: val_my_iou_metric did not improve from 0.62996\n",
      "Epoch 12/200\n",
      "7835/7835 [==============================] - 101s 13ms/step - loss: 0.1993 - my_iou_metric: 0.6194 - val_loss: 0.1971 - val_my_iou_metric: 0.6258\n",
      "\n",
      "Epoch 00012: val_my_iou_metric did not improve from 0.62996\n",
      "Epoch 13/200\n",
      "7835/7835 [==============================] - 101s 13ms/step - loss: 0.1944 - my_iou_metric: 0.6232 - val_loss: 0.1832 - val_my_iou_metric: 0.6245\n",
      "\n",
      "Epoch 00013: val_my_iou_metric did not improve from 0.62996\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 14/200\n",
      "7835/7835 [==============================] - 101s 13ms/step - loss: 0.1873 - my_iou_metric: 0.6259 - val_loss: 0.1700 - val_my_iou_metric: 0.6908\n",
      "\n",
      "Epoch 00014: val_my_iou_metric improved from 0.62996 to 0.69076, saving model to ../model/segmenter/Unet_seresnet2_deeper_32_32_0.5_0.model\n",
      "Epoch 15/200\n",
      "7835/7835 [==============================] - 101s 13ms/step - loss: 0.1838 - my_iou_metric: 0.6312 - val_loss: 0.1623 - val_my_iou_metric: 0.6760\n",
      "\n",
      "Epoch 00015: val_my_iou_metric did not improve from 0.69076\n",
      "Epoch 16/200\n",
      "7835/7835 [==============================] - 101s 13ms/step - loss: 0.1825 - my_iou_metric: 0.6335 - val_loss: 0.1578 - val_my_iou_metric: 0.6740\n",
      "\n",
      "Epoch 00016: val_my_iou_metric did not improve from 0.69076\n",
      "Epoch 17/200\n",
      "7835/7835 [==============================] - 101s 13ms/step - loss: 0.1825 - my_iou_metric: 0.6328 - val_loss: 0.1567 - val_my_iou_metric: 0.6800\n",
      "\n",
      "Epoch 00017: val_my_iou_metric did not improve from 0.69076\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 18/200\n",
      "2176/7835 [=======>......................] - ETA: 1:10 - loss: 0.1818 - my_iou_metric: 0.6217"
     ]
    }
   ],
   "source": [
    "folds = [0]\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['hassalt'])):\n",
    "    if fold not in folds:\n",
    "        print('skip fold', fold)\n",
    "        continue\n",
    "        \n",
    "    x_train, x_valid, msk_train, msk_val, y_train, y_valid, id_train, id_valid = get_splits(train_df, train_idx, val_idx)\n",
    "    x_train, msk_train, y_train = argument(x_train, msk_train, y_train)\n",
    "    \n",
    "    model = train_model(fold, x_train, msk_train, x_valid, msk_val, id_valid)\n",
    "    \n",
    "    from keras import backend as K\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
